torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 3, in <module>
    import gradio as gr
ModuleNotFoundError: No module named 'gradio'
torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../root/.cache/torch/whisperx-vad-segmentation.bin`
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpy0iyeaqq
上传文件的地址：/tmp/gradio/ec353261af79df5996d421795493ef1bb03233ba/安全会议纪要cfw要部署.mp4
base name 安全会议纪要cfw要部署.mp4
No language specified, language will be first be detected for each audio file (increases inference time).
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.
Detected language: en (0.98) in first 30s of audio...
[{'text': ' You like Mondays, right? Yes, after the weekend everything is okay. I would like to have that attitude. How are you, Tino? Are you well? Yes, I am fine again, yes. Tibor is on holiday, so I do not know if... Okay, I do not know.', 'start': 0.009, 'end': 26.049}, {'text': " Let me just share my screen. Do you know when he will be back? Next Monday. Next Monday. Okay. No, that's the wrong screen. That's the right one. Okay. I just copied the page from last week. Meeting minutes.", 'start': 28.217, 'end': 52.91}, {'text': " OK, so then let's start. First thing, hi, Joshua. I sent you, I guess, two weeks ago our roadmap and wanted to ask if that aligns with your roadmap. Unfortunately, I did not get any answer by you. If you have time to check that? Yes, after today.", 'start': 57.995, 'end': 87.688}, {'text': " I was very busy for the last couple of weeks. Okay. No problem. Great. Okay. Then let's start with the open items. Let's focus on the DBSS. I have some actions open by Tibor. I don't know if you are also involved in this, Joshua.", 'start': 88.08, 'end': 115.162}, {'text': " If not, I would wait for next week. Yeah, we can bring it up. I was in the DBSS WebEx for deploying almost every day and every time. So I'm pretty clear what's happening in the DBSS. OK, then maybe you can give me answers. So I checked the integrations into services for IAM.", 'start': 115.93, 'end': 145.111}, {'text': " I saw differences that we have on OTC Cloud like, how can I open it? I can just make it bigger. We have this kind of actions for permissions. And on Huawei Cloud, we have a few more. That's due to the different version of IAM. I'm not sure what's the IAM in Huawei Cloud right now, but currently", 'start': 145.503, 'end': 175.128}, {'text': " Those actions are what we got by this time. OK. So does it mean when we upgrade to the new IAM version, this will be automatically changed? I think some small change will be implemented. But that's a very small, small change. Like configure something, then it should be done. OK. So basically we need to wait for this IAM. Upgradation, yes. Yeah. OK.", 'start': 175.333, 'end': 205.316}, {'text': " can only be done after I upgrade. Okay. Then I checked for tech management. It's still not possible to take the DBSS resources. Do you know if we can fix that? TMS. Let me see. I think last time I checked in the Huawei Cloud in the", 'start': 209.241, 'end': 236.442}, {'text': " manual is now like connecting to the TMS. Does it connect to TMS? So if I go to OTC on the production environment, if I go to GBSS, it's in the list. But when I check it, I get the system is busy. So I cannot take any instance. Can you check? Let me see.", 'start': 236.954, 'end': 266.425}, {'text': " Last time I think it was working. Did you try today or what? Yes, I'm just live. Strange thing is when I'm on the test environment, I cannot see DBSS at all. I don't know which environment has the most updated version. I think they are both at the same version. The version is the same.", 'start': 267.108, 'end': 295.572}, {'text': " Maybe in the testbed, the connection is not done yet. I'm not sure. Yeah. Because also on production, I cannot see it. I mean, it's not a blocker for release. But still, we should care about interconnection to existing services. So you're saying TMS is not working? Is that what you're saying? Yes. Yeah, exactly. So for DBSS, it's not working.", 'start': 295.811, 'end': 325.179}, {'text': " So I can, if I go here, I can tag the instances but I cannot see it then in the TMS. So here I have, I don't know where I can even put the tags in. Databases, I don't even know where to tag. Settings, no. I don't even know where I can tag an instance. I would assume here somewhere.", 'start': 329.104, 'end': 358.592}, {'text': ' But still, if I go to tech management, I can find DBSS and if I select it, I get an error. So the system is busy. So there is something not working. Can you check that? One second.', 'start': 361.135, 'end': 387.261}, {'text': " Yeah, it's the console framework 3.0. Currently a lot of problem is due to that outdated console framework. It's not on our squad, it's on Observation Squad. So without this function, it will be problematic. Yes.", 'start': 397.944, 'end': 426.152}, {'text': " Okay. What is it? OTC console framework? Yeah, console framework 3.0. So this is the new one which will be implemented or which we have or what do we need to do? We don't need to do anything. Currently this console framework is ongoing and I think it already finished on testbed. Okay.", 'start': 430.828, 'end': 459.258}, {'text': " Okay, done by orchestration squad. Okay, basically we just need to wait for them. Ah, okay. Thanks for the info, I didn't know. Okay, this one was done. Implementation done, QA complete, only one blocker left.", 'start': 460.606, 'end': 487.449}, {'text': ' Maybe Susanna do you have a current status because I saw you invited for again the final meeting. What is still left? Yes, I have invited for Wednesday this week because I am still receiving some news from TSI colleagues which are not happy with the status of the service. There are still new bugs being found which are considered as blockers.', 'start': 488.148, 'end': 514.582}, {'text': " Also API documentation and people from Ecosystem Squad are really, let's say, not happy with the current status of API which seems to be not functional at all. I think we don't really need to go into details here. I really believe Wednesday everything will be clarified. I have also invited, I think, Leticia from Huawei. She will not join. She will not join. Okay.", 'start': 515.009, 'end': 543.814}, {'text': " And I really believe other colleagues who were part of the deployment or maybe you Joshua will be able to join and we can have a clarification. But if the problem, because I'm really like not happy, believe it or not, I would also like to have the VBS already public, but, you know, we need a discussion what is really bothering us on both sides. So let's hope Wednesday.", 'start': 545.145, 'end': 571.459}, {'text': " I can saw the blocker ticket that Lucas created. I solved this one by one. I saw it is solved. Some of them is no code. Some of them is just no real. And some of them, I only see there's only one blocker in the current state. And it is also due to the console framework.", 'start': 572.125, 'end': 600.469}, {'text': " I'm not sure. I think there's no way that DBSS can have a patch to fix that, because this console is not on the DBSS, which is the problem ticket is 5353, the web UI thing. I'm a bit confused, because last week I wrote QA is done, there was only one ticket.", 'start': 601.63, 'end': 631.425}, {'text': " Why do we have no news or we are still testing? I thought it was done. I thought as well but people inform us every day that people are still working on some kind of bug fixing or upgrading or I don't know else really. So therefore Lukasz is still testing or was still testing, I don't know.", 'start': 631.869, 'end': 659.889}, {'text': ' on Friday he sent me. I just wanted to ask what are the blockers we have because I saw an email which stated this bug ticket but Joshua you said a different ticket, right? I said a different ticket. Could you tell again which? 5353. 5353. And I have got another one in the chat.', 'start': 660.196, 'end': 684.991}, {'text': " So I really don't know where are these coming from, why the testing is not completed after several weeks or months. Sorry, I'm really not happy for our side, I have to also say, because in my opinion, testing on our side should not take that long.", 'start': 685.162, 'end': 702.637}, {'text': " also that we do not have a clear, let's say... Yes, because I thought we had a list of blockers, but we are done with testing and now they are expanding over time. Yes, so did I. So therefore I said, okay, let's put everyone together and really, I don't know if we really should discuss it from the beginning, but this is not acceptable on both, or even on TSI side from my perspective. It's taking us far too long to really close this topic. Will you close which topic?", 'start': 703.012, 'end': 732.978}, {'text': " Sorry? Really close which topic? I mean DBSS to make it public. To make it public. Because I saw this, you see the 5353, this blocker is created last Thursday. Yeah, that's the problem. And we already, and I already have some sort of the solution to that. Is that clear? That the package is not coming out tomorrow.", 'start': 735.725, 'end': 764.053}, {'text': " Okay, so it is really fixed tomorrow or what did you say? It's not going to fix tomorrow. It's not even the DBSS. Okay. Yeah, that's a different thing. The thing about what we are talking about because we thought testing is done. So I noted last week testing is done and now we get a ticket with a blocker like four days ago. So we are unsatisfied with our own testers.", 'start': 767.329, 'end': 793.626}, {'text': " We should have known that like two weeks ago. It's a bit late to have testing results because we already completed testing. Independent of what the bug is, I don't know the content, but it's really unhappy to say we've done testing and security testing is also done, for example, and then everything new pops up. So why do they still test when they say we are done? That's a bit strange.", 'start': 793.814, 'end': 823.541}, {'text': " It's about the process we have. I don't know what this box is about. Like when you don't have authority or you mess around with authority and when you try to access to the DBSS console without authority, then some small lines at Huawei Cloud will pop out.", 'start': 824.36, 'end': 850.111}, {'text': ' And they will jump to a new console. And it says back to our cloud. This is the obfuscation pages. Yeah, something like this. Ah, this one, OK. Yeah, this one. I think I can try to ask the DBSS console guy to give us a quick patch. But I think they cannot do it because this is not on the console.', 'start': 855.469, 'end': 884.889}, {'text': " another console to do that. So we see what's up later. OK. It would be nice if we can have a chat with them, because this is really a serious issue. I know. Like I said, I was in the DBSS WebEx every day. I see they're fixing stuff. Yes. I know what's going on. OK. Yeah.", 'start': 885.401, 'end': 915.162}, {'text': " But you don't have any, you said it will not be fixed tomorrow, it's a big dependency. But you don't have any estimation date or something, right? No, right now. Maybe later. Okay. Because what we then need to think about is on Wednesday when we don't have that much progress to start whitelisting for only", 'start': 916.015, 'end': 945.776}, {'text': " for example, to at least have them use the service. Just one idea, if we have so much dependencies. That's something we can discuss. I think for the TMS, back to the TMS topic. Yeah, we are waiting for the console and", 'start': 946.834, 'end': 973.439}, {'text': " If the console is online, some small configure will make it work. And so I think maybe we should remove this configure from the production console by now and for the people. And so that, so that. So it's not just the TNTMS.", 'start': 974.326, 'end': 997.346}, {'text': " So that we don't have this feature for now. And when the console is online, we can just create this by demand. Yeah. Yes, that's a good idea. How can we disable it? What do you need from? We don't need anything from you. I just leave a message to our audience. That's all. OK. So should I write you something to forward, or? No need. I already did.", 'start': 997.415, 'end': 1023.473}, {'text': " Okay, thanks. That's a good idea. Disable it and then wait for a console firmware to enable it. Yes, that's good. Do you know the status about security testing? I just noted that Thibault wanted to ask for retesting because he said we fixed all security issues.", 'start': 1024.309, 'end': 1052.875}, {'text': " I don't know about that part. Last time I hear the security says no blocker. Isn't that means we already fixed everything? I did not get that part right. Yeah, that's also what I remember as well. There should be no blocker from security.", 'start': 1053.865, 'end': 1075.026}, {'text': " Also Thibault wanted to organize some kind to show DBSS from custom perspective. I don't know, Joshua, if you were involved in this communication and have any info about that? Like a showcase, like how to use DBSS, like creating a database, then deploying DBSS.", 'start': 1084.497, 'end': 1108.933}, {'text': " sending out some malicious attacking SQL attacks and see the reports and dashboards about SQL injections and compliance reports and so on. Just like how to use it as a customer. Do we want to have that? To understand at least, because the squad members, they don't even know how this service works.", 'start': 1109.445, 'end': 1136.22}, {'text': " Like if customer asks what can I do or how do I set it up and so on, I guess the people don't have that much knowledge to answer. If we do want to write one day, then maybe, yeah.", 'start': 1139.275, 'end': 1160.503}, {'text': " Maybe what? Maybe this is doable. Should I ask Tibor again next week or is it something you could organize? Everything you ask Tibor will eventually go through me. So you can write my name here. Okay, that's good. It would be really nice if you can organize such a thing.", 'start': 1167.585, 'end': 1195.981}, {'text': ' It would be great if you can ask and then give us some next week. Okay, next thing is about the KMS upgrade. Any news for that? I guess not really, right? Not really. Ethan, we already have the package here already and are pending for Dajuan to do the upgrade.', 'start': 1202.244, 'end': 1227.927}, {'text': " I don't know. I just have July 3rd was my information. Susanna, do you have info if he already received the package? I think Chris mentioned something last week that if I remember correctly he said this in the end will not be necessary but I think we better check with him.", 'start': 1230.06, 'end': 1255.367}, {'text': ' Sylvia, do you remember Chris saying something like that last week? I remember he was talking but I do not remember the details, sorry. Okay, maybe I will check with Chris then. Yes, maybe you can ask him the next day. Because we said we wanted to start basically in July somewhere, so the package is there.', 'start': 1257.056, 'end': 1280.93}, {'text': ' Okay, I will ask Chris and then for the update here. That would be great. Yeah, also the documentation would be quite interesting, like the change log release notes. Next thing, yeah, EM upgrade. I just read some emails and as we looked at somehow it was not successful and we needed to roll back.', 'start': 1282.961, 'end': 1311.766}, {'text': ' Do you already know the root cause? Yes, it was basically not caused by us, it was caused by one of the network devices which caused the problem.', 'start': 1312.637, 'end': 1331.596}, {'text': ' So at the moment we are in the point that I think today, this afternoon Pankto wants to do the rollback of the operation which was already performed and hopefully tomorrow evening or Wednesday evening we want to do the last part of the actual upgrade of 4.2.6. So no more unfortunately. Joshua, you waste your hand? No, I misread. Okay.', 'start': 1332.09, 'end': 1360.572}, {'text': ' So this means we know what to do and we try again this week. Next thing is about HSS.', 'start': 1361.015, 'end': 1390.623}, {'text': ' Are there any important updates for that? I already saw it on the console. Of course, I am locked out again. Could you give me an update about HSS? Are we on track with implementation?', 'start': 1391.237, 'end': 1414.787}, {'text': " I think Willy mentioned that it's already deployed on the pre-prod, it's visible on the console. Today he wanted to continue but he was not sure if the, sorry I cannot remember the name of the Huawei colleague, will be available today or not. Sorry, you continue.", 'start': 1415.469, 'end': 1437.807}, {'text': " No, no, no problem. I don't know really what are the next steps. He will continue and currently this is a blocking by the firewall rules. Yes, we already submitted the firewall rules pending for the network squad to approve it. OK, right. We have two ways to go. The first way is we do not need the firewall rules. Just a small configure in the HD1 and it doesn't need to have firewall rules.", 'start': 1438.558, 'end': 1468.285}, {'text': " so that he can do it today. But in that case, we cannot test 82. I think we should just pending, just waiting for the firewall, the network squad to implement the firewalls. Just be safe. That sounds reasonable, yeah. Okay, so basically we're still in deployment phase.", 'start': 1468.916, 'end': 1495.606}, {'text': " Okay, because I just saw it and wanted to click around, but I cannot really use it because it's still like, please buy it now. And if you buy it now, you would need to install the agent. But the agent, of course, is not available yet. So maybe you need to update it here that you can download it. But this is not available yet. Because even after you have the agent on at least one server, you can start using it, right?", 'start': 1498.234, 'end': 1527.773}, {'text': ' Because if I click on upgrade now, I come to please install an agent and then I can enable it. But okay, it is still in deployment phase. Yes. And I guess Susanna for testing, the question would be if we need to involve somebody from the compute or container squad if they want also to test or if Lukas can cover everything.', 'start': 1529.667, 'end': 1557.619}, {'text': ' because it has a lot of functionalities and a lot of things to test like insert the agent, then download some vials and see if it is cleaned and if it is showing on the dashboard and so on. So it is a lot of things to test.', 'start': 1557.91, 'end': 1578.933}, {'text': " Yeah, maybe we can ask them because I don't know if it will be Lukasz or Zoli testing that. If they need, I don't know, any test cases or if that was already provided by Huawei, I don't know. I don't know. I just know we need to be careful because customers installed an agent on their machine with, I guess, admin permissions and it has a lot of permissions and a lot of features which we would need to test.", 'start': 1579.275, 'end': 1609.121}, {'text': " Okay, but great that it's ongoing and already visible on the dashboard. I don't know when we have the next system demo, but there would be nice if we can show it, at least the dashboard, even if it's not functional-wise working. I don't know when the next system demo is.", 'start': 1610.247, 'end': 1632.005}, {'text': ' We have only two, so they realize then the system demos are not very efficient always, so we have only the final and only one and a half. Okay, on the 8th of August, I see it. Yeah, then we can show it. Okay, next thing for the business demands, I have opened this thing. So, Lena, can you do me a favor and close this demand or this', 'start': 1632.722, 'end': 1661.425}, {'text': " ticket where we said we don't want to do it. This is a strange ticket where we had some kind of misunderstanding. Gulina asked if we can send the logs of the dedicated WAF to this IP and Tibor said, yes, we can configure that, but then it just turned out we can configure it only for the whole OTC for all tenants.", 'start': 1662.654, 'end': 1691.749}, {'text': " But that, of course, we don't want to send all customer tenants the locks to this IP, but would only be for one customer. So the answer would be we cannot do that. The customer can use lock forwarding to forward the locks from the WAF to LTS and then to OBS and with that one can grab the locks from his WAF. Okay, we'll do that.", 'start': 1692.329, 'end': 1721.732}, {'text': ' Otherwise this one would be a total mess of our standard and we do not configure for one customer special things. So that one you can close because if you go to the WAF, you can go to', 'start': 1721.8, 'end': 1750.862}, {'text': ' configure logs, then you can say you can forward the logs to LTS and then you can access it and then download it from the bucket. I guess there is also some head center entry for that one, how to do it.', 'start': 1752.09, 'end': 1769.855}, {'text': " Okay, then we have some enabler topics open. It's about the upgrade of anti-DDoS. Do you know if we are already working on it?", 'start': 1778.643, 'end': 1796.049}, {'text': " No. Ethan, is this day similar with the KMS, like pending for Daqian to do the upgradation? That's my question, yes. Susanna, do you know if we already can start working on that? No, this is responsibility of Chris and he didn't mention anything like that. I'll talk to him later. Thank you.", 'start': 1799.326, 'end': 1828.49}, {'text': " Maybe he is preparing that, but at least he didn't share anything with us yet. But maybe he is working on that. I don't know. Because it would be really nice to see the change log for both for the upgrades. So is it really a customer facing new feature or is it only back end? I am not quite sure. Nobody can tell me what the upgrade will include. That would be nice to achieve that.", 'start': 1829.531, 'end': 1857.193}, {'text': " And as a last thing, I have here the IP version 6 stuff. I saw there are some meetings from the network squad. You and Wolf, Susanne, right? Yeah, we both are. So it's Joshua and Tibor and myself. So basically", 'start': 1857.841, 'end': 1880.009}, {'text': " We've already got some answers from Huawei R&D that those services because platform WAF is now excluded. This is not needed. So Antivirus and BSG would need I think upgrade and R&D has planned this for end of December this year, which for us it's too late.", 'start': 1880.333, 'end': 1900.452}, {'text': ' So we have had some kind of TSI meeting when we come to some kind of conclusion that we would like to get it delivered soon. But of course for that we would need to talk to Richard and so on and so on. So I think this topic will be also mentioned tomorrow on TAS meeting. The question would be do we need to follow up this ticket here if you already are in this meeting series?', 'start': 1900.964, 'end': 1925.23}, {'text': " Well, I think not because as I said, Joshua and Tibor and myself, we are in the calls with network. Okay, because then I would need it, would delete it for the next, yeah, alignments here. If it's fine for you or because it's... It's fine for me. I don't know about Joshua, but for me it's okay. Do we have any other more enabler? Yes, you or what?", 'start': 1926.886, 'end': 1954.138}, {'text': ' Are we talking about BSG or are we talking about anti-DDoS? Susanna, I guess you mentioned both, right? For IPv6, we are talking about BSG and anti-DDoS, yes. So you want to put them together? BSG could deliver earlier.', 'start': 1957.688, 'end': 1980.708}, {'text': " I don't know. What Tibor delivered to me was that for both and I'm talking about IPv6, right? Joshua, are we talking about the same thing? Yes. Yeah. Okay. So from Tibor, I've got the information that for both is planned for end of December. Do you got the different information?", 'start': 1982.875, 'end': 2006.237}, {'text': " The RD says December is the time finish the delivery. The package is released earlier. Because that was exactly what we asked Tibor twice, if its patch will be delivered end of December or it can be already done. And he said the patch will be only delivered end of December, which would mean we can start somewhat mid of January. So I don't know.", 'start': 2009.189, 'end': 2036.067}, {'text': " You've got the clarification now. I don't know. Maybe let's wait for tomorrow and maybe try to gather as much information as we can. I'm not sure. I've got even the information in Zulip from TB. Like I said, if you want to discuss about that one here, I can also put it back on the agenda for tomorrow.", 'start': 2037.705, 'end': 2059.974}, {'text': " We got weekly calls with network. That's why I am asking. I don't want to have it duplicated. Maybe take it out of here and keep it in our calls with network. That's basically the whole list I have here. Are there any important things I should add or which we should talk about right now? I think, is that all?", 'start': 2062.09, 'end': 2091.305}, {'text': " No, I have a new topic, but if you have other things, then if it's the last topic, then I should bring this up. Yes, you can. So, RD is asking for CE firewall. Do we want to have it? They need the answer today. Yes. Yes. Yes.", 'start': 2092.602, 'end': 2121.698}, {'text': " So we do want to have it and we will try everything to do the delivery. Am I understanding it correct? On my side, yes. And Susanna, I guess also from your side, right? Okay. I think, yeah. We planned it for Q4, right? Yes. That's why I'm... It's pending.", 'start': 2122.125, 'end': 2148.899}, {'text': " I think it's fine. It's still on the roadmap and if everything will be going according to the plan, which means harder delivery and everything, I think we are ready to start as soon as we've got everything there. Okay, then I take that as a yes and until RD nothing changes, plan the delivery Q4. Yes, that's the current plan. Yes, as you can see on the screen.", 'start': 2149.241, 'end': 2173.387}, {'text': " We just don't know how quick we can put it then to the market. Like when we have the hardware, we don't know until when the first customer can use it, depending on security testing, Q&A and so on, like for every service. Unfortunately, currently we somehow take like half a year for a new service to be live because we have so many things to do.", 'start': 2175.896, 'end': 2205.077}, {'text': " because we cannot commit to have it live for customers this year. It would be nice. Don't get me wrong. The earlier the better. But it depends on security approval, QA and UAT and whatever does not work and so on. But sure, we want to have it, yes. So from our side you can give a yes.", 'start': 2208.029, 'end': 2234.821}, {'text': " Coming to that one for the roadmap, I also had an item, it is, where do I have it here? Yeah, Cloud Secret Management Service, which we had discussed like, I don't know, half a year or a few months ago. It's basically a part of data encryption workshop. Here this is", 'start': 2239.258, 'end': 2266.459}, {'text': ' you basically on Huawei Cloud have the Data Encryption Workshop and one part is KMS which we already have. And we discussed this Cloud Secret Management Service. Is that something you can confirm that we can receive that somewhere next year? And the demand ticket is as the package you deliver at the end of this year.', 'start': 2267.466, 'end': 2296.237}, {'text': ' December. Oh, okay, nice. Then I noted down. And by this mean usually is somewhere in the middle of July or somewhere in February, usually.', 'start': 2297.125, 'end': 2322.824}, {'text': " But it's not like it always happens. But usually, you have some sort of delay. Because in December, everyone has the holiday. In January, everyone in China has a holiday. Yeah, sure. No problem. It's just about rough timing. We don't need an exact date. More like which quarter, like starting next year. I just wrote down.", 'start': 2324.275, 'end': 2350.299}, {'text': " Because as you may know, we are implementing currently a function graph on, I don't know, compute or container side. And for the, let's say, whole customer experience, the secret management would be a nice addition for the whole use case. But, okay, I'm starting 2024. That's nice. Great. So then we have on the, let's say, pipeline,", 'start': 2352.09, 'end': 2380.265}, {'text': " ERM, DBSS, HSS, then Cloud Firewall and then CSMS. So basically packed for the next few months. That's great. Thank you. Okay. Anything to add? Any topics? Nothing from me. Thank you. Great. Then I would say thank you.", 'start': 2380.776, 'end': 2410.145}, {'text': ' and talk to you soon. Thank you, bye bye.', 'start': 2410.742, 'end': 2432.449}, {'text': ' Yes, just like what I said and what I wrote in the email, they are very dissatisfied with our API. I know. Yes. Because I think it is very bad. I also asked our people to intervene and take a look. But he analyzed a few categories for me. He said that some of them are considered unreasonable to analyze, and some of them are that the API design of the product itself is unreasonable.', 'start': 2432.602, 'end': 2453.865}, {'text': " But he didn't calculate a ratio or something like that. Can we do this? We have a meeting on Wednesday. It's about DBSSGA. Do you want to explain a little bit about this? Yes, because I feel like I can't do it. I can't do it either. What this thing needs is... Let me tell you about the API responsibility field first. Okay, let's talk about this.", 'start': 2454.292, 'end': 2481.613}, {'text': " We mainly teach two types of documents. One is API and the other is user guide, right? The user guide includes product introduction and so on. You can find us for all the questions about URM. It's just a document written by ourselves. As for the questions about API, it's not written by us, it's written by the developer. In the YAML file interface developed by the developer, the explanation for these is the API document. We don't have any right to modify it. We can only say that we may raise opinions and they have to change it.", 'start': 2481.903, 'end': 2508.712}, {'text': " That's what it means. The responsibility of this document is on them. Because we don't understand API interface. So that's why it's hard for me to control it. Because this document is not for us to write, not for us to control. But we do have the information from our hands. So I can't just let it be like this. The problem now is... That's why I said we need to find ISL or DDSS. Isn't it Song Yucheng's responsibility? Yes.", 'start': 2509.206, 'end': 2535.367}, {'text': " I want them to analyze this question. What kind of questions do you think should not be brought up? Should we ask them? Let's clarify this question now. We have a meeting on Wednesday. He wants to clarify everything at that meeting. Yes, but shouldn't Song Yicheng do an analysis of this issue in the early stage? What kind of questions do you think should be brought up? Otherwise, I don't know what to say to him when I go up. I don't understand their questions either. It's always been handled by them.", 'start': 2535.401, 'end': 2562.944}, {'text': " So what I'm trying to say is, should we pull them out now? Yes, yes. This is a very urgent matter. I also have a headache. Because I've done so many ZDN businesses, and we're doing UAT, but there's not a single business like DBSS's API. There's been a lot of problems in so many rounds, and there's been no end in sight. This morning, I also found a data interface person, and then we sent someone over here who has done ZDN, that is, WAF delivery. He has some experience and some UAT advice.", 'start': 2563.251, 'end': 2588.131}, {'text': " And then tomorrow, we'll take some time to look at DBSS and VIX. From a data perspective, we'll see if there are any problems that the R&D team didn't realize. That's what we thought. Who is SEL? DBSS. Li Peng. Li Peng, right? Yes. Okay, we're in a meeting.", 'start': 2588.524, 'end': 2615.162}, {'text': " I also think that if there are any questions that you think should not be brought up again, you should clarify it at the meeting. Why are they all in a meeting? Are they in a group meeting now? They are in a group meeting. I don't know if it is. Let's play that one. A little later.", 'start': 2619.206, 'end': 2645.674}, {'text': " Yes, it's fine to have a discussion group. Bring Li Peng and the relevant people in charge together and talk about what to do. Make an appointment with them. Make it clear. Just say that the first line has already... Oh, yes, this is an obvious attitude. Four people will vote. Wow, I think this is too bad. Even if we don't look at the problem and continue for so many rounds,", 'start': 2646.596, 'end': 2668.507}, {'text': " I don't think that's a problem. That's true, that's true. Because I can't see it now, and DeDian sometimes checks with us, and sometimes it's hard for me to tell which ones are checks and which ones are real. So I have to, before I refute, I have to, now it seems that we really have a problem, then I can only... Because it, because the number is large enough, I don't think it's necessarily a problem of checking. It should be that there is a part of confirmation that is a problem, and there is a part that may be a problem of communication.", 'start': 2669.189, 'end': 2697.142}, {'text': " We've been through a lot. I think they are very strict. Some of them may have a different way of thinking from us. They are very strict. But I don't think they ignore it. And we can explain some of the problems to them reasonably. We can communicate with them clearly. We haven't met them and they forcibly say they don't agree with us. They will ignore it. Only let us push them back in line. I see.", 'start': 2697.517, 'end': 2723.029}, {'text': " Let's set up a discussion group. Let's make an appointment. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's set up a discussion group. Let's", 'start': 2723.285, 'end': 2751.613}, {'text': " Okay, I'll hang up now. If you need to talk to someone, including information, I think it needs to be listened to. I'll get someone to go to the meeting. Okay, bye bye.", 'start': 2752.09, 'end': 2766.749}, {'text': ' Mmmmm.', 'start': 2781.374, 'end': 2804.36}]
It appears you've shared a transcript of a conversation likely from a meeting or call where various topics and issues were discussed among team members. Here's a summary and key points extracted from the text:

- The discussion seems to revolve around ongoing projects, with mentions of ERM (Enterprise Risk Management), DBSS (Database Security System), HSS (Home Subscriber Server), Cloud Firewall, CSMS (Customer Service Management System), indicating diverse areas of work.
  
- There's a note about being busy for the next few months due to these projects, suggesting a packed schedule ahead.

- Dissatisfaction with an API is mentioned, possibly due to functionality or performance issues. This dissatisfaction seems to be expressed by Dedian, who might be either a client or a stakeholder in the project.

- A meeting is referenced where Li Peng and other relevant personnel are present, indicating the need for coordination among team members. There's also mention of a group discussion that needs to be set up to address certain issues effectively.

- The transcript ends with arrangements being made for a follow-up call or meeting and the speaker indicating they will send someone else to listen in on future discussions regarding information matters.
  
- Communication about problems appears to be a point of focus, as there's an emphasis on explaining issues reasonably and communicating clearly. This suggests that misunderstandings might have occurred in previous interactions.

- It's also noted that while some issues may stem from differing perspectives or ways of thinking, the team is encouraged to not ignore these but rather address them head-on through open discussions.
  
Overall, this seems like a typical dialogue within a project management context where multiple stakeholders are coordinating efforts and addressing challenges as they arise. If you need further analysis on specific parts of the conversation or have any questions regarding aspects of project management, feel free to ask!torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../root/.cache/torch/whisperx-vad-segmentation.bin`
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmp6tb4x59p
临时文件夹地址：./tmp6tb4x59p
上传文件的地址：/tmp/gradio/f69e80020c6068519fc7bc66f4902e99577d0159/20240510_100652.m4a
base name 20240510_100652.m4a
No language specified, language will be first be detected for each audio file (increases inference time).
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.
Detected language: en (1.00) in first 30s of audio...
[{'text': " I just want to quickly go over the cases that we have highlighted from Huawei's side and also give you the chance to give a quick Q&A on that specific cases. So if you already have some questions in mind or you're interested in specific things, then we can go over that. And this is where I will also just jump into directly. So we have our principal AI platform approach.", 'start': 0.009, 'end': 26.101}, {'text': " which you know is Model Arts. It's continuously updated now. This is on the one hand side, of course, necessary to meet the market demand, to have the updated frameworks available. On the other hand side, it's also necessary to have the updated foundation that Model Arts is to all of those services, right?", 'start': 26.101, 'end': 43.985}, {'text': ' Because finally all of those services somehow rely on ModelArts for training, inference, processes and the according infrastructure provisioning. So ModelArts is really like the core cornerstone from all our AI activities of course.', 'start': 43.985, 'end': 60.282}, {'text': ' Then the OCR platform, we already have that available. Of course, this is also subject to be updated. We have certain scenarios discussed, for example, with our license or ID recognition examples.', 'start': 60.725, 'end': 79.258}, {'text': " where anyhow according training data is needed. For example, if you consider your passport that is globally standardized, right? So normal passports is relatively easy to realize on such service. If you think about your local ID card, for example, the German ID is different from, I don't know, the Hungarian ID or the Chinese ID, because there is not an actual standard. Even in the EU, it's not fully standardized. So what I did, for example,", 'start': 79.565, 'end': 108.968}, {'text': ' I just searched for public training data for IDs and some governments offer that. So for the Netherlands, for example, you can easily get training data. And I contacted also with the German Ministry of Interior to ask them about training data for Germany. And guess what?', 'start': 109.462, 'end': 126.596}, {'text': " No training data available. And if you don't get that from the German Interior Ministry, then most likely you will not get it for free anywhere else. So that's also then of course for us a subject matter.", 'start': 127.073, 'end': 143.575}, {'text': " The meteorological model example, I think it's kind of a prominent case, I also presented on that earlier, and I think this is also the candidate where at least the inference part to make weather predictions is the closest, and I have, even if no final decisions are being made yet,", 'start': 144.104, 'end': 164.787}, {'text': " I have the feeling that this is the most realistic to be released in a rather short time frame. And therefore it's also most likely that we will find a customer for that because we usually have this chicken and egg problem in our discussions with Huawei and TSI.", 'start': 165.247, 'end': 180.93}, {'text': " I think we are all aware, but finally we need something that is available in front of the customer and also the training data that is being used from our side is, yeah, weather is more or less standardized globally, right, so the functions are the same. The weather training data is available in open source, so that's also very easy to justify for the European market.", 'start': 180.93, 'end': 201.698}, {'text': ' We have dependencies on service level, but more important, if we want to do fine tuning and training of such a model, we need a serious amount of GPUs. I think we are all aware this is under discussion and should be solved then. TFDS is this train defect inspection.', 'start': 202.21, 'end': 221.254}, {'text': ' I understand that there are customers in Europe which T-Systems is in contact with. I think Holger also meanwhile mentioned that he will have direct interaction with potential customers for example in Switzerland. If this is successful we will see.', 'start': 221.869, 'end': 239.548}, {'text': " Anyhow, it's a relatively complex case. It needs localization, so data fine-tuning. It needs an end-to-end solution. For example, you need local cameras, network integration and a service provider that maybe also does software integration with the system of the train operator.", 'start': 239.548, 'end': 258.78}, {'text': ' So we are talking here about projects. My colleagues from R&D told me, I think Joshua, you work in this department as well, right? So they usually have like years of cycles in their projects. Yeah, the project started in around 2020 and even right now they still keep developing these servers, keep adding new data.', 'start': 258.882, 'end': 286.015}, {'text': " And also the according cases that are possible there are frequently working. You can see the red highlighted use cases services here are those which Huawei just highlighted to be very interesting. But you can see TFDS in this case is also challenging. So it's always a matter of balance of making it available in a reasonable time with a reasonable effort and also then finding the right customers. So this is what we are doing in parallel.", 'start': 286.903, 'end': 316.288}, {'text': ' Also the digital human, digital human brain approach, which consists of large language models and also digital human is basically a fancy thing that is anyhow', 'start': 316.988, 'end': 331.698}, {'text': " I would say in a very challenging market situation. So, if you find offerings on AI, most likely they will be also from this domain. And also, TeSystems has already partners in these issues and Deutsche Telekom as well. So, I think this is something because it's also very difficult to monetize on. Everybody likes it as a marketing inclusion to show it, to show how fancy AI is.", 'start': 331.834, 'end': 356.783}, {'text': " But finally, monetizing from that, for example, in broadcasting domain is something that works, for example, in China. So, we see that public television or events facilitators, they use this kind of technology in China actually, but the real world usage and the really GA usage in Europe is not there. So, if you want to monetize on this now, I think the judgment is that it's not possible, anti-systems will not", 'start': 356.783, 'end': 385.896}, {'text': ' kind of put work to you guys that finally cannot result in monetization.', 'start': 385.896, 'end': 392.585}, {'text': " but in parallel they are working with partners. I think here is one like HeronOS. This is part of the digital solutions. I think they don't name it here, but it's part of digital solutions portfolio. So, if you want to have information on that, it's by accident I know the CEO pretty well for years already. So, if you're interested in this as well, just let me know. I'm happy to share the additional information.", 'start': 393.012, 'end': 416.766}, {'text': ' Of course, I will not cover now other information here, but I will share the slides, as I said, so you will find all the argumentation and also the partner scenarios here with Develop, for example, where they make also a good progress with your internal LLM hub. I think this is T-Systems initiative, right? Yes, I believe behind Develop is IITS, probably.', 'start': 417.432, 'end': 444.957}, {'text': " But yeah, it's the systems. Yeah, and this LLM Hub thing, of course. Yes, LLM Hub, definitely the systems. Yeah, okay. You can also find a reasoning here, which is about maturity, revenue potential, realization effort and the Pangu technology. Obviously, here's no Pangu involved. Other cases where, for example,", 'start': 444.957, 'end': 469.224}, {'text': " Let me find one, go to the slides. For example, this railway inspection case, yes, Pangu is involved. Realization effort is very high, revenue potential is, I would say, medium, and idea maturity is already quite far. But that's kind of, yeah, what makes the actual, yeah, waiting.", 'start': 469.616, 'end': 490.452}, {'text': " how this case is being weighted towards other cases. And that's also why we partially have this meeting today, because it's not only about the weighting of this existing list, it's especially also about what is not on the list. And this is also why we are talking today, because we are not limited to this list.", 'start': 491.578, 'end': 514.701}, {'text': ' This kind of additional functions, features, where we want to stay in contact with you is about reasoning. Reasoning by how far we can use the Huawei portfolio and also best practices and technology to make useful functions, features, services available that we can bring into the market and make use of.', 'start': 515.06, 'end': 542.483}, {'text': ' and not bind ourselves only to such large initiatives that we are doing here. So I think doing both in parallel is what is necessary. And yeah, then I would be happy to start also Q&A now. And yeah, I already get all the finger signs from Hector. Thomas, stop talking. People want to see some technique. Anyway, colleagues, please, if you have any questions, feel free.', 'start': 542.483, 'end': 569.616}, {'text': ' Hi Gabriel. Can you go back to that list? This one, yes. So, out of all of this, which other use case is a complete baked product, like the methodological service? So that one, we discussed that this is the most', 'start': 574.701, 'end': 603.456}, {'text': " Most likely really an individual service, but we already run it on OTC. Is any other use case like that on this list? It's a product? Yeah, actually the AI Drug Discovery Platform and the AICC are most product-like from my point of view. I don't know, Joshua, if you have another point of view, but I was into this AI Drug Discovery case, for example,", 'start': 603.729, 'end': 630.35}, {'text': " Unfortunately, it's relatively complex, also language-wise, so it's not available in English language, as far as I know, in a productized version.", 'start': 630.35, 'end': 644.343}, {'text': " Chinese only, as far as I know, and Arabic, because one of the large projects is Arabic. And anyhow, it's like a product, so you can use this as a standalone product for drug discovery. And AICC, which is a contact center, it's like a telephone center, a support center solution, I would call it.", 'start': 645.128, 'end': 670.128}, {'text': " that can be used right away, but in its nature is also that it's bound to language, right? And this NLP model and its training background and the surroundings are also not in a GA level where I would say that it's for localization for Europe productizable, basically. I'm sorry, did you say the number 6 is not supported English?", 'start': 670.128, 'end': 695.265}, {'text': ' No, AI drug discovery.', 'start': 695.981, 'end': 704.991}, {'text': ' product-like topics that have a verticalization included already and can be used by those customers straight away. Other stuff like for example our enterprise knowledge base or also industry CV, they are more like a framework that gives you kind of a specific functionality but it needs still a lot of', 'start': 705.196, 'end': 726.715}, {'text': " professional service or integration and project background to make it actually work. So I would not consider it basically a SaaS model. Even if it is consumed like a SaaS, but it needs a lot of surroundings still to make it work end-to-end. Does that answer the question? I was really wondering about this as well. So which of these can be really, let's say, in quotes, easily solved?", 'start': 726.715, 'end': 755.879}, {'text': ' like just giving the customer an image or working together with the customer on developing an image. So that, yeah, that was my question, thank you. Yeah. Just one comment here, for example, this enterprise-grade knowledge base or digital human brain, for that, is NEX somewhere to develop by your colleagues to like have one use case', 'start': 756.34, 'end': 786.237}, {'text': ' for the demo or whatever. So, for example, like medleet for the OTC app center or whatever, and integrated with some mobile application or whatever. So, is there any already implemented demo in the Huawei side? Yeah, we have. Of course, yeah. So, we can exchange on that, if you like, Sjoerd.', 'start': 786.647, 'end': 814.974}, {'text': ' Cool, cool. Thank you very much. Okay, having talked about demos, then I would like to hand over to Joshua, because this is also what he is going to have in his part. After my long PowerPoint talk, he will get into some technological cases and also do some demo. So Joshua, stage is yours. Okay, so let me share my screen.', 'start': 816.271, 'end': 845.111}, {'text': ' So this is my agenda. So first I would like to show a small demo, OCR demo for Passport. No driverless, unfortunately. Driverless is not available. So just let me quickly log into the...', 'start': 856.869, 'end': 884.906}, {'text': ' our graph and see.', 'start': 885.555, 'end': 893.626}, {'text': " So OCR for passport. We all know what our passport looks like. I have to correct something. The passport for each country is relatively slightly different. So our OCR's mechanism to", 'start': 929.258, 'end': 957.671}, {'text': ' to recognize this passport is now from the, yeah, this is a sample passport.', 'start': 960.691, 'end': 969.224}, {'text': " If you have yours, you can compare it with my Chinese passport. I don't, yeah, the online cannot see, but you see we have two columns here, and here you only have just one column. It's relatively a little bit different. So our OCR's mechanism to recognize, subtract the information from this passport is not from here. It's not a subtract the information from here.", 'start': 969.838, 'end': 998.387}, {'text': ' But you see this has a machine code down there. You only subtract this part and press it so that you can get the correct information. Obviously, you see this is all in English letters and this is a digital number. So the OCR can only recognize those things.', 'start': 998.387, 'end': 1026.92}, {'text': " So I will just give you a quick demo. This is Huawei's Hong Kong region.", 'start': 1027.654, 'end': 1041.613}, {'text': ' And we have the experience center, everyone can register the Huawei Cloud account, just create a free one.', 'start': 1041.971, 'end': 1057.841}, {'text': ' and go to the experience center and it should be available this experience center is for free you can just click the card OCR and you can see this also have another', 'start': 1057.841, 'end': 1076.101}, {'text': " Oh, Indian passport. Yeah, you can see it's way more different than the European one and the Chinese one. But nevertheless, it subtracts the machine code here, and the result will look like this. It will pass this machine code to here. We can also just quickly upload", 'start': 1076.391, 'end': 1104.087}, {'text': " The Italian passport I just showed you before, you see, you will quickly subtract the correct information. So that means the solution and you don't pay for the image.", 'start': 1105.23, 'end': 1124.104}, {'text': " I think you just read the last two rows. In these last two rows, you interpret the content of the fields. Yes, that's correct. And that's also the globally standardized part. Yes, that's the only standardized part in the passport. You can see the MDNs.", 'start': 1125.776, 'end': 1144.462}, {'text': " India's passport, Vietnam's passport, way more different than each other. I think the most difficult part also in this document checks is also like checking validity, right? If it's a fake ID or not, I guess it's difficult. I think it's not part of the service, right? Yeah, not part of the service. That's another story. I think Huawei have similar service, but I don't think I have this on my hand.", 'start': 1144.462, 'end': 1169.718}, {'text': " Yeah, no problem. I was just thinking because having to read from this machine code is relatively easy, right? Yes. But yeah, I can also just put a blank piece of paper then there. I don't need a passport for that, right?", 'start': 1169.718, 'end': 1186.817}, {'text': " I've never tried that, but I don't think that will work. Maybe we fake one and try it, just out of curiosity. Yeah, I think if it looks like this, then I think it will work. Because if you watch closely, you'll see this number is a little bit blurred. This is already a fake one. Okay, cool, that's our first demo.", 'start': 1186.817, 'end': 1213.78}, {'text': " I have the same feeling. I mean, if we just read the last two rows, I don't see any value on this solution because we're just reading text that is already there. So if you, for example,", 'start': 1214.292, 'end': 1231.715}, {'text': ' edit that image that you have and just delete all the image with all the signature and date and so on and just save it, I mean just set that with another color you can use whatever color you want the image size will be still the same because in OCR as far as I know the image size should be always the same with the same pixel size and you import this new image with all of this you will get always successful now the question is', 'start': 1232.022, 'end': 1257.807}, {'text': " about how we can also preserve with this OCR kind of security check that we know what you are scanning is correct with the content of the other fields. I mean, that's not part of OCR, I know, because OCR is just reading.", 'start': 1258.08, 'end': 1275.981}, {'text': " Yeah, just turn the image to the letters. Yes, that's what you do indeed. So if you say in the real business case, usually the company will buy several OCR servers. They will buy Huawei's OCR, they will buy Amazon's OCR, and use all of those OCR servers, because OCR servers are quite relatively cheap, and they subtract the same document and compare the result.", 'start': 1275.981, 'end': 1305.094}, {'text': " do not match that the business progress show already know that something is wrong here and they will compare by human, let the human do the final decision to get what's the correct answer for this. Does that answer your question? Yes, yes. Some questions about the OCR because the OCR test is done. Guys?", 'start': 1305.094, 'end': 1333.626}, {'text': ' Can you show us the current features of OCR on Huawei phone? I mean the features, so what other type of OCR is available? Oh, sure. You mean...', 'start': 1337.892, 'end': 1353.609}, {'text': " We have tons of OCRs here. Certificate OCR, Received OCR, Industry OCR. I don't know what the Industry OCR here means, but currently it's not available in Hong Kong region. I think in the hub center there is a table. Yes, they have a table.", 'start': 1354.497, 'end': 1375.845}, {'text': " And in this region, I chose this region simply because you have the experience center, it's for free. So everyone can go there and try it. Just register Huawei's account on the Hong Kong region and that's all. Okay. And currently from the available options, is there anything that could be used internationally?", 'start': 1376.305, 'end': 1400.52}, {'text': " that doesn't require a new model for the European IDs or something. So anything that could be reused in Europe.", 'start': 1400.811, 'end': 1410.384}, {'text': " The passport is a good example. Like I mentioned before, the machine code is standard globally, so they should not have any problem. But for the rest of those, I don't think so. Because each country, even inside Europe, each country has their own format of the IDs received and all other stuff.", 'start': 1410.657, 'end': 1440.247}, {'text': " How complicated is it to add something new? Let's say we in T-Systems would like to integrate our own ID badge and try to subtract the information from that.", 'start': 1440.538, 'end': 1456.852}, {'text': ' Would this be possible? What is the effort behind? For this question, we do have a table that requires what the sample looks like, how many samples are needed, and if you want to add something customizing, you can prepare those data, send it out to our R&D. Our R&D will train you a new model and put it into a new service and only dedicated for the OTC.', 'start': 1457.551, 'end': 1487.227}, {'text': " and I will share this with you later. And this can be privatized? I mean, by listing? Yes, it could be by listing. Okay, thank you. One small question about this, I'm just really curious,", 'start': 1487.227, 'end': 1509.821}, {'text': ' that you already have offering in public cloud, which of them are doing', 'start': 1511.408, 'end': 1521.271}, {'text': " what are the best used, I mean you are offering in this case some kind of solution that is based on templates, ID, pass, license driver, whatever, and you are so specific that you have this solution in Asia, so it's not just China,", 'start': 1521.493, 'end': 1543.848}, {'text': " Vietnam it is from country to country the same solution different train because the documents change from yes in general which of these solutions that you're offering is doing", 'start': 1545.64, 'end': 1560.811}, {'text': " If we are just talking about revenue, I'm afraid none of them is doing a very good job on the revenue-wise. How did OTC, the squad, make money doing the dedicated service?", 'start': 1562.022, 'end': 1580.572}, {'text': " big customer in the bank, the biggest bank, they have a lot of bank paper. We do a dedicated customized model for them and they pay us a lot of money. That's how it works. For the professional service, not the OCI itself.", 'start': 1580.572, 'end': 1601.408}, {'text': " Yeah, the professional servers for OCR. They're still using the OCR model to recognize stuff, but they put a lot of strategy to make sure it fits the particular template of the bank. That means OCR itself is useless. You can only wear it one way.", 'start': 1601.903, 'end': 1622.227}, {'text': " If you have it empty, I mean, from that point of view, I'm not saying that this service is not worth it, it's useless at that point, but you will get the money by using dedicated solutions for each customer and while listing the solution for each customer.", 'start': 1623.148, 'end': 1642.295}, {'text': ' We have a bank, we are doing these templates for them, dedicated, so one bank is asking for 20 templates because they have 20 different documents and you deliver it. Okay, professional service. They have a solution and they start using OCR because the solution is running on OCR, correct?', 'start': 1643.251, 'end': 1661.715}, {'text': ' And then the other industry like insurance company have their own business use case and do also the professional services, deliver all that training and they can use it in their Huawei Cloud and this is another specific business. And so OCR can grow.', 'start': 1661.817, 'end': 1682.312}, {'text': " Otherwise there is no way, right? Because it's the same as we believe on the OTC. Half right, half wrong. Yes, indeed. Because you can tell the bank's document is way more different than insurance's document. But they can always use the general table, general OCR to try it first.", 'start': 1682.312, 'end': 1706.971}, {'text': ' We do the dedicated model for them simply because they think the accuracy is not high enough.', 'start': 1707.858, 'end': 1714.326}, {'text': " So we do the dedicated service for them, professional service for them. If they try the general table, general OCR, and they think it already fits their requirement, no problem, it can sell very well. So it depends on the scenario, case by case. So that means you have two kinds of OCR solutions. One is try and see if it's working with this text and table.", 'start': 1714.718, 'end': 1744.002}, {'text': ' And the other one is, if the level of accuracy is higher, then you have for that professional services that they can use to be dedicated to solve that specific use case. But in general, what you want to say, every customer will be able or is able to use this text and table and it should work. But for a specific case, the other solution, correct? Yes, I just want to show you that the other solution is available.', 'start': 1744.002, 'end': 1771.715}, {'text': " The name is what? Professional Service? Professional Service for OCR. I think Gregor and his team also built something using the OCR. They can use the OCR pretty well to check our Huawei's documents. Whether it includes Huawei Cloud, Beijing Force, something like that. This is also a very classic case for the general OCR. Okay, perfect.", 'start': 1771.715, 'end': 1801.34}, {'text': " Okay, next. Any other questions? Okay, next demo, please. Okay, next demo. Let me see what's the next. Ah, CodeArt Snap. Probably this is a new service. Probably nobody has introduced this one before. Yeah, so let me just quickly give us", 'start': 1801.834, 'end': 1827.978}, {'text': " introduction of what Kodas is. I'm not going to go over this slide by slide, so I will just be quick because there are just some number shows how good our Kodas is. I will leave these slides to you and you can read it afterward.", 'start': 1830.401, 'end': 1854.036}, {'text': ' So what is Codasnap? You all used ChargePK before, right? Presentation board? Oh, yeah, yeah.', 'start': 1854.292, 'end': 1866.305}, {'text': " you all used the chat gpt before, right? You know the chat gpt can do the coding. You're asking can you help me write a python function of how to sort", 'start': 1868.933, 'end': 1885.026}, {'text': " sort a list or run your data structure of what you give a demand and it generates code for you. And most of the time it's runnable. So this is the code rsnap. It's only dedicated for writing code. It's using the large language model, but it's not for chatting, it's for writing the code. Okay, very simple. You have like eight major features.", 'start': 1885.845, 'end': 1913.404}, {'text': ' Well, actually, we only have four right now, but I will show you later. Code generation. Yeah, this is a feature. You see, code generation is very easy. You give your word and generate code. RDE knowledge is like a chatbot. You ask a question, it answers you.', 'start': 1914.411, 'end': 1940.998}, {'text': " It gives you the answer, but it's dedicated for this development knowledge, like how do you write this, how do you connect to this world, how do you set up your policy, those kind of questions. Unit test generation, I believe we all know that, right? Generated test cases is the subset of this one, the first one called generation. And co-explanation,", 'start': 1942.585, 'end': 1969.991}, {'text': ' Like you choose a code and it will tell you what this code is doing.', 'start': 1971.118, 'end': 1978.831}, {'text': " What is this code designed for, right? Yeah, designed for. How is this processed? How is this doing? So you have existing code? Yes, you already have existing code, like you inherit this code from your previous R&D and you don't know what he's writing about, you can use this one. So the guy that left the company, yeah? Yeah, or get fired. Comments and debugging.", 'start': 1980.145, 'end': 2006.118}, {'text': " Yeah, that's all. Comments is like writing the comments because somebody is very lazy and don't want to write the comments and they can use this to write for you. Debugging, we all know what debugging is. You give it the error message, it tell you which part of the code gets wrong and give you the suggestion to how to fix it. Yeah, that's all. Any question? If not, I'll show you the demo.", 'start': 2006.647, 'end': 2034.872}, {'text': ' The rest of them is very...', 'start': 2035.213, 'end': 2041.903}, {'text': ' I have one question. Sorry to interrupt you. What is behind this CodeArt snap? Is it an open source solution behind that? Or is it a Huawei design solution? We have two versions right now. Currently, we have two versions in parallel. One is using the open source, which is Colama 2. And one is Pangu. And I think for OTC, we are only available for Pangu.', 'start': 2042.329, 'end': 2070.862}, {'text': " Oh, no Llama. No Llama Code 2. Llama Code. Code Llama. Code Llama. Okay, I know another competitor for it. It is called StarCode 2. Probably you hear about it. Star what? StarCode 2. It is open source. It's available. You can install it in LM.", 'start': 2071.323, 'end': 2097.739}, {'text': " And what it does, it supports 600 programming languages. And with it, you can do some activities. I didn't test it until now. I know that it's there. There is, I think, they offer three different versions. One is three, then seven, and 15 billions of tokens. And the biggest, of course, supports 600 programming languages. The smallest only uses, I think, 100 or something like that.", 'start': 2097.739, 'end': 2127.671}, {'text': " Nevertheless, it's closely to this solution that you're presenting. That is the reason that I'm just thinking about if you already believe that it's something similar like this. So I can show you this. It is called Starcoder 2. I do know they have a lot of similar open source solution for it. I do know that.", 'start': 2127.671, 'end': 2156.561}, {'text': ' And we are... Is this product already available on Huawei Cloud? In the beta mode, yes. And this is running on Model X? No. No? Surprise, no.', 'start': 2157.159, 'end': 2184.377}, {'text': " How is this model licensed? The one in the World Wide Cloud, the commercial models? Put down what? The billing for this stuff, for... Billing? Yeah, currently it's beta mode, so it's free.", 'start': 2187.005, 'end': 2205.947}, {'text': " I don't know. But the building issue is never our concession, right? Because OTC makes its own building system, right?", 'start': 2206.715, 'end': 2222.551}, {'text': " You charge whatever you want. You always have the right answer for that. I mean, as always, you are right Joshua. We will give a suggestion from Huawei side, but the system is free to do whatever they want. But I guess Matthias was just interested to see what our understanding is, right? So what we think the charging model will be. I do not know. I'll be honest. It's in beta mode. It's for free. And currently,", 'start': 2223.302, 'end': 2247.841}, {'text': ' It just let you use it for free and charge you nothing. For free, it does not explain the license. Oh, license. Sorry.', 'start': 2248.268, 'end': 2259.206}, {'text': " I would like to understand the license of the model you're providing. But they are using Pangu also. It's using Pangu, so it's cross-sourced, so they don't have this license stuff. I mean, it's included because you are the owner of Pangu, right? Not really, but I will get to you later. Can I...", 'start': 2259.667, 'end': 2288.319}, {'text': " I guess it's a commercial license, so we can just use this model via an API, but we cannot download it and use it on our own, right? Yes, I will show you the demo later. You cannot download the model, you cannot access to the model directly, you cannot train the model, you only use the model via API. Does the model support ARG? That means we can add some different", 'start': 2289.241, 'end': 2317.995}, {'text': " Yes, indeed, it has some RAG technology there, but it does not allow you to customize your own knowledge bases. Like I said, it's more or less like a cloud server, so you only use it", 'start': 2318.831, 'end': 2342.995}, {'text': " Yeah, but if I have an open source model, for example, I can do ARG, I can put my own data in it. And when you say I can modify it, but you cannot use your own data, that is something I don't understand, sorry. No, no, Matthew, wait. I think with this solution, it's just you have to use this model, it supports only use code. Code generation or documentation... No, it does not support ARG.", 'start': 2343.933, 'end': 2371.698}, {'text': " Is he talking about R-A-G or G-A-G? What's a G-A-G? He is saying R-A-G, so retrieval augmented generation. R-A-G. R-A-G, yes.", 'start': 2371.937, 'end': 2384.138}, {'text': " Yeah, I know RAG, yes. In SAI, you have some RAG solution. Indeed, but like I said, it's a cloud service. It does not allow you to customize this one. It's more or less like OCR. You say you can channel OCR model yourself. Doesn't really... I don't really think so.", 'start': 2385.299, 'end': 2409.514}, {'text': " I checked also for the charging model. So what they do most likely is going to be a subscription model per user. So you have something like $6 per person per month to have this DataArts, this CodeArts in use. Do you happen to know... You have explained now that it's in Mango?", 'start': 2410.896, 'end': 2440.265}, {'text': " You have explained that it costs money per API call or per NAID or for whatever. But do we have a license for this model? This model is not originally open source, so there is not a license per se. If you talk about a license to use the code that you are creating, this is not up for discussion. You don't need a license for that. Okay. Okay, got it. I just need to understand that. Thanks.", 'start': 2440.486, 'end': 2468.626}, {'text': " it does not have the... the model itself doesn't have the license because it's not an open source model so you don't need a license to use it but to use the servers, you indeed have... Every code somebody has written needs to have a kind of license because otherwise it will be copyrighted by the... I got it, how? So I'm just asking because our customers", 'start': 2468.848, 'end': 2497.858}, {'text': " One thing I'm not sure we are talking about the same amount, only just to be sure. When you as a customer owns the code and you want to use this service to generate codes,", 'start': 2498.131, 'end': 2520.93}, {'text': ' or a check code, document code, extend code, check for security or whatever, you just are using the service and this service just throw you the answer the same way as a LLM', 'start': 2520.93, 'end': 2540.503}, {'text': ' software product answers you it generates you only use an answer to your questions but with the code that you own that you are using of course if you are using this code in your company and this code requires a license', 'start': 2540.503, 'end': 2556.118}, {'text': " This solution only uses check, but doesn't tell you for Oracle, I don't know, some kind of specific code that you are using, and you must have the license to use that code at the end in your applications, of course. But this software is not designed to tell you, you need a license, or please take care that for this code, you will need an extra role, and this one.", 'start': 2556.118, 'end': 2585.265}, {'text': " I can expect that German customers will ask for a license to understand who and how the model or the model service can be used. And if it's aligned with European regulation or European laws regarding AI", 'start': 2585.538, 'end': 2610.077}, {'text': " Compatibility with German infrastructure, with German law. So in the ARR, I checked, there's no rules to talk about this code generation topic. I don't mean the generated code. I mean the license of the model which is generating the code.", 'start': 2610.776, 'end': 2638.899}, {'text': " But it is licensed from us. It's not an open source, it's a commercial license that is provided by OTC, for example. So this is from us, in that case, right? Yes, just like OCR, you don't have the OCR model license. It contains dozens of models inside the OCR servers.", 'start': 2639.497, 'end': 2664.292}, {'text': " I think I got the point from Matt right now. By offering this service on the OTC, I mean the CodeArts, then it's the question of copyright of that service.", 'start': 2666.459, 'end': 2686.237}, {'text': " So from my point of view, copyright. So copyright, you know, like NBDS with MongoDB. If we say NBDS, we are offering MongoDB, then MongoDB will come to us and say, you are not allowed to sell MongoDB because MongoDB is copyrighted, it's termed, unlicensed. Pangu is developed by Huawei. Yes, I know. That's his point of view also. We're just going to solve this topic.", 'start': 2686.237, 'end': 2715.64}, {'text': ' What I actually meant by my question is, is this model somewhere stated and is it ensured that this model covers the AI requirements and limitations or what you call it from the European Union?', 'start': 2715.64, 'end': 2738.029}, {'text': " There are AI specifications that it should not be... Like a... Like I mentioned before, AI art do not have any rules against code generation. If so, please find out and let me know. It's for example like this OCR. OCR has now as far as I know from Huawei, they do a certification AI C4 certification. Yeah.", 'start': 2739.684, 'end': 2769.053}, {'text': ' So, now the question probably will be from Matt is if this kind of certification also has this code art or is it going to be only used to prove that this has some kind of compliance, fulfill the expectation of AI solution? I mean, typically we talk for example here about things like bias, right? Yes, so it should be prevented that any bias is involved in such actual toolings, right, in the training data.', 'start': 2769.684, 'end': 2799.002}, {'text': ' So, what I can share to you is that we made actual research. So, I, for example, was also involved with our public affairs department where we analyze the AI Act, which is the predominant AI legislation in Europe. So, it will get effective most likely in June or July this year.', 'start': 2799.002, 'end': 2823.507}, {'text': " I can share you some documents, I will double check if I'm allowed to put this to external, that in relatively short words is explaining our interpretation of the AI Act, which is the predominant legislation and will be our foundation for that. And also this was the foundation for choosing such cases, right? And Code Arts was not part of our first line suggestions.", 'start': 2823.507, 'end': 2851.476}, {'text': " maybe also because it's a relatively complex case, because it's also part of a more difficult question to ask. By definition, can code have a bias? I mean, the result, yes, but the code itself, not. So that is the understanding that I have currently in mind. I'm not a philosopher,", 'start': 2851.8, 'end': 2877.671}, {'text': " But of course, these are questions that we bother ourselves with as well. So I think it's a very difficult question to ask. But also for this, you will not get a license. I think this is more actually a localization and legal question than a licensing question. It's more maybe certification and audit related.", 'start': 2878.183, 'end': 2904.531}, {'text': ' Does it does it match your understanding Matt? So I will check if I can send this documents to you, but I think this is like what you are bothered about, right? Yeah, got it. Thank you', 'start': 2904.531, 'end': 2932.125}, {'text': " Oh yeah, back to the slides. I'm not going to go through these slides one by one. I will just leave it to you to read. I have some competitive and some introduction of each.", 'start': 2934.667, 'end': 2957.363}, {'text': " each function. I think I would rather go through the real example for this CodeOpsNav. You have nothing left. So I'm going to show you a real demo, which requires some coding stuff. I don't need this, I don't need this. Yeah.", 'start': 2959.138, 'end': 2986.408}, {'text': " So, this is the OCR's API document, right? We're all very familiar with this document, and I tend to write a code called this API, yeah, to get IAM's token with the,", 'start': 2998.558, 'end': 3023.422}, {'text': " This is called Codesnap. Internally it's called Codemap, but it doesn't matter, it's just a different name. Codemap? Codemate, yeah. Codemate is like the component in DataArt, right? It's a different name for Codesnap. It's the same thing, exactly the same thing, but a different name. Codemap is like MAT, like our MATE book. MATE, yes.", 'start': 3024.753, 'end': 3052.91}, {'text': " I don't know why they have different names, but they are exactly the same thing. So now you have a token, and you can now talk to this, right? Yeah, I have internally access to these servers, so I can call these... But these servers are in Chinese, right? Oh, this is Chinese. I will go to that later. Yeah, so let me introduce this developing...", 'start': 3053.319, 'end': 3081.408}, {'text': " environment just in case someone doesn't have the coding background. This is so-called IDE. The R&D uses this to write the code. Very simple.", 'start': 3081.817, 'end': 3094.497}, {'text': " Code rsnap or this code mate is like a plug-in. It's very simple. It's just like a plug-in. You go to the market, say download the plug-in, and this plug-in will automatically install it into this IDE. And when you open it, you have the small box that says login, and this is already login.", 'start': 3096.425, 'end': 3118.729}, {'text': " and you are logged in, then you have access to the data servers. For which IDEs is it available? I guess Visual Studio or something? Visual Studio, oh yes, in the slide you have pages, I think it's in the end. VS Code, Python, IntelliJ, IDEA, all those popular IDEs are supported.", 'start': 3119.838, 'end': 3140.503}, {'text': " Okay, so how to use this is very easy. You don't need to do anything, just write the code. You see, I just mentioned I would like to write a code that calls this API, right? This API is for getting the IAM tokens. We're all very familiar with that. Then we can just put a hint in the comment and say, I would like to write a", 'start': 3142.227, 'end': 3172.039}, {'text': " call API function and I would like to call this API. Yeah, very easy. I tell him to do what, sorry for this, this is quite mess, but I think even it's quite messy, this small code made still kind of get a understanding what I want to do. Yeah.", 'start': 3172.79, 'end': 3194.241}, {'text': " You can see it's not the best grammar, it's not very clear, it misses a lot of information. But if I just type the auto plus C, it will automatically generate the code, half of the code for it. Okay, so I type the tab, which I confirm this is the code I want.", 'start': 3194.241, 'end': 3216.425}, {'text': " So let's see what it gives us. It gives us a URL, which matches this one. And IAM endpoint is... I will give this parameter later. It gives us a request body.", 'start': 3219.735, 'end': 3237.671}, {'text': " It's a JSON format, but it doesn't generate the code how to actually send this request to the API endpoint. So I plus auto plus C and let it keep generating. You can see that it's keep generating this line. It's a POST request, send a URL with this handle, this body to the API endpoint.", 'start': 3237.671, 'end': 3267.534}, {'text': ' Okay, so I have this line and also I have, but this is still not the end of the service. I still need a return, return value. Yeah, return value. So I click the auto plus C again, it will automatically generating the response header with this, let me tap the tape to confirm, X subject token. This is the token we want.', 'start': 3268.558, 'end': 3297.892}, {'text': ' Okay, we have this function already. You can see you have some red line here, which means something is wrong. The first-time generation always requires some', 'start': 3299.019, 'end': 3314.787}, {'text': " You see this username is not defined anywhere. So I just put it here. This also requires a little bit background for coding. You need to fix those stuff yourself. But the key point is it help you generating the code quicker. You don't need the bar on the middle. You use the underline bar. And this one.", 'start': 3314.923, 'end': 3343.012}, {'text': ' Oh, and the request, request for the, yeah, import. This solution is half, I mean, half using by the grammar check. Yes, very much. The studio itself, and the other half is the code generated by Kotlin. So you are having two parts of it. The one that is just generating the code for you,', 'start': 3346.783, 'end': 3371.288}, {'text': " And the other one is the engine itself that is checking your grammar. Yes, and this server can also help you checking the grammar, but it's not online yet. This feature is not online yet, but it's in the list.", 'start': 3371.578, 'end': 3389.667}, {'text': " Okay, so you have this func code already here, and I would like to make this API call. I need to fulfill those parameters. I think I will just copy this. I read this before, so that I don't need to type line by line.", 'start': 3391.288, 'end': 3418.404}, {'text': ' Oh, I need to import the pw, okay. And do the API call. Ah, I need to type this myself, really.', 'start': 3419.172, 'end': 3443.507}, {'text': ' Ah. Yeah. See, it helped me generating the code already. Hmm.', 'start': 3460.708, 'end': 3489.172}, {'text': " I know this is not working because I was in the company's proxy which forbade me to call this API. I will just quickly change the proxy and see if I can get this API call to go through smoothly. Why did you do that?", 'start': 3495.418, 'end': 3518.899}, {'text': " Do you happen to know the backend infrastructure of this? Is this a big service? What do you mean? Like, what did it take to deploy this? Is this something simple like OCR to deploy and maintain? Or more complicated like, I don't know, MRS or something?", 'start': 3520.452, 'end': 3547.858}, {'text': " The actual dependency is not clear yet, but the architecture is quite simple. I expect it could be as easy as OCR. It's something on the cloud, in the virtual machine, like a brain. The plugin is just get your code, send it to the brain, and let the brain decide what to do, and get the result back.", 'start': 3548.712, 'end': 3573.592}, {'text': " I don't think it has a console. It might have a simple console like OCR, but like CSS or MS console, I don't think so. It's more in a plugin format. Okay, got it. When you are done with the demo, can we see and", 'start': 3576.374, 'end': 3599.94}, {'text': " see if we can find it on the console, just if there's anything referenced there on how to use this or something. I'm just interested how the customer can find this. Ah, sure.", 'start': 3600.64, 'end': 3617.978}, {'text': ' Oh, yeah, I forgot to print the result.', 'start': 3632.875, 'end': 3636.254}, {'text': " Yeah, you see, this is the IAM token. If you do the IAM, like do the QA a lot, you probably will be familiar with this token. It's a big 64 token and yeah, this API call is a success. How long does it take? A couple minutes, five minutes, and we already have like 50 lines of code. One thing, observation from myself,", 'start': 3643.49, 'end': 3671.032}, {'text': " This plugin seems more or less the same as OCR was doing. You have an endpoint, your plugin, this. So the model is there behind this, and you just subscribe to it. It's like a LLM hub that we're offering, you know? And the user token, and then you can use it, it will be built, and then you can use it as a plugin into your programming engine and that's it, correct? Yes, very simple. Yes, okay, got it.", 'start': 3671.357, 'end': 3700.196}, {'text': " The question is, if now it's in beta, what are the 4 parts that are working right now? You show 8? Yeah, yeah, yeah. Code generation seems to me like it's working. Code documentation, you have it, you have this unit testing, you have this explanation... What?", 'start': 3701.169, 'end': 3724.531}, {'text': ' Here you see we only have these four on the board, right? I just show you the code generating which is not here.', 'start': 3724.906, 'end': 3736.852}, {'text': " for some reason, because you don't really need to, like you write a code, you doesn't really need to go here, click this button, and in general, it's just inconvenient, so we don't put it here. But for code, it's best expectation, due to some language, default setting is only setting to the, sorry, it's quite small. I'm not sure if people online can see it clearly. I'll try to make it bigger.", 'start': 3737.381, 'end': 3766.715}, {'text': ' For the code is blank due to the default setting is setting in Chinese. I could do a translation. I could just... Explanation, right? Yeah, explanation. So what do you mean by default is Chinese? How can we change it to English, for example? The RD will change it in the backend.', 'start': 3767.534, 'end': 3796.988}, {'text': ' Okay, so this is how the service is provided, the customer cannot change this? No. Currently, we do not open this to the customer. You remember when you use the chat GPT, you write some prompt, right? Sometimes you use Hungarian, sometimes you use English. Yeah, prompt.', 'start': 3798.097, 'end': 3820.913}, {'text': " If your prong is writing in Chinese, then probably the model will respond to you in Chinese, because it thinks you're talking to him in Chinese. Like I talk to you in English, you don't reply me in Hungarian or something.", 'start': 3823.746, 'end': 3842.381}, {'text': " In this case, it recognizes itself. So if we change the poem, then it will support English. I already tried that. I saw the English and maybe I can show you later. Because currently it's generating some explanation of Chinese, so I will just copy it to the translator and see if it makes sense.", 'start': 3844.65, 'end': 3874.462}, {'text': ' They are using the IAM servers of the OpenSCAD and OPTEN and WIRED tokens. Correct, right? And the detailed usage scenario and the main logic is described as below. Step-by-step, quite clear.', 'start': 3875.282, 'end': 3892.91}, {'text': " Okay, got it. Question, which programming languages are supported right now in this codemap? You also have a list. The main programming languages are all supported. They include C, C++, Java, Python, and the other stuff. It's a long list, I can't remember. Okay, one more question to the guys that don't know about this session. What do you think? You like it?", 'start': 3893.831, 'end': 3918.746}, {'text': ' You saw the way how the code is generated. You saw how easy it was to get this implemented there in just five minutes. Of course, we know that five minutes not always is everything clear. You have only to verify the code that is really doing what you are expected to do. But from your point of view, as you are working more on the programming side, do you think is this work for you?', 'start': 3923.166, 'end': 3950.64}, {'text': " Matt, Joel, Ferry. I found it very interesting. It sounds, it looks usable. So I'm eager if we can have a test drive for it. I think it's, it looks quite cool. I like this integration with the development UI, IDE.", 'start': 3952.125, 'end': 3980.469}, {'text': " As for me, Hector, in the last couple of posts, I use a lot this ChetGPT codexplainer. For example, when I use some programming language that I don't really know, like PHP or Java, this codexplanation is really good of ChetGPT, so it's like telling what the code is doing, the functionality, everything in a really, really good way, so absolutely understandable 100%. As for the code generation,", 'start': 3982.073, 'end': 4009.445}, {'text': " It's not always so good, so when you are prompting some more, you know, complex sentences, what you should do, then JetGPP can generate some not so good working code, of course. You know, I have to run a lot of scenarios, I should use this tool, as Matt mentioned, and maybe we can compare JetGPP to this, which is better, which function functions better, so that's my opinion.", 'start': 4009.735, 'end': 4037.654}, {'text': " to find out the competitiveness of this, right? So whether it is really worth it to offer in comparison to the open-source stuff. Yes, that's also true. I think HTTP does that for free, and it's really good, really good. I know, HTTP is really good, but it's a different scenario. In the real world, probably people do not use HTTP to generate the coding, for some reason. I think you know that.", 'start': 4038.029, 'end': 4067.551}, {'text': ' Do you think this is more refined, so this generates more acceptable code, more precise? No, not in that level. I know we probably, I mean probably, these servers are not as good as Chair-GPT, I have to be honest with you. But Chair-GPT also has some drawbacks in collecting your code.', 'start': 4069.548, 'end': 4096.084}, {'text': " Okay, yeah, it stores the data, right? It stores data and uses the data to improve itself. It's written down in their server selection. And for our server selection, yes, we do record", 'start': 4097.927, 'end': 4112.722}, {'text': " something, but we do not record your code. Like you see I'm generating some code, right? I click tab to confirm. You only record which code I confirm, I mark it as a good code, and that's all. And you will not store your code, you will not store your code for a long period.", 'start': 4112.892, 'end': 4136.937}, {'text': " So it's a commercial service and we do have our license. Sorry, I have a question. If you mark a code, which is the good code or the bad code, you have to store the code, right? Yeah, for a short period. So you store it for a short period and JetGPG stores it for a longer period? Yes, JetGPG uses the code to retrain their model.", 'start': 4137.193, 'end': 4166.067}, {'text': ' But if you are marking the code as good as bad, what you are doing with this result, you are training the model to make it better, right? No, you just require a personal favor. The model is set, so using a set model, it is very different. So ChagPD makes use of your code, so it would not be suitable in a commercial environment when you are developing something that you eventually want to sell or something like that.', 'start': 4166.715, 'end': 4195.282}, {'text': " because your code would be out somewhere, right? And in comparison, this would not do that, in a sense. It stores it for, I don't know, saving data for, I don't know.", 'start': 4195.776, 'end': 4210.794}, {'text': " mandate or something while you are working on this, but it will not make use of your code. Yes, indeed. And plus this is deployed in the OTC, and Huawei will not take the information from the OTC to Huawei and return the model. There's no way to do that. Even if we want to do that, there's no way to do that. Okay, I see now. So Hector, this is the benefit.", 'start': 4211.169, 'end': 4237.978}, {'text': " Yes, exactly. I'm just listening, you know, because we're not brainstorming, I'm just seeing what are the key values for this. I see now three key values. The one is you can plug it into your... I don't know if it is very... Do you know the changeability you can use also set it as a plugin in your Visual Studio?", 'start': 4238.558, 'end': 4261.067}, {'text': " Yes, yes, yes. It's possible. Okay, I was not aware of it. So that means it is exactly the same. The same solution, only use that it's dedicated for the OTC and we don't own the customer's code on it. We are just helping. Okay, got it. There is then two solutions. Okay, so no question for this code mate.", 'start': 4262.551, 'end': 4288.302}, {'text': ' I will quickly go through the next generation of the CSS.', 'start': 4289.514, 'end': 4305.486}, {'text': " Like I mentioned before, the RIG stuff. So I will just quickly go through how this CSS will support RIG in the future. We do all know what RIG is, right? I saw OTC have a lot of partner doing the RIG. So I don't think I have to explain", 'start': 4306.561, 'end': 4335.145}, {'text': ' step by step what IEG is, what embedding is. So we all know IEG contains two parts, the large language model and the search part. And CSS mainly takes responsibility for the search part. So the main focus of this is help you search the right content so that your large language model will answer more precisely.', 'start': 4336.135, 'end': 4363.268}, {'text': ' Like if you search wrong or your document is not related, obviously the large language noddle will just make up something or just answer you wrongly. You mean this hallucination that you want to correct.', 'start': 4366.203, 'end': 4381.869}, {'text': ' So this is the core competitiveness and the path tool. We have a new embedding model.', 'start': 4385.555, 'end': 4402.637}, {'text': " which is also developed by Huawei. It's called CC-CSS Embedding, E for Embedding, and provides a semantic front-end sorting model to improve the top-k. Top-k is the most k-relevant", 'start': 4403.558, 'end': 4425.913}, {'text': ' information. You do a search and it gives you a couple results and you use the large language model to summarize the result. We can call that summarized. And they also have some program organization and', 'start': 4426.817, 'end': 4454.172}, {'text': ' and just trying to give you some better results, like providing the proper rewriting. I will go to that later. Search planning, intention identification, and query rewriting, yeah. And this is our', 'start': 4455.213, 'end': 4477.551}, {'text': ' This is our architecture for the CSS. You may already see your partner do the similar stuff. I know that. So I will just highlight some different parts of our CSS model. So one is here, search re-rank.', 'start': 4479.189, 'end': 4508.933}, {'text': " We all know when you pass the query into the query writer and you put a query writer to do a semantic search to the CSS, it will give you a couple results. That's called phase one, a lot of relative documents. But which one is the most relative to your question? Use another re-rank model to sort it and only use the most related", 'start': 4509.275, 'end': 4539.275}, {'text': " and put it into the large language model to generate the answer. In the process, I don't see referencing, right? Does it support referencing to verify which document was actually used to show it to the end customer? It will.", 'start': 4539.275, 'end': 4561.237}, {'text': ' Very important. Yeah, very important. It shows the explanation of this solution, right? The code competitiveness, document splitting, because the large language model always have some limitation on the contents. And so we also help you splitting the document in a reasonable way.', 'start': 4561.561, 'end': 4590.811}, {'text': " This is all the large language model related stuff and I will just leave it to you to read this part. Yeah, I think we don't have too much time. So I have to be quick.", 'start': 4592.329, 'end': 4614.565}, {'text': ' In the form part, we could also use the OCR to subtract the stuff from the PDF document or image document, subtract the information. I just want to highlight a little bit about the search planning because this is also a key point for this RIG solution. You were generating the', 'start': 4615.213, 'end': 4642.892}, {'text': ' a similar query, like when you ask the RIG system whether today? You can tell your', 'start': 4644.872, 'end': 4663.37}, {'text': " question is a lack of a lot of detail so you will do a query rewriting and intention classification like if you say weather today you will rewrite your query like what's the weather in munich today to make the question more precise so that you you ask the question more precise you better you can expecting you get a better", 'start': 4665.06, 'end': 4694.991}, {'text': " and you will rewrite a couple of your query, and after that, if the query is still not clear enough, it will ask you, will you ask whether it's in Munich today, or you want to ask whether it's in Bonn today, it will ask you.", 'start': 4695.418, 'end': 4717.551}, {'text': " clear question, I absolutely know what you're asking about, and you would use this query to do the search. It's totally logical, you know, I'm just thinking, I'm always furious when my wife answers one of my questions with another question.", 'start': 4718.37, 'end': 4735.589}, {'text': " But it seems like it puts out the reason of that is because they want to be more persistent with your answer. And not your answer, a different answer that you don't expect. Yes, use the question to answer. You got what I mean.", 'start': 4737.773, 'end': 4759.019}, {'text': ' and this is the documentary trail progresses nothing to talk about just when when you rewrite a', 'start': 4759.923, 'end': 4770.333}, {'text': ' query, you use the semantic vector to do the retrial, and we have this post-processing, you sort your result to the most relative result on the top, the less relative result on the bottom, and', 'start': 4772.039, 'end': 4792.039}, {'text': " use this model to do the sorting and use the best result to generate the answer. That's basically the whole story of the CSS-IG solution. So only two parts. One is to help you ask the question more precisely. Second is to help you re-rank your result.", 'start': 4793.319, 'end': 4815.401}, {'text': ' This is the implementing detail. I will now go through that step by step. You also have a feedback mechanism. When your search is still wrong, still deadly wrong, you will mark a dislike.', 'start': 4818.029, 'end': 4843.029}, {'text': " Some people will verify if your result is actually deadly wrong and it will fix the weaker basis. So you have some feedback mechanism. But this is not that useful in most scenarios. This is the competitive needs. It's mainly compared with the Chinese. I will go to the language support later.", 'start': 4843.302, 'end': 4867.312}, {'text': " You are saying that I'm seeing on the slides that it is not a simple solution that is just supported on CSS. You need also Pango for it, right? I mean, if you were on one slide before on this one, you may see that you have this Pango. Yes, I know, I know, I know. Yes, indeed. So that means it's not just having CSS. You also read Pango, yes.", 'start': 4871.032, 'end': 4900.589}, {'text': ' So it is CSS plus this RIG support and Pangu? Yes. Even if we install CSS with this RIG support, it will not work because Pangu is needed, right? Yes. Okay. So Pangu could be one of the dependencies, but CSSRD can help to install this dependency for you.', 'start': 4901.391, 'end': 4924.667}, {'text': " But now I don't see what is not the value for me as a customer if I have this solution together with CSS. For me it seems like Bangu cannot work with RNG and that is the reason that CSS supporting RNG will support Bangu model to get more better.", 'start': 4925.589, 'end': 4946.305}, {'text': " I think, if my understanding is not wrong, then this confusion on your side is coming that you are expecting to be Pangu available in a, let's say, commercial service and then CSS in addition, but you can also have Pangu just in the back end without offering it to the outside. If that's your question, I don't get your question.", 'start': 4946.305, 'end': 4969.326}, {'text': " Yes, exactly, because it was for me not clear. Okay, thank you. Okay, yeah. The Pango could be a component of the CSS and hiding in the backend. That's correct. Okay, so this would be... So this Pango would be integrated into CSS? Yes. I mean, technically, it's not. I mean, technically, actually, it's not integrated with CSS, but you would implement it next to it, right? Yeah, next to it.", 'start': 4969.326, 'end': 4997.176}, {'text': ' And the CSS we are doing right now, I think it already supports the first part, right? Because it seems like it already has this vector stuff. So this we are already doing the first part, more or less. This one, embedding? No, I mean the CSS. Oh, yes, yes.', 'start': 4999.889, 'end': 5028.951}, {'text': ' the current version of CSS we are delivering is already going to support this? Yes, I think so. And even the last version is also supported, but you have to implement the semantics such yourself, which is not that hard.', 'start': 5029.172, 'end': 5047.5}, {'text': " Guys, I think it's time to make this a short break because it is 11.30 and I promised Cornelia that you have to join this daily otherwise I will be killed and I don't want to be killed. What we can do is just go for the daily and we can join at 12 back here and then we'll have here in the office a short break and then we will continue with this presentation.", 'start': 5048.456, 'end': 5077.91}, {'text': " If it's fine for you? Sure. Yes, guys. So we all just changed the meeting. Thank you, guys. Thank you. Yep, that's all from my side. Thank you, guys. Thank you, Marek. Same.", 'start': 5080.299, 'end': 5102.125}, {'text': " So you're waiting for everybody to leave and then going to the other meeting? No, no. They will tell you... We'll talk behind the scenes about the results of the YG right now. From my point of view, I'm a little bit...", 'start': 5106.34, 'end': 5124.906}, {'text': ' I mean the main reason we are talking about this obviously is that we should stay in a frequent exchange if such additional solutions could make sense.', 'start': 5126.067, 'end': 5143.848}, {'text': " How hard is it to implement it? Is the localization making sense? For example, in this RAG, I guess language support is an important part, yeah? Yes, yes. I don't know, Joshua, I guess German language is not supported in this RAG solution, right? Because the LLM is not supporting German language. Sorry. For RAG. Why we are talking here? Because it makes sense that we keep aligned about potential additional solutions, right?", 'start': 5143.848, 'end': 5172.09}, {'text': ' but still then we have to follow also the reasoning. Can we localize it? So for example', 'start': 5172.363, 'end': 5176.578}, {'text': ' language support. I guess German language is not supported. No, German is not supported, but English is supported. But I think in programming language you need English. Yeah, of course, but I mean for RIG the most important part is that you have the additional document intake. Yes, yes, yes. And if the language model is not supporting German language and you have a German manual, for example, and they customize a German service, well, you will not use it.', 'start': 5177.483, 'end': 5202.602}, {'text': ' It will not throw an error or expectation, but the search result will be poor. And then we have to understand the tension also. If we bring this in English language, how much effort does it take? How many hours does it take to implement it? What is the service dependency also for the customer? What is the process to make it available? For what? For Code Arts? All of those solutions, right? So if there is,', 'start': 5203.473, 'end': 5233.234}, {'text': " solutions you think that you want to have, we have to get into more detail to verify how to do it, right? But I thought this code is still beta, so that means it's someone like... Could be, could be not. The other one with CSS, it seems for me like it's also there.", 'start': 5233.234, 'end': 5251.425}, {'text': " Partially at least yeah, so we would still need the LLM implementation right and this is definitely missing and Then we have to check. Do you think you have customers for this? Do you think it makes sense to have that? because we Please correct me Joshua. Did we actually present this RIG solution to the systems as a candidate? I don't think so right now", 'start': 5251.425, 'end': 5275.35}, {'text': ' Nobody... How to say? Understood. I can tell you the reason behind, but no. The answer is no. Very polite, Joshua. Very polite. He approves, right? You tell more...', 'start': 5275.606, 'end': 5301.766}, {'text': " As you believe. Okay, got the point. But the point is nobody can forbid us to talk about that, right? So we can talk here. If that's wrong. Yes. Yeah, I mean, obviously everybody can forbid us, right? But we can talk about it and we can verify if we think it makes sense to continue to go into this direction. Ah, yes, that makes more sense. That's what I'm talking about. Yeah, exactly. That's the point. Because we have no reasoning, basically.", 'start': 5302.517, 'end': 5328.729}, {'text': " To do or not to do RAG in this kind of style. Nobody knows. Because we never talk about it. I'm just getting asked last time if we offer some kind of vector-based database on OTC and just wonder why those customers doesn't know that we have RAG there on CSS.", 'start': 5329.087, 'end': 5347.21}, {'text': " So, where vector database and CSS, where is the why? Why is the customer asking on it? And for me, that's exactly the point. You are presenting something with CSS and vector database and RNG. Wait a bit of it, yes. Exactly, so that means probably it seems like this kind of use case that somebody is asking is already part now of the real life that somebody is trying to do it. But, and that is the big but,", 'start': 5347.671, 'end': 5375.862}, {'text': ' You know, based on my experience not only here on OTC, also when I work for a Japan company Fujitsu, we always are missing something. That customer is asking for something because they believe they want it. They ask for something specific, special, because they hear from someone and we just answer, yes, yes, we have it.', 'start': 5376.237, 'end': 5400.845}, {'text': " At the end, when we sit together with the customer and start asking, okay, why do you need a blue elephant? We at the end turn out that they don't need a blue elephant. It is enough for with a tiger or another stuff to get the solution done. And that's exactly what I'm just figuring out right now, where it make, how we can evaluate if this,", 'start': 5401.084, 'end': 5425.674}, {'text': " that you're presenting when they make sense or in which scenarios can make this sense, right? Because with this, then we can start building exactly the real use case or close to real use cases. And then after that, then we have just the basis for this real use cases, then we can start doing hallucination like LLM does. And we start figure out if this could also match other use cases that we already have.", 'start': 5425.674, 'end': 5454.616}, {'text': " So for this CSS, I was thinking, yes, I do present you a lot of good features with the Panguio LLM, but you can also run without the Panguio LLM. You can integrate. CSS itself is a vector database. Now, how about just integrating CSS to your partner's solution? It's more stable, more fast.", 'start': 5454.872, 'end': 5480.247}, {'text': " Yeah, it has a lot of good features already inside, it's our best-selling product. And it's proven. It's nothing like freshly coming out, it's like bulletproof, reliable. Yeah, so if we don't care about the Panguil, yeah, it's totally fine for me, but it has good cases to help sell CSS better.", 'start': 5481.817, 'end': 5504.701}, {'text': " That's the key message. I'm pretty sure, but as I told you, we have to talk more about the use case for it. Which documentation did you use to create the code in OCR? It's in token authentication, I think.", 'start': 5505.316, 'end': 5531.408}, {'text': " Version endpoints, yeah. So I would say there's an endpoint here. Joshua, what documentation page did you visit from the OTC to create that code? I want to test something.", 'start': 5536.22, 'end': 5562.176}, {'text': ' The IAM token creation, right? But which page was it? Oh, sorry, I was replying my message. Just a short jump out. Could you please share with me the URL that you used to get that code, create that code in the... Oh, from the UGC document. Can you tell me the URL? Sure, sure, sure. Please.', 'start': 5565.35, 'end': 5591.527}, {'text': " I sign you to leave. Thank you, that's all. Because I want to test it with what I told you before, this starcoder2.", 'start': 5595.401, 'end': 5616.22}, {'text': ' That was a loud inbox. Which language have you created that code in? Python.', 'start': 5635.179, 'end': 5663.626}, {'text': " probably I was expecting you won't be able to generate the code because this is IAM stuff, particular for Huawei Cloud, and which is the, and this code rsnap is particular training using the Huawei Cloud's code. So I was expecting the,", 'start': 5668.234, 'end': 5696.578}, {'text': " Probably the open source won't get that good on this.", 'start': 5696.954, 'end': 5722.193}, {'text': ' What is the key for this code arts since you already have', 'start': 5728.336, 'end': 5737.671}, {'text': " infrastructure behind running only just this model and then everyone can just attach via API to ask questions to data and that's it. How to use API to add? I mean, you have Visual Studio, you put the plugin to connect it, exactly, and then you start asking whatever you want. So that means for me, there should be somewhere an endpoint on the Odyssey", 'start': 5738.166, 'end': 5766.527}, {'text': " API endpoint there with your credentials or whatever, and then you can start consuming that. Yes, theoretically yes, but I don't think anyone uses the API for this service. You can imagine that it's in the plugin format. It's already...", 'start': 5766.852, 'end': 5788.251}, {'text': " It's really, right? So it's just one instance. Yeah, that is for everyone can ask to this instance, right? Like OpenAI. Yeah. Yeah, right? Kind of, but it's a plug-in integrated into your... Yes, yes. I mean, it's just one cluster with HA that it's really with this model running behind the scenes and then every OTC", 'start': 5788.251, 'end': 5813.422}, {'text': " Tenant that has strived for the usage of it can then go to there with user credentials And start asking for code, testing, whatever, correct? I think so. Yes But it does not support like a chat Like when you say hi. Yeah, I know. I saw that you did in chat. Did you start Set some text there and start activating it to get that information and it start filling up and now say it's enough", 'start': 5813.422, 'end': 5842.91}, {'text': " No, okay. I want to go back. They can go back. You just are interacting with this program. So you didn't ask, please do this and that. I don't need to ask. You just say, okay.", 'start': 5843.251, 'end': 5855.265}, {'text': " You will quickly take a look at what you have already written, what's in your command, and you will think, if I see this code before, or if I was going to write this function, what am I supposed to write? It will do the coding for you. You are generating the code, if you think it's good, I can use this code, you just click confirm.", 'start': 5855.691, 'end': 5880.179}, {'text': ' I have this here as you may see I have this with star code too and I just ask this and it is also 11 please create a Python code for following API', 'start': 5880.64, 'end': 5901.63}, {'text': ' and they start just creating this Python code, identity, methods, whatever, and they say the response should be looks like follow. So it seems like this solution, by using this programming language of this open source, they just create these results, but seems like yours are a little bit different, they are more extended.', 'start': 5902.056, 'end': 5926.323}, {'text': " I think it's wrong in some way. I think you're missing something. Domain name password. Inside the domain, inside it should be a name inside of ID.", 'start': 5927.995, 'end': 5949.599}, {'text': ' This key should be there. You can generate a body and fix yourself.', 'start': 5953.763, 'end': 5978.131}, {'text': " You can see the image I sent it to you. Yes, the image. You sent me an image. Let me see. Yeah, I sent you an image. Here. This is a runnable code. You see, I identified the URL. I have the header. I don't think I have a header. I have the JSON body. I have the send request this function. I have everything is runnable. And I don't think they're generating", 'start': 5978.473, 'end': 6006.032}, {'text': " Yes, yes, you know, the intention of it, it's at the end to compare, you know. At the end, for a customer, it's important to say, okay, I can do this with open source, whatever. But they decide to hand over their code using the Charged GPT, I know, I'll be honest, I don't think that this", 'start': 6006.459, 'end': 6033.08}, {'text': " These servers are as good as ChargerDT, to be honest. The size is relatively small than ChargerDT. Which size do you mean? The model size. The latest version, the current version, I think is 13 billion or something like that. It's relatively small.", 'start': 6033.609, 'end': 6059.633}, {'text': " So compared with the Charged GPT, I don't think it's comparable. It always depends on the model, you know? Actually, the model size doesn't mean everything if there's quality. If you don't have good quality, you can have 20, 30, billions, whatever, 100. If the quality is too bad, then the answer won't be really bad. Yes, I know. But I mean, meanwhile,", 'start': 6060.009, 'end': 6086.118}, {'text': " I think the models, they are already in that dimension, qualified to have pre-processing that identifies if something is improving the model already or not. So that's not the big issue anymore. Yes, exactly. Now the issue is not the model itself, it's exactly the extension of the model.", 'start': 6086.237, 'end': 6108.217}, {'text': " I know, I have a Funtime Llama 3 environment set up in the OTC already. What do you have, sorry? Funtime Llama 3 environment. Ah, Llama 3. It's runnable. I Funtime myself Llama 3. Nice. With one T4. Surprise, surprise. I know, probably Llama 3 is also possible here because, you know, let me show you.", 'start': 6119.377, 'end': 6147.159}, {'text': " Lama 3 is already here, do you want to take a look? Yes, I have here... Yes, it is also in... Lama 3, so I have just to set Lama 3, and which Lama 3, let's see... I will have to suggest you... They have this HE, right? I have suggested you to not use this old Lama.", 'start': 6147.79, 'end': 6177.193}, {'text': ' You roll top a little bit. What do you mean? I suggest to not use O-lama. O-lama? Yes. Do not use it because you roll up a little bit.', 'start': 6177.517, 'end': 6189.804}, {'text': " But actually there are the models that are supported here. I know. You can see that it is very good to use, I know. But the problem is the same, it's using the quantumness model. Quantumness 4B, I don't know if you know what that's supposed to mean. No. Okay, so we call it Orama.", 'start': 6190.93, 'end': 6217.125}, {'text': ' 8-bit, right? 8-billion... 8-billion tokens. Parameters. Usually, one parameter is using the FP16, which means 16 bits to represent one floating point. So, this 16 bits is talking about this 8-bit standard. 16 bits represent one parameter.', 'start': 6218.524, 'end': 6248.353}, {'text': " And the quantized 4-bit means you only use 4 bits to represent one parameter. So you can probably tell that the accuracy is very, very low. It's extremely four times lower than the standard one. So the accuracy is low, that means you have a lot of hallucinations.", 'start': 6248.797, 'end': 6274.804}, {'text': " Not as good as the full model. That's my point. So, OLAMA only supports a quantum-less model. So, usually you use OLAMA, that means the quality, the model's quality is less than the full-size model. No, don't they?", 'start': 6275.52, 'end': 6304.497}, {'text': " I think we can go here, right? Yes, exactly, just here. I have to get up from this station. Oh, whiteboard. Yeah, there's the pen. Oh, there's the pen. So... I think you have to wait to... Hold it again, and then whiteboard.", 'start': 6313.712, 'end': 6341.937}, {'text': ' Okay, so usually the mainstream model uses FP16. Full floating point, 16. For one parameter. For one parameter. What is this 16? 1, 0, 1, 0. You know, only recognize 1, 0. So you have 16 of these 0 or 1s represent just one parameter. Like 1.3, 2.5, something like this.', 'start': 6345.998, 'end': 6375.862}, {'text': " Very precise, it could be 2.5, 4, 3, 1, a lot of digits. Because 16-bit can represent a lot of numbers. It's 2 to the 16 minus 1. It can represent this number of possibilities for this one parameter. Quantum net model, however, later you go back to Olama and check,", 'start': 6376.237, 'end': 6406.22}, {'text': " And check, it's quantized 4B, they only use quantized 4B. Which means, compared to this, you only have 2 to the 4 minus 1, 2 to the 4 is 1. So FB4. Yeah, FB4. Okay, now I got it, okay. So you only have this number of possibilities, so 2 to the 4 is what? 14, 15.", 'start': 6407.466, 'end': 6431.954}, {'text': ' one parameter, so the accuracy will be very very low. Clear? Yes. Why does OLAMMA only use 4-bit? Because it is designed to put the large language model into a PC or small local execution.', 'start': 6434.684, 'end': 6455.879}, {'text': " It's good, it's very easy to use, but the accuracy is a trade-off. I mean, you can run it here on other devices, but the quality is poor. Yes, it's a trade-off. I mean, for me it's okay, but for a company, it's not enough. Yes, so if you just use this, it's very easy to develop, so personally using it is not a problem. Okay, now what about Hangu? Hangu?", 'start': 6456.391, 'end': 6484.599}, {'text': " I think it's standard, FP16. Some of them use 32-bit, I don't know which one, but it's either one or the other, and it never uses 4-bit. And Pan Gu's code hard snap, I think it's 13-bit or something. For coding.", 'start': 6486.374, 'end': 6509.155}, {'text': " And for large language model, we have several versions. It's called M1, M2, M3, M4, and in future, M5. M1 we never talk about, the quality is too poor. The M2 I think is, I need to check out my notes.", 'start': 6509.872, 'end': 6533.609}, {'text': " Something new for me? No, no, no. He's a little bit bored. Definitely not. OK. 32. 13, 17.", 'start': 6540.401, 'end': 6563.677}, {'text': " Billion, billion, billion. This is 10. So the number doesn't have the pattern, but you can remember it's a little bit larger than the Lama 2. The Lama 2, the smallest is 7B, and I think it has 32 or something.", 'start': 6569.258, 'end': 6598.439}, {'text': ' for Lama 2. Because if you check the time, Pangu and Lama 2 are most likely to be competitive with each other. As Lama 3 comes out, Pangu is slow, is a little bit left behind.', 'start': 6598.916, 'end': 6617.978}, {'text': " OpenSource and OpenSource, right? We all know that. And LAMP 1.2 has 7 bits, compared with this one. And M4 is way too large, and usually servers don't use M4. I don't know what scenario they use M4, I don't know this yet. But basically, that's the story. How did we manage to get", 'start': 6618.968, 'end': 6646.8}, {'text': " this accuracy, for example, for 7 dB. What do you mean by accuracy? In the standard, we have some way to verify the accuracy. It's case-by-case. If it's CV, then we have opportunity detection,", 'start': 6648.302, 'end': 6676.732}, {'text': " detection task, it all depends on the task. Image classification, if an image is a cat or a dog, if the cat is correct, and the model predicts the cat is correct, so we get 100 points. If it's a dog,", 'start': 6677.875, 'end': 6700.503}, {'text': " you get zero points. You add those points together, and do the math, and you get your points. That's one way to verify the accuracy. For large language model, we have several ways to verify the accuracy. It's called, in the industry level, it's called MMLU. MMLU mode tag,", 'start': 6701.783, 'end': 6730.094}, {'text': ' The last two digits is language understanding. Massive multi-task language understanding. You use this data set and', 'start': 6733.524, 'end': 6762.995}, {'text': " You use the model to do this test, and it will give you a score. That's one way.", 'start': 6763.729, 'end': 6776.544}, {'text': " human eval, it's also similar, but you use the language model to do the task, and a human evaluate if it's correct or not. So you evaluate, I mean not you, but somewhere else do the human evaluation, or it's just MML? I think we have both. I think we have both. We have a lot of ways to do this procession.", 'start': 6776.937, 'end': 6806.408}, {'text': " Every test, we have a score. Yes, yes, of course. There's no way to get out because it is easy to integrate a skill from it. But the other thing is that this human evaluation also takes part of this test after you have a model.", 'start': 6806.783, 'end': 6824.002}, {'text': " I don't know that. I was not involved deeply into this kind of... The score of this MMLU, comparing Banggood with ChenGBT? They do have this comparison. But we are not comparing with ChenGBT, we are comparing with Lama 2. Because, why we are not comparing with ChenGBT? Because of... I believe it's too good.", 'start': 6824.428, 'end': 6853.131}, {'text': " That's one thing. The second thing is that Huawei internally is forbidden from using the TrapGBT for the reason I mentioned before, in collecting your stuff. One good example is when one time, this is a fun story, when one time we have a R8G customer that I want to use your", 'start': 6853.387, 'end': 6877.295}, {'text': ' your product to do the RGU, use CSS to do the RGU, and you have to prove your case is better than the GPT. So we use the data customer providing us to', 'start': 6877.756, 'end': 6894.872}, {'text': " do a comparison. Ranking. Ranking, yeah. Because we specially use the data to find our model, so we win in the first round. But two weeks later, the Chai GPT knows all the answers, and so we lost again. That's the fun story. So we know they are collecting our data to retrain their model. No surprise. Oh, yes, exactly. Since they offer this for free,", 'start': 6895.043, 'end': 6924.974}, {'text': " mostly free, then they own everything, they own your knowledge. I know that story also from Samsung. Okay, fine. Let's see. Now it's time that the team members should join.", 'start': 6925.418, 'end': 6942.312}, {'text': " I don't have access to this CSS new version, it's not available yet.", 'start': 6946.766, 'end': 6969.514}, {'text': " I mean the CSS components I guess are, but not the model integration? No. So for the CSS part, I think you got what I'm trying to say and you got the meaning, yeah, we can sell this CSS to the IG as a component. Yeah, that's all I need to want to talk about.", 'start': 6970.384, 'end': 6996.254}, {'text': " It will automatically be deleted on midnight. Yeah, exactly. So you have time until midnight. Otherwise, that's it. So let's see. Chats, what do we have? Yeah, Huion face. I know, I know. Huion face. Four star quarter. Yeah, exactly.", 'start': 7007.875, 'end': 7031.203}, {'text': " There was some partnership discussion for hugging phase, right? From ecosystem team? Oh, yes. It's actually me to suggest them to go to the hugging phase. They just have similar idea, but I'm not sure if I should continue with this task or what. I have to consult my management. Yeah, consult them. I guess you mean with your management, you mean Richard, right? Or any consideration?", 'start': 7034.633, 'end': 7063.268}, {'text': " I don't want to go. A hunting phase. Yes, hunting phase. Since we are not very likely to get the AI gallery to the OTC in a short time, I think it's a good idea to just go to the hunting phase and they have more", 'start': 7071.51, 'end': 7095.23}, {'text': ' developed there. They have a major ecosystem. They have everything. Google, Amazon, Azure, they all get into the', 'start': 7097.329, 'end': 7110.862}, {'text': " cooperating with HoneyFace deeply, so I don't see why now OTC should not do that. So I suggest them to like point their way to go to the HoneyFace and they are very interesting and that's basically the story. Yeah, I don't know if OTC is considering such kind of partnership as well. Please consider, that's our... Sorry? That's our solution for the ecosystem. So please consider my...", 'start': 7111.886, 'end': 7140.009}, {'text': ' We can talk with Hitler, but I think Hitler is not writing now. Maybe I think we should talk to Neil Magnus. Do you know him? Yes, Magnus.', 'start': 7142.176, 'end': 7156.425}, {'text': " I saw him create a account in the honey phase. That's OTC, Open Telecom, but inside the repo, there's nothing there. So maybe we should push him a little bit harder to develop something there. When Hector has fed already with his writing...", 'start': 7157.142, 'end': 7186.186}]
The conversation appears to be discussing the evaluation and comparison of AI models, specifically mentioning MMLU (a benchmark for measuring machine learning model's understanding) and the comparison between different models like Banggood, ChenGBT, and Lama 2. There is a discussion about human evaluations being part of the testing process after a model has been developed.

The speaker mentions an internal prohibition at Huawei on using TrapGBT due to concerns over data collection practices. A humorous anecdote is shared about how a competing model (Chai GPT) improved its performance by apparently retraining on proprietary data, which caused the speaker's team to lose in a subsequent round of testing.

There is also discussion about the commercialization strategy for a component called CSS (not further detailed), indicating that it could potentially be sold as part of an integrated solution. The conversation touches on partnerships and collaborations with entities like HoneyFace, hinting at strategic directions related to AI ecosystems and market positioning against competitors like Google, Amazon, and Azure.

The speaker also suggests reaching out to Neil Magnus regarding developments in a repository connected to Open Telecom (OTC), urging more active engagement to foster ecosystem growth. There's a playful mention of "Hector" being fed with writing, which could imply the need for continued content generation or model training activities within their AI endeavors. The conversation ends with an invitation to further discussion involving Magnus. 

Overall, the dialogue is rich with details about internal policies, competitive dynamics, and strategic planning in the realm of AI technology development and deployment.Bad value in file PosixPath('/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/matplotlib/mpl-data/stylelib/tableau-colorblind10.mplstyle'), line 2 ("axes.prop_cycle: cycler('color', ['006BA4', 'FF800E', 'ABABAB', '595959', '5F9ED1', 'C85200', '898989', 'A2C8EC', 'FFBC79', 'CFCFCF'])"): Key axes.prop_cycle: "cycler('color', ['006BA4', 'FF800E', 'ABABAB', '595959', '5F9ED1', 'C85200', '898989', 'A2C8EC', 'FFBC79', 'CFCFCF'])" is not a valid cycler construction: 
torchvision is not available - cannot save figures
Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 7, in <module>
    from main import get_transcription
  File "/home/linux/meeting_whisper/main.py", line 5, in <module>
    import whisper
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/whisper/__init__.py", line 13, in <module>
    from .model import ModelDimensions, Whisper
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/whisper/model.py", line 13, in <module>
    from .transcribe import transcribe as transcribe_function
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/whisper/transcribe.py", line 21, in <module>
    from .timing import add_word_timestamps
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/whisper/timing.py", line 7, in <module>
    import numba
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/numba/__init__.py", line 77, in <module>
    from numba.misc.special import (
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/numba/misc/special.py", line 3, in <module>
    from numba.core.typing.typeof import typeof
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/numba/core/typing/__init__.py", line 1, in <module>
    from .context import BaseContext, Context
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/numba/core/typing/context.py", line 11, in <module>
    from numba.core.typeconv import Conversion, rules
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/numba/core/typeconv/rules.py", line 2, in <module>
    from .typeconv import TypeManager, TypeCastingRules
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1012, in get_code
  File "<frozen importlib._bootstrap_external>", line 672, in _compile_bytecode
KeyboardInterrupt
torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 720, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 736, in simple_response
    await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 72, in app
    response = await func(request)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/routes.py", line 1116, in upload_file
    form = await multipart_parser.parse()
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 603, in parse
    async for chunk in self.stream:
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/requests.py", line 238, in stream
    raise ClientDisconnect()
starlette.requests.ClientDisconnect
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpcvbcvt7z
临时文件夹地址：./tmpcvbcvt7z
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back. Thank you Joshua. Please, it's time to continue with your presentation. It was regarding, as we all remember, CSS using RIG and also Pongo semantic model for that solution. Please, share your slides. So that everyone knows what you are talking. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAR, right? Yes, we do have some competitiveness with the existing large language model. But this is nonsense. You don't look this because it's only for Chinese embedding. We don't have the Concur accuracy for English embedding yet. So, we don't have the Concur accuracy for English embedding yet. But my point is CSS can itself do not need to associate with this embedding model or any Pongo large language model itself is a very good databases and Victor databases. I will show you the competitiveness of CSS itself to any other open source CSS later. Okay. I don't have that much left to talk about with this slide. This is a successful story. Use CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Like use RIG to search the most correlated response, like how to deal with angry customer. And it will just generating the... generating the most proper answer based on the current situation. And just like a code R step, you generate the code, you generate the answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo. I don't have the demo yet. I was not able to access to the demo. Feel free to click this link, but I don't think this go anywhere. So, it's called code search. Yeah, it's called code search. Indeed. So, that means what code search? It is this... It's called this solution integrate Pongo with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decide it's called code search, then it's called code search. Okay, the next question is since Pongo. Pongo is something that we don't have here in OTC. But Pongo exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this World of AI Summit. But one year before, he go to the main stage and present something about Pongo. For... Yeah. For this electricity stuff with... Electricity with power. Yes, there. So, the question is since Pongo is more than mature in Huawei, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customer. So, this is more like a brainstorm. It's not like brainstorm. But yes, we have a lot of different Pongo model as you may already know. We have the CV, different Pongo model for different AI task. For example, CV, we have the electricity tower. We have the TFDS. Those are actually have customer in using of those. And the CSS and the Pongo? I mean, we're talking about the now not Pongo. Goal search. I mean, for goal search, you just show the case. Yeah, I just show the cases. But it's not a real customer. I'm not... This is a real customer. It's a real customer. It's a real customer. And the real customer is doing what? Using this RAG to build a customer service assistance. Like a... Support. Yeah, customer support. Or help center. Help center, yeah. Help center, yes, indeed. What kind of customer? Again, was it a bank or what was it? Yes, a bank. Huawei have a lot of customer with bank. So... And then you seen CSS, which is the RAG and Pongo together. And they are just... What's injected on this RAG? What's injecting in the... You mean injecting to this RAG's knowledge basis is the customer's servers. His... Historical chat record. Like... Basically, this is chosen by... This database is chosen by human. Yeah. How to dealing with angry customer. How to answer this question. Come frequent QA question. And all those data are put together and fit into this RAG. So when a customer... When a customer find your customer servers, they always find the RAG. Yeah. So, customer servers, they always want like those kind of thing, right? I go charge, I don't know that how to use this and that. Those are most of the answer is in the frequently asked QA. And they just don't bother to read this. So, this RAG will help the customer servers people to get the correct response to those customer. Okay. So, the value of this is improve the efficiency and customer's... Satisfaction. Satisfaction. Yes. But this... From what I've been told, this can be also done without CSS and using just a simple LLM with RAG on top or on DC? So, what is the difference now? Using the... Can you just give me a second, please? Okay. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, Amber Search. With this Amber Search, what they are doing is they have a little... They train... They have a model. They put on this model the documentation of what happened from the OTC. And with this, this is the RAG part so that they do condemn the use case. It's to... To develop a chatbot with this chatbot the same as here. You have your help center. You start asking questions and it will be... It gives you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise what if your solution is better and we already don't know? So, please. So, let me show you this. Here, for example... Can you see my screen? Yes. No, I think you are not sharing. I know you are not. Okay. You see this in... So, this is... Behind this, as I told you, it's LLM with RAG and it's using only the documentation URLs that we have on the OTC. So, there is not a service description and so on. So, it would call, for example, here. Okay. What is that? LTS support. I don't know. Availability. So, what is... This is... Doing it, it's... You see in the left side, it's just the links that it found some kind of information but it's still not doing something. On the right side, it's the... This... So, you see? Yes. this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it is creating, of course all that information is based on the documentation of the OTC, because we have these as basis. At the end, when it is completely finished, you may see for example here this number one. Number one is a reference that has been used for this part here. Number two refers to this one, and three and two is just a mix of these sentences from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been, find this kind of information on that sentence. And this is it. And the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just an LLM and also ARG. That ARG is just connected to this URL docs OTC systems comes no more, no less. I think principally it's, technically it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So I guess technically there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. And what is the cost? And what is the actual business model? Because in this case, this is obviously being focused on end users, right? So if you want to make this happen again for your end customers, if you are like, for example, I don't know, a system integrator or something like that. You have to be either a partner of mBus search then again, or you have to make a commercial model with them to sell this to your own end customers. So this can be relatively complex and then also become a matter of cost related to that. Since I don't know how mBus search is charging and what they kind of invoke in business model means. And I have also no answer for the actual business model. I think anyway, these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business quality output. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here. I just asked in Q2. I just asked in English because you see that the documentation is also in English related. Correct? So, but I can also ask the same question in German and I will get the answer in German also with the reference in English. I think it's similar question, same way and try to translate in German. You are now the... You are German. You know the question. I think I did some mistakes. I think the question is good. The answers that I see so far on the left side are not like that applicable. But I think the right side where it's giving the answers looks good so far. Just looks primary, standby, so failover. So you see in this solution I just got this. And you may see here the reference. Also I have a reference. But when we select the reference it will be forward me to the documentation still in English. So that means this model can just support German and English and you see also a way to... Even if I'm German and I don't... I'm not really confident with English and so on. So I can just select it and I have exactly the reference to all of this answer here. So it depends on the answer and the question. But you may see all of this. So if you have this also with your solution integrated a similar way of it, it will be of course a very good... We are now customers for it. I'm pretty sure we have still in Germany customers that are looking also for this kind of solution. For example. Yes. For your question. Like what's the difference between us and the Ember Search? You mentioned they use the open source model to retrain the model. Yeah. They have their own embedding function. They have built their own knowledge bases. Yes. You can always use that in the... With the open source. You can build an end to end solution, product with all using all the open source solutions. Yes. There's no problem. I can tell you that. Basically you can build everything with open source nowadays. But why people still go to the commercial? Why people buy the open source when they have the open search? You know CSS open search? Yeah. Even though open search is open source and they still go to Amazon to buy it. Why? Because they don't know how to use it. Yeah. We have different... We can see in different angle. Yes, the open source is cheaper. But as I mentioned before, cheap free cost most. Yeah. When the server's down, when the server is misfunction, nobody care. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We have also have me to help you build a... Take a look with what's your problem, give you some advice to... That's all the commercial does. So similar story here. Yes. My question to you, Joshua. I like it. I don't say that it's wrong or that we're wrong. No. I would like to hear from you or Thomas or... If we can also offer with the something like this. I mean similar to English, German, like you see. I think the demo would be really helpful. Yes, exactly. Yes, a demo would be very helpful. If there's something like this, I mean open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be a very good... I will propose also your solution because it... If you achieve such kind of results, why not? It wouldn't be the last one that I will say no. Yeah. I mean, do you need time to prepare a demo? I mean, if you find something like this... I saw that Enva Search, they are doing quite good for my first... And yes, I can go back to R&D and... Yes. Yes. I can find a demo for you and see how they are working on. But currently, it's not good. The large language model is not very good at German. So when you speak German to them, it probably will just reply English or just randomly mumble something. Yeah. That's one of the drawbacks. But I see what can I do. But most likely is demo. So if it is a demo, it will be in English. If it's in English, I think it would be a good start, you know, because... I think one demo is enough. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Cool. Okay. Please continue with your presentation. I have another question. What is your name? My name is This is just one example for a help center. Do you believe that there are another use cases also related to this one that you are presenting? What I'm presenting now is the CooSearch, is the CSS for IG solution. And currently, it's... Yeah, like I said, it's only for IG solution. So it's only for the CooSearch. So the CooSearch for IG is strongly related. And for your question, if you can use in other scenario, any IG use cases can buy our CSS with databases. And one of the core competitive needs is... I'm not sure on my screen. Yeah. Yeah. I think it's... Yeah, I think it's... Yeah. So, I think it's a good question. I think it's a good question. Yeah. So, I think it's a good question. I think it's a good question. Yeah. It says, Joshua, I start. Joshua, maybe you stop it and start again. Yeah. One of the very competitive for our CSS is... Oh. I think I was offline. Sorry. Let me reconnect it to the network. Okay. So, I think it's a good question. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. I just wonder if we still in the queue or not. I want to start Cadett. Yeah. I'm gonna... I want to start again because my screen初めつきて. Okay. see my screen let me let me just reconnecting to the session join the session rejoin the session yes so during this time guys from the team what do you think about this this solution from Georgia would be nice to know how the customer can make use of this so better individual product or and you go or they can use this and they go to the CSS page or something either or how how can they access this yeah I'm not sure your question correctly so you say how people going to use this kuiser try this is a outbox serve us so it itself is a sow us yes you can go to the house ladies tss motion right now if you can see something similar to a body to actually ssc you need you need to register for permission uh my permission is not available yet that's why that's why i don't i can't show you the demo okay i have some awesome access to the google cloud yeah access to the huawei cloud let's see um i'm also really curious because i like it to be honest i really like it what you present and now when we are all sitting to that probably will have the chance to um to see it so this is in css right yes yes yes okay and then i uh i'm in the right region so i'm in hong kong region it's fine uh no or should i do no we should change it to beijing okay let's change to beijing okay because beijing one is a beijing one or beijing four oh you uh did you see the cool search suddenly disappear yes disappear just a little bit uh i think i think you use the uh you have to use the uh how uh no international china mainland china mainland upper right corner i mean we change the access capabilities so but but if you are able to choose beijing when he is in china mainland already otherwise it wouldn't be uh but our account is not yeah the account is international so it may not be available international in the uh right now but i can show you show you my okay let's see i will stop sharing we have different kind of accounts globally i see that the accounts for china mainland and international and they have different permissions okay let's see but it's supposed to be also available for me i don't know they don't like me i mean i don't even have access to china magnet anymore i'm only allowed to use your view as employee only the region where you are usually working actually so this is what joshua also just mentioned for me it's actually very difficult at the moment to get access for chinese resources oh that's because latency ah no no this is just like a lot of things that you can do in china mainland so you may want to check out the chatbox Lance valley channel as well i want to check yeah and from there i can answer the form okay good i'm really enjoying this i'm just just i'm a little bit accurate here so so i'm going to send this to joshua to he's going to ask that you can do the code because i really love yahoo tys and i want to register something to him oh i think that's pretty cool thank you so much yes joshua thank you thank you joshu thank you you look i such you or i thought you like kคะ so i immediately had this as well like i would say i just you're on PCN budget battle don't have permission that are pressed for permission yeah I don't have this permission so I cannot assess it anywhere so my story ends here but this is that also says that we mentioned that before the MLP could be a component behind behind the scenes no I mean principally yes but not as a service presented to the customer right this is what we discussed before yeah I saw I see that Yahoo yeah that's that's the that's the story I can I can try to get a permission and see me or somebody else to show you this demo yes the my key message is our CSS for our solution have this curing rewriting and result re-ranking function and even without those even without the pangu is itself is a very good vector databases and here is you let me let me show you the github for benchmark this is this is what approximately nearly a neighbor near sister PRESENTATION neighbor search function is a it's a search function in the benchmark it compare with all those algorithm or Wannaa kardeş and this is also Search engine, yes. This is also very popular. You see 28k is made by Facebook and it compares all of them. You can see our Huawei's search engine algorithm is QSGNGT. I don't even know how to spell it. This is Huawei's algorithm. It's inside CSS. You see QSGNGT. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best, I mean the list with colors on the right side. So the graph is the ranking, the best to the... The right side here is like which one represents which graph. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes. In the same record rate, the more query per second is better. So you see at the same record rate, Huawei's CSS search engine performance is always the top, highest. See this line here. And horizontally, the same speed, the query per second, we call it speed, number per second, right? The higher record will be better. We all know what record is, right? Do you check so that the guys can access to this? Copy the... The address, right? Yes. Sure. So the address has not to type this. It's good. Where is the... Sorry, I just looking for... If you put it on the solid, then I can put it on chat. Oh, okay. So that would be, I think, the most is Spark and then we have it. Yeah. And this repository is now maintained by Huawei. And you can see it's also very active a couple days ago. Yeah. Last year, four days ago. Yeah. So I think you can also show that our Huawei's search engine is already have... Could mean something. Yeah. Could be some competitiveness. And the rest of them, the rest of the images also similar story. Yeah. But for different task. Those are all task. Yes. And you can see the Huawei's... The QS something, something is also kind of competitive be something. Yeah. Competitively. Okay. Fine. Yeah. So that's one of the main point. The other point is all writing down in the CSS release note and CSS promotions, guide, slides, and so on. Yeah. So I think that's all. Yeah. So I think that's all. Yeah. So I think that's all. Yeah. So I think that's all. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Just to me, the guide, slides, all those stuff is there. So even without the Pangu model, CSS itself could be something. So that's all for this CSS story. Yes. And my presentation should be end here. If you don't have any other question. Do we have any other question? Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. guys I think probably good okay guys then we will close the session thank you so much for joining hey wait I think Milan asked Martin asked if the IAG can use for the help center chatbot and I understand it correctly yeah my question my answer will be yes no there's no problem to build this and it's not it's nothing hard I built one small demo before you see there is for OCR so I think it's a good idea to build it for OCR documentation QSH is nothing hard and yeah so the answer will be yes the documents all English it could be doing very well yeah that's all for my presentation and based on my outline my very last topic is a little bit small discussion with the Model R school of marketing it's a brainstorm stuff and see if we want to talk about this because you know the model R is on his way doing the operations smoothly and it will sooner or later upgrade to the latest now we have a chance on the asking us if you want to add any feature anything to make it more sellable in Europe anything you can you can check the how Google sells how it sells how Amazon sell they are similar similar product and give them any advice they can see if we have a walk around or solution or just add this feature they study working right now yeah you have we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this just me this way now I believe there's only just one way to find this out do you have a kind of a business plan? any of benchmark of the current version forungs compared for example with with a AWS with your own other similar products I know this is Sagemaker then we sure Google is collect voice a machine I think uh my machine I think my hernie's for cheer the Google use two business in But I mean, if you have some kind of benchmark compared with similar ML solutions, then it will be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. Model R is not like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And Model R is still machine learning and we don't have this benchmark for machine learning. It's more about the feature set comparison, right? Yes, indeed. What they might offer, what we don't currently. Yes, what they might offer, what we see that is a good feature, maybe we would like to edit it. Now is a good chance to talk about it. Now the window is open. We still don't know what the new version or the fourth jump, we still don't know what it will have. We can do it in several steps. Once we can get the release now, second, you can go to the Huawei Cloud and check out the latest Model R directly. The latest, do you know what version the Huawei Cloud is running? Doesn't really matter. If you see it's good, it's good. Then when you upgrade it's not, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as Diego because we all know that Huawei Cloud in their regions, they offer different versions. Just go to Beijing for. Exactly. What you could provide us is which version. Exactly. Exactly. Which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region and Huawei Cloud has the current version that we will get the deliver. But really also the future level. Okay. So we can also figure out or see what is the difference because, you know, release notes. Okay, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and Ferry or short or Vnet or I don't know. All the team members could also just check it and see what features are there really running. We can see. And probably also evaluate if there is some kind of I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature than this model. I was thinking. I think I missed the point the first time. So what Joshua, you're saying is that now we have a time frame where Model X R&D is giving us the opportunity to give feedback on what we would like to see. Okay. Thank you. Thank you. Bye. I think this is a tool you have in the future, right? Yes, indeed. So I was thinking differently. So I was thinking if you see Amazon have this feature, I think is good. Google have this feature. I think is also good, just list all what you think is good. And then the R&D says are we available, yes or no, or do we have a walk-around or do we have to redevelop something? Yeah, that's my point. Okay, for this, we can use the public cloud model and so on. model it doesn't really matter yes it doesn't really matter it would be uh maybe months or first months but maybe half a year or so before this appears on otc whatever we request right um okay we can do that do you know how how long this window is open uh yesterday uh i uh now they they have some session host and uh tell us to give them feedback i don't have anything on my mind so i will bring up the uh customized image this topic to them and uh i hope i do hope we can add more good feature inside it and uh uh i hope we can add more good feature inside it and uh so i don't know if i make my point clear now now now i tell andy say hey uh your uh uh ai framework is relative old i would like to have some feature that can have uh latest framework latest driver cuda uh python uh tensorflow latest version i want to customer i would like to my decision which one is good which uh which we will choose which framework yeah i would like to have this feature now i bring this to them and i also want to have some uh some idea like add this feature that otc can customize their own image like uh uh per inference with llama free or training with llama free uh those image and otc can develop this image and make it available to customers so the customer just one click and they can deploy the i also want to have this feature but uh yeah i have those things in my mind but i do want some info from you guys that's that's that's what i want to talk about yeah as soon as possible yeah because developing also needs needs some time um okay yes so we will try to do this how about uh so how about we do this so our next spring starts on next monday so we are going to connect with the next spring starts on next monday so we are going to connect with the allocate maybe one or two days or from you guys so in this case so Matt Joel very so maybe each of you spend one day comparing this stuff so I don't know if you guys have access to public if you don't Hector could provide you a user account or maybe even I could I don't know maybe Hector can provide me an account as well okay yes guys so we can give you an account you spend one or two days comparing GCP, Azure and so on yes and let's say the week after we head together again and we talk about this 5 for me great okay sounds great I just wanted to add one additional or one small topic which would help us going to market it's a simple logo made for Europe or certified by for European usage or leverage for Germany or something I think you are totally right Matthias Rechenbork I think unfortunately it's a little difficult because we have no no remain virtual much no such stamp that we can get from official's stages right now I think the best thing we have for the moment is AIC4 right and I had actually an interview with Ernst & Jan after the last audit they invited me for an interview and you know we have currently C5 this is our principal cloud certification yes be outed at the moment but Ernst & Young at that time was already planning to offer to T-Systems to audit against AI C4 or whatever comes in future in addition so things like like AI Act etc. So I think it's like a matter of time when OTC will have to review exactly this again and raise their hand and say guys now we have SOC, C5, IT Grundschutz please audit and compliance what the next thing we should do is AI C4 audit or whatever applies to have an official stand right? I'm already looking for budget. We have to make our own. Okay, very good. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Hey guys, it's now time for lunch. Thank you very much for joining the session. Gergo just let me know who should then add to the Huawei tenant for next week to take care of this model arts and I will then add them to Huawei cloud. That's it I think. Okay, please create one for Zsolt, Kari and Matt. Okay, Zsolt and Kari and Matt. Okay. Yep. Okay. Okay, great. Thanks for your time, colleagues. Thank you. Thank you. Goodbye. Goodbye. Goodbye. So, let's go for lunch, I think. One bottle of wine. Nice presentation. Thank you, Joshua. Joshua, thank you. I like it. Thank you. Thank you.
The discussion in the text revolves around a marketing brainstorming session regarding Model R, a machine learning solution offered by Huawei Cloud. The team is discussing ways to improve and make Model R more competitive and sellable in the European market.

Several points are raised during the conversation:

1. Benchmarking: There's a suggestion to compare Model R with similar ML solutions from competitors like AWS Sagemaker and Google Cloud Machine Learning Engine to identify potential improvements or missing features.
2. Feature comparison: The team agrees that comparing feature sets between Model R and its competitors will help determine what enhancements could be made to make it more competitive in the European market.
3. Customization: There is a desire to allow customers to customize their images, specifically mentioning the need for latest AI frameworks, drivers, CUDA versions, Python versions, and TensorFlow versions.
4. Certification: Matthias Rechenbork suggests having a logo or certification that highlights Model R's compliance with European standards, which could help in marketing efforts.
5. Audit and Compliance: It is mentioned that OTC (presumably T-Systems) currently has C5 certification for its principal cloud services but is looking to be audited against future standards like AI C4 to ensure compliance with AI Act requirements.

The team agrees to allocate time next week to compare Model R with GCP, Azure, and other competitors. Hector will provide access to Huawei Cloud tenant accounts for Zsolt, Kari, and Matt so they can conduct the necessary research. The session concludes on a positive note, with the team looking forward to lunch after their presentation.The discussion in the text revolves around a marketing brainstorming session regarding Model R, a machine learning solution offered by Huawei Cloud. The team is discussing ways to improve and make Model R more competitive and sellable in the European market.

Several points are raised during the conversation:

1. Benchmarking: There's a suggestion to compare Model R with similar ML solutions from competitors like AWS Sagemaker and Google Cloud Machine Learning Engine to identify potential improvements or missing features.
2. Feature comparison: The team agrees that comparing feature sets between Model R and its competitors will help determine what enhancements could be made to make it more competitive in the European market.
3. Customization: There is a desire to allow customers to customize their images, specifically mentioning the need for latest AI frameworks, drivers, CUDA versions, Python versions, and TensorFlow versions.
4. Certification: Matthias Rechenbork suggests having a logo or certification that highlights Model R's compliance with European standards, which could help in marketing efforts.
5. Audit and Compliance: It is mentioned that OTC (presumably T-Systems) currently has C5 certification for its principal cloud services but is looking to be audited against future standards like AI C4 to ensure compliance with AI Act requirements.

The team agrees to allocate time next week to compare Model R with GCP, Azure, and other competitors. Hector will provide access to Huawei Cloud tenant accounts for Zsolt, Kari, and Matt so they can conduct the necessary research. The session concludes on a positive note, with the team looking forward to lunch after their presentation.
./tmpcvbcvt7z/20240510_121130.m4a
临时文件夹地址：./tmpcvbcvt7z
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back. Thank you Joshua. Please, it's time to continue with your presentation. It was regarding, as we all remember, CSS using RIG and also Pongo semantic model for that solution. Please, share your slides. So that everyone knows what you are talking. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAR, right? Yes, we do have some competitiveness with the existing large language model. But this is nonsense. You don't look this because it's only for Chinese embedding. We don't have the Concur accuracy for English embedding yet. So, we don't have the Concur accuracy for English embedding yet. But my point is CSS can itself do not need to associate with this embedding model or any Pongo large language model itself is a very good databases and Victor databases. I will show you the competitiveness of CSS itself to any other open source CSS later. Okay. I don't have that much left to talk about with this slide. This is a successful story. Use CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Like use RIG to search the most correlated response, like how to deal with angry customer. And it will just generating the... generating the most proper answer based on the current situation. And just like a code R step, you generate the code, you generate the answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo. I don't have the demo yet. I was not able to access to the demo. Feel free to click this link, but I don't think this go anywhere. So, it's called code search. Yeah, it's called code search. Indeed. So, that means what code search? It is this... It's called this solution integrate Pongo with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decide it's called code search, then it's called code search. Okay, the next question is since Pongo. Pongo is something that we don't have here in OTC. But Pongo exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this World of AI Summit. But one year before, he go to the main stage and present something about Pongo. For... Yeah. For this electricity stuff with... Electricity with power. Yes, there. So, the question is since Pongo is more than mature in Huawei, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customer. So, this is more like a brainstorm. It's not like brainstorm. But yes, we have a lot of different Pongo model as you may already know. We have the CV, different Pongo model for different AI task. For example, CV, we have the electricity tower. We have the TFDS. Those are actually have customer in using of those. And the CSS and the Pongo? I mean, we're talking about the now not Pongo. Goal search. I mean, for goal search, you just show the case. Yeah, I just show the cases. But it's not a real customer. I'm not... This is a real customer. It's a real customer. It's a real customer. And the real customer is doing what? Using this RAG to build a customer service assistance. Like a... Support. Yeah, customer support. Or help center. Help center, yeah. Help center, yes, indeed. What kind of customer? Again, was it a bank or what was it? Yes, a bank. Huawei have a lot of customer with bank. So... And then you seen CSS, which is the RAG and Pongo together. And they are just... What's injected on this RAG? What's injecting in the... You mean injecting to this RAG's knowledge basis is the customer's servers. His... Historical chat record. Like... Basically, this is chosen by... This database is chosen by human. Yeah. How to dealing with angry customer. How to answer this question. Come frequent QA question. And all those data are put together and fit into this RAG. So when a customer... When a customer find your customer servers, they always find the RAG. Yeah. So, customer servers, they always want like those kind of thing, right? I go charge, I don't know that how to use this and that. Those are most of the answer is in the frequently asked QA. And they just don't bother to read this. So, this RAG will help the customer servers people to get the correct response to those customer. Okay. So, the value of this is improve the efficiency and customer's... Satisfaction. Satisfaction. Yes. But this... From what I've been told, this can be also done without CSS and using just a simple LLM with RAG on top or on DC? So, what is the difference now? Using the... Can you just give me a second, please? Okay. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, Amber Search. With this Amber Search, what they are doing is they have a little... They train... They have a model. They put on this model the documentation of what happened from the OTC. And with this, this is the RAG part so that they do condemn the use case. It's to... To develop a chatbot with this chatbot the same as here. You have your help center. You start asking questions and it will be... It gives you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise what if your solution is better and we already don't know? So, please. So, let me show you this. Here, for example... Can you see my screen? Yes. No, I think you are not sharing. I know you are not. Okay. You see this in... So, this is... Behind this, as I told you, it's LLM with RAG and it's using only the documentation URLs that we have on the OTC. So, there is not a service description and so on. So, it would call, for example, here. Okay. So, this is the... How LTS support high availability. So, what this is doing, it's... You see in the left side, it's just the links that it found some kind of information but it's still not doing something. And on the right side, it's this... So, it's not doing anything. It's not doing anything. It's just... So, it's just... Summary. Yeah. I just tried to creating some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC. So, because we have this as basis. At the end, when it is completely finished, you may see, for example, here, this number one. And it's the reference that has been used for this answer for this part here. Number two refers to this one. And three and two is just a mix... This sentence is from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation where it has been find this kind of information on that sentence. And the same also for the other one. As you see, I didn't use CSS. I'm not using also vector database. It's just an LN and also ARG. That ARG is just connected to this URL docs OTC systems comes no more, no less. I think, principally, it's... Technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So I guess, technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. And what is the cost? And what is the actual business model? Because in this case, this is obviously being focused on end users, right? So if you want to make this happen again for your end customers, if you are like, for example, I don't know, a system integrator or something like that. You have to be either a partner of mBus search then again, or you have to make a commercial model with them to sell this to your own end customers. So this can be relatively complex and then also become a matter of cost related to that. Since I don't know how mBus search is charging and what they kind of invoke in business model means. And I have also no answer for the actual business model. I think anyway, these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business quality output. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here. I just asked in Q2. Yes. I can see English because you see that the documentation is also in English related. Correct? So, but I can also ask the same question in German and I will get the answer in German. Also with the reference in English. Yes. I think it's similar question, same way and try to translate in German. You are now the... You are German. I didn't know if I did some mistake or not. I think it's the same question. I think it's the same way. I think it's the same way. I think it's the same way. I think it's the same way. I think it's the same way. You are German. You know if I did some mistakes. How does the area S-Vof-Verfügbarkeit work? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think the right side where it's still giving the answers looks good so far. Just looks primarily standby, so failover. So, you see. And this... In this solution I just got this and you may see here. The reference also I have a reference, but when we select the reference it will be forward me to the documentation still in English. So, that means this model can just support German and English and you see also a way to... Even if I'm German and I don't... I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of this answer here. So, it depends on the answer, on the question. But you may see how it works. Okay. So, if you have this also with your solution integrated, a similar way of it, will be of course a very good... We are now customers for it and I'm pretty sure we have still in the German customers that are looking also for this kind of solution. For example. Yes. For your question, like what's the difference between... Between us and the Amber Search? You mentioned they use the open source model to retrain the... Retrain the model. Yeah. They have their own embedding function. They have built their own knowledge bases. Yes. You can always use that in the... With the open source. You can build an end-to-end solution, product with all... Using all the open source solution. Yes. Yes, there's no problem. I can tell you that. Basically, you can build everything with open source nowadays. But why people still go to the commercial? Why people buy the open source when they have the open search? You know CSS open search? Yeah. Even though open search is open source and they still go to Amazon to buy it. Why? Because they don't know how to use it. Yeah. We have different... We can see in different angle. Yes, the open source is cheaper, but as I mentioned before, cheap free cost most. Yeah. When the server's down, when the server is misfunction, nobody care. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We have... Also have me to help you build a... Take a look with what's your problem, give you some advice to... That's all the commercial does. So similar story here. Yes. My question to you, Joshua. I like it. I don't say that it's wrong or that we're wrong. No. I would like to hear from you or Thomas or Huawei. If we can also offer with the something like this. I mean similar to what's for English, German, like you see because... I think the demo would be really helpful. Yes, exactly. Yes, a demo will be very helpful. Let me... If there's something like this, I mean open source, okay, fine for me. But if you can achieve such quality with open source like this, it could be a very good... I will propose also your solution because if you achieve such quality, it's not going to be a good solution. If you achieve such kind of results, why not? It wouldn't be the last one that I will say no. Yeah. I mean, do you need time to prepare a demo? I mean, if you find something like this... I saw that they are doing quite good for my first... And yes, I can go back to R&D and... Found a solution. Yes. Yes. I will go back and find a demo for you and see how they are working out. But currently, it's not good, very... The large language model is not very good at German. So when you speak German to them, it probably will just reply English or just randomly mumble something. That's one of the drawbacks. But I think what can I do, but most likely is demo will be English. Okay. If it is in English also, I think it would be a good start, you know, because we are here in Europe, so most of the people that are interconnected, they speak English, so that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, let's continue with your presentation. I have another question about CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I am presenting now is the cool search, the CSS for IG solution. And currently it is... Yeah, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use in other scenarios, any IG use cases can buy our CSS with databases. And the... The... One of the core competitive needs is... I'm not sure on my screen. It says, Joshua, I start, maybe you stop it and start again. Yeah. One of the very competitive for our CSS is... Oh. I think I was offline. Sorry, let me reconnect it to the network. Mm-hmm. Okay. We are now bringing in... You cannot do all of the work that we are talking about in this session. Okay? Yeah, but... It does seem it would be the problem and I'm giving false information for the sake of this presentation. No. You should. No, of course not. Okay. Hello. Hello, you asked where you from in the US? I'm from New gelean, South Africa. Oh, I see. I was born here five years ago and you are from Set back there. Is it under his No, but my name statement is being like this. No, not electronic identification. Let me just reconnect into the session, rejoin the session. So during this time, guys from the team, what do you think about this solution from Georgia? It would be nice to know how the customer can make use of this, whether it's an individual product or they can use this and they go to the CSS page or something like that, or how can they access this? Yeah. I'm not sure I understood your question correctly. So you say how people are going to use this cool search, right? This is an outbox server, so it itself is a server. Okay. So this is a product you can find on the console? Yes. You can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. Okay. I have some access to the Huawei Cloud. Yeah, access to the Huawei Cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. I'm not sure I understand what you're saying. I'm not sure I understand what you're saying. I'm not sure I understand what you're saying. Okay. So you can see the code. Now when we are all sitting together, we will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. And then I'm in the right region, so I'm in Hong Kong region, it's fine? No. Or should I change to Beijing? No, you should change to Beijing. Okay. Let's change to Beijing. Okay. Because Beijing 1 is a Beijing version. Okay. So I can see the code. Okay. So I can see the code. Okay. So I can see the code. Okay. So I can see the code. Okay. So you can see the code. You can see the code. Okay. So this is in Beijing 1 or Beijing 4? Oh, did you see the code search suddenly disappear? Yes, disappear just a little bit. I think you have to use the... International? No international. China Mainland. China Mainland. Upper right corner, I mean we changed the access capabilities, but if you are able to choose Beijing 1, he is in China Mainland already. Otherwise... We've changed the access capabilities already. Okay. You're getting the access capabilities. We reached Beijing. You're getting the access capabilities. Okay. So you can choose Beijing 1. Yeah, we've changed the access capabilities. Okay. So we have listed the one in the right page. But if you are able to choose Beijing when he is in China mainland already, otherwise he wouldn't be able to. But the account is not. The account is international, so it may not be available international right now. But I can show you mine. You can show us. Okay, let's see. I will stop sharing. We have different kind of accounts globally. I see that. We have European accounts, accounts for China mainland and international. They have different permissions. Okay, let's see. But this is supposed to be also available for me, or not? I don't know. They don't like me. I mean I don't even have access to China mainland anymore. I'm only allowed to use Europe as employee. Only the region where you are usually working actually. So... This is what Joshua also just mentioned. For me, it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because latency. No, no. It's just like, I would say bureaucracy and budget. Ah, yes, yes. So Joshua, if you are sharing, I want to tell you you are not sharing. Oh, I'm not sharing. Okay. But I'm pretty sure you were only... You see, this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, da-da-da-da-da, platform. If you click this, it will ask you if you don't have permission, da-da-da-da-da, a platform permission. Yeah, I don't have this permission, so I cannot access it anywhere. So my story ends here. Yeah. Okay. Go to... But this is... That also says NFPs are changing. Yeah, then take it to our permission. So they keep using NFPs. Yeah. Okay. So you're saying that the MLP service? Yeah. Then maybe you share your... Did we mention that before? The MLP could be also a component behind the scenes? I cut this in. Okay. Maybe I missed that part. So in order to have this, we would have to have an NFT as well? No. Right. I mean, principally, yes, but not as a service presented to the customer, right? This is a service. This is a service. This is what we discussed before. Yeah. Oh, okay. Okay. Gotcha. Okay. I saw. I see that Yahoo. Yeah. That's the story. I can try to get the permission and see if me or somebody else going to show you this demo. Yes. Perfect. My key message is our... Yeah. Our CSS for RAG solution have this query rewriting and result re-ranking function. And even without those, even without the Pangu itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the... This is the... This is the approximate nearly neighbor... Near t-stutter neighbor search function is a search function in the benchmark. It compare with all those algorithm or... No algorithm. This is all the... Searching engine. Searching engine. Yes. Yeah. Yeah. Yeah. Yeah. This file is very... This file is also very popular. You see 28k is made by the Facebook and yeah, it compare all of them. You can see our Huawei's searching algorithm is QSGNGT. I don't even know how to spell it. This is Huawei's algorithm. I just say it. It's just a... Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. is inside the CSS, you see, QSGMGT and this is the performance, you see, it's a green X here on the very top So they are sorted from the best, I mean the list with colors on the right side is the ranking? Yes, the red side here is like which one represents which graph Yes, yes, I know It's not necessarily by order, you can only see that it's queries per second, so the more queries they do, the better Yes, in the same record rate, the more query per second is better So you see at the same record rate, our Huawei CSS searching performance is always good So you see at the same record rate, our Huawei CSS searching performance is always good the top highest yeah see this line here and horizontally the same speed the Q represent and we will call speed number per second right the higher record higher record will be better we all know what record is right copy the address right yes sure sorry I just looking for you put it on solid then I can put it on check okay yeah and this this repository is now maintained by Huawei and you can see is a red is also very active a couple days ago yeah that's the last year four days ago yeah yeah so I think you can also show step otherwise searching engine is already have coming something yeah could be some competitive and the rest of them the rest of the image is also similar to the previous one story yeah but for different tasks that was all test yeah you can see how is the QS something something is also kind of competitive be something yeah competitive yeah so that's that's one of the main point the other point is all writing down in the CSS release no and CSS promotions guys lies all those stuff is there so even without the pangu model CSS itself could be something so that that that's all for the this CSS story and my represent my presentation should be end here if you don't have any other question do we have any other question guys okay probably good okay guys then we will close the session thank you so much for joining hey wait I think Milan Oscar we hope no Martin is Oscar if the IG can use for the Help Center chatbot and I understand you correctly okay this was just basically I had the same question I had the same question yeah my question my answer will be yes no there's no problem to build this and it's not it's nothing hard I'd be one small demo before you see there is for OCS documentation QA search is nothing hard and yeah so the answer you'll be yes documents or English it could be doing very well yeah that's all for my presentation and based on my ally my very last topic is a little bit more discussion with the model ask or marketing it's a brainstorm stuff and see if we want to talk about this because you know the model is a very good model and it's very good and it's very good to know that it's a very good model and it's a very good model and it's very good to be if you decide to be me yeah I they result off that I'm thinking yeah I'll have to see behind me good D say give them any advice they can see if they have a workaround or solution or just add this feature and they start developing right now yeah we have we have this chance so we can have a small brainstorm in this session or maybe find another session to to talk about this if you ask me this right now i believe there's only just one way to find this out do you have a kind of benchmark of the current version for model arts compared for example with uh with aws um with the all other similar products uh i know this is sake maker then in asia google it's called i think machine learning uh i think i think machine learning is for asia the google is a v something but i mean if you if you have some kind of benchmark compared with a similar ml solutions then it will be more simple to figure out in which station should we see the improvement on it right it's a little bit different uh model ours is not like css css we compare with the speed and recall it's very clear because css only do search and uh modos is still machine learning and we don't have this benchmark for machine learning i i don't i don't i don't it's more about the feature set comparison right yes indeed what what they might offer what we don't currently yes all day my offer what we don't what we see that it's a good feature maybe we would like to edit it now it's a good chance to talk about it and uh i'm not sure if you think it's going to be a problem now the window is open. You still don't know what the new version, or the fourth jump, you still don't know what it will have? You can, we can do it in several steps. Once we can get the release now, second you can go to the Huawei Cloud and check out the latest Moto R directly. The latest, do you know what version the Huawei Cloud is running? Doesn't really matter. If you see it's good, then when the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following, because I know, I mean I am also the same opinion as Diego, because we all know that Huawei Clouds in their regions, they offer different versions. Just go to Beijing for it. Totally. Exactly. What you could provide us is which region has the same version or similar version as we will get on the OTC, so that we can just get a better, I mean we can test everything of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region and Huawei Cloud has the current version that we will deliver. Okay. So we will get the release, but really also the feature level and we can also figure out or see what is the difference, because you know release notes, okay fine for me, but we need to touch it, to check it and also for example we have here on our team, Matt and Ferry or Schultz or Vinet or I don't know, all the team members could also just check it and see what features are there really. Okay. So we can see what features are there, what are the features that are currently running, we can see and probably also evaluate if there is some kind of, I mean after that, when we have the list of these features, we can just see with customers if they are looking for another features than this model. I was thinking... I think I missed the point the first time. So what Joshua you were saying is that now we have a timeframe where ModernArts R&D is giving us this kind of information. Giving us the opportunity to give feedback on what we would like to have in the future, right? Yes, indeed. So I was thinking differently. So I was thinking like if you see Amazon have this feature, I think it's good. Google have this feature, I think it's also good. Just list all what you think is good and let the R&D says it's available, yes or no, or do we have a workaround or do we have redeveloping something. But yeah, that's my point. Okay, for this we can use the public cloud model, it doesn't really matter. Yes, it doesn't really matter. It would be maybe months or of course months, but maybe half a year or so before this appears on OTC, whatever we request, right? Okay, we can do that. Do you know how long this window is open? Uh... Yesterday. Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind, so I will bring up the customized image, this topic to them. And I do hope we can add more good feature inside it. So I don't know if I make my point clear. Now I tell R&D, say, hey, your AI framework is relatively old. I would like to have some feature that can have latest framework, latest driver, CUDA, PyTorch, TensorFlow, latest version. I want to customize. I would like to make decision which one is good, which we choose which framework. Yeah, I would like to have this framework. Yeah. I would like to have this feature. Now I bring this to them. And I also want to have some idea like add this feature that OTC can customize their own image like inference with Lama3 or training with Lama3, those image. And OTC can develop this image and make it available to customer. So the customer just one click and they can deploy the Lama3 already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's what I want to talk about. And give us, I think, some time, two weeks. I don't know how long. Yeah, as soon as possible. Because developing also needs some time. OK, yes. We will try our best. How about we do this. So our next sprint starts on next Monday. So we allocate maybe. One or two days or from you guys. So in this case. So Matt, Joel, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public cloud. If you don't. Then Hector could provide you a user account. Or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing GCP, Azure and so on. Yes. And let's say the week after we head together again. And we talk about this. Time for me. Great. Sounds great. I just want to ask one additional or one small topic. Which would help us going to market. It's a simple logo made for Europe or certified by for European usage or leveraged for Germany or something. I think you are totally right. But yes, they can work. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernst & Young after the last audit. They invited me for an interview. And, you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst & Young at that time was already planning to offer to the systems to audit against AIC4 or whatever comes in future in addition. So things like AI act, etc. So I think it's like a matter of time when OTC will have to review exactly this again and raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. And then we have to make sure that we have a good standard for the next audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking for a date on us. Okay. We have to make our own stamp there, right? Okay, guys. Then it's now time for lunch. Thank you so much for joining this session. Gergo, you just let me know who should come next. Okay. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. And let me know who should then add to the Huawei tenant for next week to take care of this model arts, and I will then add them to Huawei cloud and this is it, I think. Okay. Please create one for John, Terry, and Matt. Okay. John, Terry, Matt. Okay. Yep. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. And I'll see you in the corporate things. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Thank you. Bye. Bye. So let's go for lunch, I think. I don't know what they want. Nice presentation. Thank you, Joshua. Joshua. Thank you. I like it. Thank you. Thank you. Thank you.
In this meeting, the team discussed feedback on ModernArts R&D and features that could be added to make Huawei's cloud more competitive with public clouds such as Amazon and Google. The team wants to compile a list of desired features and provide it to R&D for consideration in future updates. They also discussed giving access to public cloud models to team members so they can compare features and provide feedback. A timeframe was mentioned, but the exact duration is unclear. It may take several months or half a year for requested features to be implemented on Huawei's cloud (OTC). The team will allocate time in their next sprint starting next Monday to compare GCP, Azure, and other public clouds. Hector will provide user accounts for those who need access. The team also discussed the possibility of creating a logo or certification for European usage, but it may take some time as they are currently certified with AIC4 and C5. The meeting concluded with plans for lunch and next steps to add team members to Huawei's cloud tenant for further discussions on ModelArts R&D features.ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 720, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 736, in simple_response
    await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/routing.py", line 72, in app
    response = await func(request)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/routes.py", line 1116, in upload_file
    form = await multipart_parser.parse()
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 603, in parse
    async for chunk in self.stream:
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/starlette/requests.py", line 238, in stream
    raise ClientDisconnect()
starlette.requests.ClientDisconnect
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpfu_p26v0
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, 10 years from this, we started working with the presentation. It was regarding as we all remember CSS. It's in RIG, also, Pongo Semantic, Modern for that subject. Yes, sure. Share your slides. So, so that everyone knows what you are talking. Yes, exactly. We stay here. Yeah, we stay here. Competitiveness between CSS, Solution and Open AR, right? Yes, we do have some competitiveness with the existing large-led grid model, but this is nonsense. You don't, you don't, you don't look this because it's only for Chinese embedding. We don't have the conquer accuracy for English embedding yet. But, yet. But my point is CSS can itself do no need to show you with this embedding model or any Pongo lingerie, large-led grid model itself is a very good data basis and Victor, beta, Victor databases. I will show you the competitiveness of CSS itself to other open source CSS later. Yeah, I don't have that much left to talk about with this slide. This is a successful story, you CSS with this IG solution to be a customer service assistance. I believe we are all very familiar with this kind of story, like a user IG to search the most correlated response, like how to deal with angry customer. And it will just generate the most proper answer based on the current situation. And just like a cold ass tab, you generate cold, you generate the answer. Basically, it's the same thing. I will give you the slide to read after the meeting. Demo, I don't have the demo yet. I was no able to access to the demo. You feel free to click this link, but I don't think it's going anywhere. So, it's called cold search. Yeah, it's called cold search indeed. It's so that means what cold search it is this it's called this solution integrate the combo with CSS. It's called cold search. Yes, indeed. I don't ask me why is coco search somebody that decides coco search and this coco search. Okay, the next question is since a combo. Pango is something that we don't have here and all this thing. Pango exists already since two years or a while ago because I remember last year. I was not in this world of ice summit, but one year before he got the main stage and percent something about combo for this electricity stove with electricity. Yes, the electricity with power. Yes, there. So, the question is since that was more than a two in what are the current use cases that you already have with this solution. Real use cases and real customers. Real use cases and real customer. So, this is more like a bridge stone part. It's not like a bridge stone part. Yes, we have a lot of different Pango model. As you may already know, we have the CV different Pango model for different AI test. For example, CV, we have the electricity tower, we have the TFDS. Those are actually have customer in using of those. And CSS and Pango. I mean, we're talking about the normal tango cold search. I mean, for course, it just showed the case. Yeah, I just showed the cases. But it's not a real customer. This is a real customer. It's a real customer. It's a real customer. The real customer is doing what? Using this RHE to build a customer server's assistance. Like a support. Yeah, customer support. Or help center. What kind of customers began with the bank or what? Yes, a bank. Well, however, we have a lot of customer with bank. So, you've seen CSS, which is the RHE. Yes, Pango, together, and they are using what's injected on this RHE. What's injected in the, you mean, injecting to this IGE base? Is the customer's servers, his historical chat record? Like, basically, this is chosen by this database, is chosen by human. How to deal with angry customer? How to answer this question? Confircant QA question. And all those data are put together and fitted to this IGE. So, when a customer, when a customer finds your customer's servers, they always want those kind of things, right? I go charge, I don't know how to use this. And those are mostly of the answers in the frequent RQA. And they just don't bother to read it. So, this IGE will help the customer's servers, to get the correct response to those customer. So, the worry of this is in both the efficiency and customer's services. So, it's a fashion. Yes. But this, from what we've done, we've also done without CSS, and using just a simple LLM with RG on top, or on this. So, what is the difference? You see the... I just give a second. I'm sorry, I didn't... I have a nowadays, what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they have a... They train, they have a model. They put on this model the documentation of what I'm from the OTC. And with this, this is the RG part, so that they do condemn the use case. It's to develop a chatbot. With this chatbot, the same as here. You have your help center. You start asking questions, and it will be to give you the right answer. Also with the reference. Let me show you exactly what I mean, only that you know this, and then you can tell me what is the difference. For me, it's important to understand what is the difference, because otherwise, what if your solution is better, and we already don't know. So, let me show you this. Here, for example, can you see my screen? Yes. So, I think you are not sharing. Okay, you see this. So, this is behind this. As I told you, it's an LM with RG, and it's used to use the documentation you are. So, it will have an OTC. So, there is not service description. So, if we call, for example, here, how LDS support... I don't know, but it's updating. So, what this is doing, it's to see in the left side, is just the links that it found some kind of information, but it's not doing something on the right side. It's the summary. I try to create some kind of response. Nevertheless, when it is then really undone with all that information that is creating, of course, all that information is based on the documentation of the OTC. So, because we have these as spaces. At the end, when it is completely finished, you may see, for example, here, there's number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two are just a mixed sentences from between two. When I just want to go and see exactly if this answer is correct. I just here select the number one, and it forward me to the documentation, or else that it has been found this kind of information on that sentence. And the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It shows LN and also RG. That RG is just connected to these URL docs of the C systems. No more, no less. I think, principally, technically, it's more or less doing the same right. It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So, I guess, technically, there's not much difference in what you finally get. The question is, how complex is this Huawei 4-striple? Yes, yes, one is the cost. And what is the actual business model? In this case, this obviously being focused on end users. So, if you want to make this happen again for your end customers, if you're like, for example, I don't know, the system integrator or something like this. You have to be either the partner of M-Bus search then again, or you have to make a commercial model with them to sell this to your own end customers. So, this can be relatively complex and then also become a matter of cost related to that. Since I don't know how end users are charging and what they kind of invoke in business model means. And I have also no answer for the actual business model that is behind this. For the moment, I think, anyway, these are the things that we would have to compare. I mean, I do have a sense of it. I mean, it's not the technology set. The answer is also the business quality output. How should I compare this now? I have no idea. Can you say this will be better or who worries about it? I think it's difficult to say. This I can show you. What is the difference? Also, one big difference of this solution. You can see here. I just ask in English, because you see that the documentation is also in English related. So, but I can also ask the same question in German. And I would get the answer in German, also with the reference in English. So, I think similar questions, similar way, I'm trying to translate them. German, you are not there. You are German. I did some mistakes. How does it work? I think the question is good. The answer is that I see so far on the left side are not like that applicable. But I think. In the right side where it's giving the answer is looks good. So far. It looks like a prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. One, what would you select the reference? It would be 4 words, it would be 4 words, the documentation, and the English. So, that means this multiple I can't use it for German. In English, and you see also a way to ... Even if I'm German and I do not, I am not really confident with English and so on. If you have this also with your solution integrated, I'll say a similar way of it. Of course, we have very good, we are now personal for it, and I'm pretty sure we have still on the in-general, customers that are looking also for this kind of solution. For example, yes, for your question, what's the difference between us and the end-boss search? We mentioned they use the open source model to return the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. You can build an end-to-end solution, with all the open source solutions. Yes, there's no problem. I can tell you that basically you can build everything with open source. But why people still go to the commercial? Why people buy open source? When they have open source, you know, CSS, open source. Even though open source is open source, and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheap, but as I mentioned before, cheap with free cost most. When the server is stung, when the server is misfunction, nobody, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least SIE will take a look when something goes wrong. SIE will help you answer the question. We also have a me to help you build a take a look if it was your problem, if you were some advice to... That's all the commercial does. So, a similar story here. Yes? The question to you, Michelle. I like it. I don't say that it's wrong. That's wrong. I would like to hear from you or Thomas, or what we can also offer with you. Could you come, something like this? I'm in similar, English, German, like you see? Because I think that more will be really important. Yes, exactly. That more will be very helpful. I think that's something like this. Open source, okay, fine for me. But if you can achieve such quality with open source like this, it could be very good. I will propose also your solution because if you achieve such kind of results, why not? I won't be the last one that I will say no. Yeah, I'll be doing good. I'd like to prepare a demo. I don't need to find something like this. I saw that I must have there doing quite good for my first pet. Yes, I can go back to Andy and find a demo for you and see how they are working on it. But currently, the large language model is very good at German. When you speak German to them, you probably will just repry English or just render them on both something. That's one of the drawbacks. But I think what can I do? Most likely, the demo will be English. If it's English, I think it would be good start, because we are here in Europe. Most of the people that are interconnected, they speak English. That would be very, very good start. We can extend it later, but for the first version, that would be amazing. Okay, let's continue with your presentation. I have another question about what do you see? This is just one example for our health center. Do you believe that are other use cases also related to this one that you are presenting? What I'm presenting now is the co-search is CSS for IG solution. Currently, like I said, it's only for IG solution. Only IG is strongly related. And for your question, if you can use in other scenarios, and IG use cases can buy our CSS with databases, with databases. One of the core competitively is, I'm not sure on my screen. It says, socialize tasks, and reviews of it and stuff again. One of the very competitive for our CSS is, oh, I think I was offline. Sorry, let me reconnect it to the network. Not just because you changed the... You can see how I've heard your phone. Can you see my screen? No, no, it's a work of company. After you... Let me just reconnect it to the... The joint session. The joint session. So, during this time, guys, from the team, what do you think about this solution from your... We're being nice to know how the customer can make use of this. So, whether... this is an individual product, or they can use this, and they go to the CSS page, or some kind of... or how can they access this? I'm not sure. I understand your question correctly. So, you say how people are going to use this... ...coursage, right? This is our box server. So, it's self-user servers. Okay, so this is a product you can find on the console. Yes, you can go to the hallways, latest CSS version right now. I believe you can see something similar to it. But I... To actually SSC, you need to register for permission. My permission is now available yet. That's why... That's why I can't show you the demo. Okay, that's it. I have some... Also, the access to the Go over cloud. Yeah, as I said to the hardware cloud. I'm also really curious, because I like it. For me honest, I really like it, what you percent. Now, when we are all sitting to Edborough, you will have the chance to... to save. So, this is a CSS right? Yes, in CSS. Okay. And then I... I'm in the right region, so I'm from over here. It's fine. Or should I use the... Now, to be... Change it to Beijing. Okay, let's change to Beijing. Use Beijing 1, is Beijing 1 or Beijing 4? Oh, use... Did you see the close-up suddenly disappear? Yes, disappear. Use a little... I think you use the... You have to use the... How... No international. China mainland. China mainland. Upper or right corner, I mean we change the access capabilities. So... But if you are able to choose Beijing 1, is... in China mainland, or otherwise it wouldn't be... But the Hong is not. Yeah. The Hong is international. So, it may not be available international in the... right now, but I can show you... Show you my... I think so. Okay, let's see. I would stop sharing that. We have different kind of accounts globally. I see that the... So, we have different accounts... We have different accounts... I think it's a... Accounts for China mainland and international... They have different commissions. Okay. Let's see. But this is supposed to be also available for me or... I don't know. But I... They don't like me. I mean, I don't even have access to China mainland anymore. I'm only allowed to use... You... You... As an employee. Only the region where you are usually working actually. So, this is what... Joshua also just mentioned for me. It's actually very difficult at the moment to get access for... Chinese resources. Oh. It's because latency. Oh, no. It's just like... I'm just... You're only for seeing budgets. Oh, yes, yes. So, Joshua, you are sharing? I know. I'm not sharing. You want to tell me what you are not sharing? Oh, I'm not sharing. Okay. What time did you work on? You see, this is Beijing4 region. And this is the CS console right now. I have the cool search document, the platform. If you click this, you will ask you if you don't have permission, that the... A prefer permission. Yeah, I don't have this permission, so I cannot assess it anywhere. So, my story ends here. Yeah. Okay, go talk. But this is... That also said... And I have company talking. So, that's what you are using in an app. Yes. Yeah. Then maybe you share your... You know, those solutions. I'll... Do we mention that before the MLB could be also component behind the scenes? I can't... Maybe I missed that part. So, you know that to have this, we would have to have an app here as well. No. Right. I mean, principally, yes. But not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, okay, question. Okay. I saw, I see, take your who. Yeah, that's the... That's the... Sorry, I can try to get permission and see if... Fun. Me or somebody else going to share this demo. Yes. Perfect. My key message is our CSS for RIG solution. This Q-ring handwriting and the result with ranking function. Even without the... Even without the PANGW, itself is a very good... Wiktor databases. And here is... Let me show you the GitHub for benchmark. This is the... This is the... Apox made nearly... Neatist... Nebosuch function is... It's a search function in the benchmark. It compare with all those... Algorithms or... Or... No, no, Algorithms. This is all the... Searching engine. Searching engine, yes. This... This file is also very popular. The... 28K is made by Facebook and... Yeah. It compare all of them. You can see... Our Huawei search in Algorithms is QS-GN GT. I don't even know how to spell it. This is... This is Huawei's... Algorithms is inside the CSS. Yeah. You see... QS-GN GT. And this is the performance. You see... It's a green X here... On the very top. So they are sorted from the best. I mean, the list... With colors on the right side is... The ranking... Yeah, the best to the... The right side here is... It's like which one represent which graph? Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes. In the same record rate, the more... QRIP per second is better. So you see... At the same record rate, our Huawei... CSS Searching performance is always the top... Highest. Yeah. See this line here. And the horizontally... The same speed. The QRIP per second. And we will call it speed. You guys... Number per second, right? The higher record... Higher record will be better. Or what record you... The chips... So do you guys... Says to this... Copy this... Of the digest. Yes, yes. Sure. So the digest has not to type this... It's... Where is it? Where is it? Sorry, I just looking for... Oh, yeah, yeah. Did you put it on the... So, lip, then I can put it on chip. Oh, okay. So, that's what I mean. I think we must start and then... We got it. Yeah. And this... This repository is now maintained by Huawei. And you can see it's already... It's also very active a couple days ago. Yeah. Not so long ago. Yeah. Four days ago. Yeah. Yeah. So, I think you can also show that... Huawei's searching engine is already... ...coming something. Yeah. Could be some competitive news. And the rest of them... The rest of the... Image is also a similar story. But for different tasks. And you can see how it's... The QS something is also... ...kind of... ...competitive... ...be something, yeah. Competitive. Okay, fine. Yeah. So, that's one of the main points. The other point is already down in the CSS... ...revisual and CSS... ...promotion, guys, guys... All those stuff is there. So, even without a... ...pangu model, CSS itself could be something. So, that's all... ...for the CSS story. And my representation should be... ...and here, if you don't have any other question. Do we have any other question? Guys. Okay, from me. Good. I think, guys, then, we will close the session. Thank you so much for joining us. Wait, I think... ...Milan asked... No, Martin is... ...asked if the IG can use for the... ...help center chatbot. Am I understanding correctly? Okay, this was just basically... ...I have the same question already... ...or my echo. Okay. We saw it. Yes, my answer will be yes. There's no problem to build this... ...and it's nothing hard. I've been one... ...small demo before. You see there... ...you see for OCR's documentation... ...it's not in hard. And... ...so, the answer you'll be yes. The document is all English. It could be doing well. Yes, that's all for my presentation. And... ...based on my online... ...my very last topic is a little bit... ...small discussion with the Modo Asco Marketing. It's a brainstorm stuff... ...and... ...see if we want to talk about this... ...because you know the Modo Asco is... ...only in his way doing the upgrades smoothly... ...and... ...it will soon be a little upgrade to the latest... ...now we have a chance on the asking us... ...if you want to add any feature... ...anything to make it more sellable in... ...Europe. Anything, you can check the... ...Cow Google sales, how it sells... ...how Amazon sell their similar... ...similar part of... ...and give them any advice they can see... ...if you have a walk around or a solution... ...or just add this feature... ...they start developing right now. We have this chance, so... ...we can have a small brainstorm... ...in this session or maybe... ...find another session to talk about this. You asked me this one, now. I believe... ...there's only just one way to find this out. Do you have a kind of benchmark... ...of the current version from all of us... ...compared for example with AWS... ...with all other similar products? I... ...know this as a Saga Maker... ...then in... ...SagaWayPasher... ...SagaWayPasher... ...with Google, it's called... ...I think... ...WayPasher... ...and I think... ...I think... ...I think it's for HRR... ...the Google is V-Samsin. But I mean, if you... ...if you have some kind of benchmark... ...compared with similar... ...MN solutions... ...then it will be more simple to figure out... ...in which session... ...so we see the problem on it, right? It's a little bit different. The... ...mode of ours is known like CSS... ...we compare with the speed and the record... ...it's very clear because CSS only do such. And... ...mode of ours is too machine learning... ...and we don't have this benchmark for machine learning. I don't... ...I don't... Yes, it's more about the features that comparison. Yes, indeed. But what they might offer... ...but we don't currently. Yes, or they might offer what we don't... ...what we see... ...it's a good feature... ...maybe we would like to edit it... ...now it's a good chance to talk about it... ...and... ...yeah. Now the window is open. You still don't know what the new version... ...or the kind of port, you know, the port jump... ...is still not know what it will have. You can... ...we can do it in several steps... ...once we can get the release... ...now second you can go to the Huawei Cloud... ...and check out the latest mode of ours directly. The latest... ...we know what version... ...the Huawei Cloud is running. That's a very limited... ...if you see it's good... ...then when you upgrade it now... ...then you can always... ...demand it and edit to the latest version... ...and now the window is open. What we can do is follow in... ...because I know... ...I mean, I am also the same opinion as they were... ...because we already know... ...that all it is out there... ...regions... ...they offer different versions. Just go to Beijing for... Exactly. But would you provide us with which... ...region has the same version... ...or similar version as we will get on the Odyssey... ...so that we can just... ...get a better... ...I mean, we can test everything, of course... ...but we will never have the chance to test... ...ape this model, in this case. So, just give us an idea... ...which region and what we cloud... ...has the current version that we will get there later. But really, also the feature level... ...and we can also see what is the difference... ...because we know... ...release notes, okay, fine for me... ...but we need to touch it to check it... ...and also, for example, we have here... ...no team met and ferry... ...or short or vignette or either... ...or all the team members also do check it... ...and see what features are there... ...we need, running, we can see... ...and probably also evaluate if there is some kind of... ...I mean, after that, when we have the list of these features... ...we can just see with customers... ...if they are looking for another feature than this model. I was... ...sumping... I think I missed the point the first time. So, what just showed you are saying is that... ...now we have a time frame... ...where Model X R&D is giving us the opportunity... ...to give feedback on what we would like to have in the future, right? Yes, indeed. So, I was thinking differently... ...so I was thinking, you feel... ...see, our Amazon has this feature, I think it's good. Google has this feature, I think it's also good. Just a little bit, what you think is good... ...and like the RDS says, it's a variable... ...yes or no, do we have a workaround... ...or do we have redeveloping something? That's my point. Okay, for this we can use the public model... ...and say that it doesn't really matter. Yes, it doesn't really matter. It would be maybe months or... ...first months, maybe half a year or so before this... ...year is on ODC, whatever we request, right? Okay, we can do that. Do you know how long this window is open? Yesterday... ...now they have some session host and... ...tell us to give them feedback, I don't have anything on my mind... ...so I will bring up the customized image... ...disturbing to them. I do hope we can add more good features inside it... ...and so I don't know if I make my point clear. Now I tell Andy, say, hey... ...Ai Framework is related... ...I would like to have some features there... ...and have latest flamwork, latest driver,... ...cuda, PyTorch, Tenton Floor, latest version... ...I would like to have my decision... ...which one is good, which will choose which flamwork. I would like to have this feature. Now I will bring these two there... ...and I also want to have some idea... ...that OTC can customize their own image... ... like inference with flamwork or training with flamwork... ...those images. OTC can develop this image... ...and make it available to customers. So the customer just won't click... ...and they can deploy the flamwork. I also want to have this feature. But I have those things in my mind... ...but I do want some input from your guys... ...that's what I want to talk about. And if GIPP is, I think, some time, two weeks... ...I don't know how long will it be? Yes, as soon as possible. Yes, because developing also needs sometimes. Okay, yes. Where we try to go? So how about we do this? Our next string starts on next Monday... ...so we allocate maybe... ...on or two days... ...or from you guys. In this case, so Matt, Joel, Perry... ...so maybe each of you spend a one day... ...comparisoning this stuff. So I don't know if you guys have access to Bobbick. If you don't... ...then Hector could provide you an user account... ...or maybe an even I could, I don't know. Yes, maybe Hector can provide me an account as well. Okay, yes, guys. So we can give you an account. You spend one or two days... ...comparing the GCP, Asia, and so on. And in, let's say, the me-carcter... ...we had together again. And we talk about this. Okay, five more minutes. Great. That was great. And this one, we had one edition... ...or one small topic... ...for which it would help us going to market. It's a simple logo made for Europe... ...or certified by our European Union... ...or leverage for Germany or something. I think you are totally right, Matt, Joel. It's a little difficult because... ...we have no such stamp that we can get... ...for official stages right now. I think the best thing we have for the moment... ...is AIC4, right? And I had actually an interview with Aniston... ...and Jan, after the last audit... ...they invited me for an interview... ...and you know, we have currently C5. This is our principle cloud certification, yeah? And AIC4 is nothing that we audit at the moment. But Aniston Young... ...at that time was already planning... ...to offer to the systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time... ...when OTC will have to review exactly this again... ...and raise their hand and say, guys... ...now we have, I don't know, SOC, C5, IT Grundschutz... ...please audit and compliance. What the next thing we should do is... ...AIC4 audit or whatever applies... ...to have an official extent, right? I'm already looking for budget tonight. Okay. You may have to make an appointment. Okay, guys, then it's now time for launch. Thank you so much for joining this session. Gogo, just let me know who should... ...add to the Huawei tenant for next week... ...to take care of this wall of lots... ...and I will then add them to Huawei Cloud. This is it, I think. Okay, this is great, my version. Very and much. Okay, short for a minute. Okay, yeah. Okay. Great. Thanks for the time, colleagues. Thank you, thank you. And I speak to a couple of things. Thanks. Good bye. Good bye. So, let's go for launch, I think. Now I'm going to go to the left. Nice presentation. Thank you, Josh. Josh, thank you. I like it. Thank you, guys.
It seems like you're discussing feedback and feature requests for a Model X R&D project, possibly related to AI frameworks and cloud services. Here's a summary of your discussion:

1. **Feedback Window:** There is an opportunity for giving input on what features or improvements are desired for the future Model X.
2. **Feature Suggestions:**
   - Amazon and Google have certain features that you find beneficial; you want to incorporate similar functionalities into Model X.
3. **R&D Decision Variable:** The RDS (Research Development System) uses a variable system where decisions can be made based on yes or no feedback for each suggested feature.
4. **Time Frame:** It was mentioned that there's a window of opportunity, possibly months to half a year before the product goes on ODC (On-Demand Compute).
5. **Customized Images:** There is an interest in customizing images with specific frameworks like PyTorch or TensorFlow for inference and training purposes.
6. **OTC Customization:**
   - OTC can develop its own images based on customer preferences, allowing customers to quickly deploy their preferred framework by simply clicking a button.
7. **Input Needed:** There's a need for input from team members (Matt, Joel, Perry) regarding comparisons of GCP (Google Cloud Platform), AWS (Amazon Web Services), etc., in the context of the mentioned features.
8. **Access to Bobbick:** Team members need access to Bobbick or a similar system to perform their evaluations; Hector can provide user accounts for this purpose.
9. **Next Steps:**
   - Allocate one or two days from next Monday to compare different platforms and discuss findings in a meeting.
10. **Certification Discussion:**
    - A discussion about obtaining European Union certification or leveraging German standards was mentioned, highlighting the difficulty of getting official stamps at present.
    - Current certifications include C5 and AIC4 (AI Cloud 4), with plans to offer systems that comply with AI Act and similar regulations in future audits.

It looks like your team is focused on aligning Model X features with market needs, including compliance and customization options. Let me know if you need further clarification or assistance!Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
It seems like you're discussing feedback and feature requests for a Model X R&D project, possibly related to AI frameworks and cloud services. Here's a summary of your discussion:

1. **Feedback Window:** There is an opportunity for giving input on what features or improvements are desired for the future Model X.
2. **Feature Suggestions:**
   - Amazon and Google have certain features that you find beneficial; you want to incorporate similar functionalities into Model X.
3. **R&D Decision Variable:** The RDS (Research Development System) uses a variable system where decisions can be made based on yes or no feedback for each suggested feature.
4. **Time Frame:** It was mentioned that there's a window of opportunity, possibly months to half a year before the product goes on ODC (On-Demand Compute).
5. **Customized Images:** There is an interest in customizing images with specific frameworks like PyTorch or TensorFlow for inference and training purposes.
6. **OTC Customization:**
   - OTC can develop its own images based on customer preferences, allowing customers to quickly deploy their preferred framework by simply clicking a button.
7. **Input Needed:** There's a need for input from team members (Matt, Joel, Perry) regarding comparisons of GCP (Google Cloud Platform), AWS (Amazon Web Services), etc., in the context of the mentioned features.
8. **Access to Bobbick:** Team members need access to Bobbick or a similar system to perform their evaluations; Hector can provide user accounts for this purpose.
9. **Next Steps:**
   - Allocate one or two days from next Monday to compare different platforms and discuss findings in a meeting.
10. **Certification Discussion:**
    - A discussion about obtaining European Union certification or leveraging German standards was mentioned, highlighting the difficulty of getting official stamps at present.
    - Current certifications include C5 and AIC4 (AI Cloud 4), with plans to offer systems that comply with AI Act and similar regulations in future audits.

It looks like your team is focused on aligning Model X features with market needs, including compliance and customization options. Let me know if you need further clarification or assistance!
./tmpfu_p26v0/20240510_121130.m4a
临时文件夹地址：./tmpfu_p26v0
临时文件夹地址：./tmpfu_p26v0
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, 10 years from this, we started working with the presentation. It was regarding as we all remember CSS. It's in RIG, also, Pongo Semantic, Modern for that subject. Yes, sure. Share your slides. So, so that everyone knows what you are talking. Yes, exactly. We stay here. Yeah, we stay here. Competitiveness between CSS, Solution and Open AR, right? Yes, we do have some competitiveness with the existing large-led grid model, but this is nonsense. You don't, you don't, you don't look this because it's only for Chinese embedding. We don't have the conquer accuracy for English embedding yet. But, yet. But my point is CSS can itself do no need to show you with this embedding model or any Pongo lingerie, large-led grid model itself is a very good data basis and Victor, beta, Victor databases. I will show you the competitiveness of CSS itself to other open source CSS later. Yeah, I don't have that much left to talk about with this slide. This is a successful story, you CSS with this IG solution to be a customer service assistance. I believe we are all very familiar with this kind of story, like a user IG to search the most correlated response, like how to deal with angry customer. And it will just generate the most proper answer based on the current situation. And just like a cold ass tab, you generate cold, you generate the answer. Basically, it's the same thing. I will give you the slide to read after the meeting. Demo, I don't have the demo yet. I was no able to access to the demo. You feel free to click this link, but I don't think it's going anywhere. So, it's called cold search. Yeah, it's called cold search indeed. It's so that means what cold search it is this it's called this solution integrate the combo with CSS. It's called cold search. Yes, indeed. I don't ask me why is coco search somebody that decides coco search and this coco search. Okay, the next question is since a combo. Pango is something that we don't have here and all this thing. Pango exists already since two years or a while ago because I remember last year. I was not in this world of ice summit, but one year before he got the main stage and percent something about combo for this electricity stove with electricity. Yes, the electricity with power. Yes, there. So, the question is since that was more than a two in what are the current use cases that you already have with this solution. Real use cases and real customers. Real use cases and real customer. So, this is more like a bridge stone part. It's not like a bridge stone part. Yes, we have a lot of different Pango model. As you may already know, we have the CV different Pango model for different AI test. For example, CV, we have the electricity tower, we have the TFDS. Those are actually have customer in using of those. And CSS and Pango. I mean, we're talking about the normal tango cold search. I mean, for course, it just showed the case. Yeah, I just showed the cases. But it's not a real customer. This is a real customer. It's a real customer. It's a real customer. The real customer is doing what? Using this RHE to build a customer server's assistance. Like a support. Yeah, customer support. Or help center. What kind of customers began with the bank or what? Yes, a bank. Well, however, we have a lot of customer with bank. So, you've seen CSS, which is the RHE. Yes, Pango, together, and they are using what's injected on this RHE. What's injected in the, you mean, injecting to this IGE base? Is the customer's servers, his historical chat record? Like, basically, this is chosen by this database, is chosen by human. How to deal with angry customer? How to answer this question? Confircant QA question. And all those data are put together and fitted to this IGE. So, when a customer, when a customer finds your customer's servers, they always want those kind of things, right? I go charge, I don't know how to use this. And those are mostly of the answers in the frequent RQA. And they just don't bother to read it. So, this IGE will help the customer's servers, to get the correct response to those customer. So, the worry of this is in both the efficiency and customer's services. So, it's a fashion. Yes. But this, from what we've done, we've also done without CSS, and using just a simple LLM with RG on top, or on this. So, what is the difference? You see the... I just give a second. I'm sorry, I didn't... I have a nowadays, what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they have a... They train, they have a model. They put on this model the documentation of what I'm from the OTC. And with this, this is the RG part, so that they do condemn the use case. It's to develop a chatbot. With this chatbot, the same as here. You have your help center. You start asking questions, and it will be to give you the right answer. Also with the reference. Let me show you exactly what I mean, only that you know this, and then you can tell me what is the difference. For me, it's important to understand what is the difference, because otherwise, what if your solution is better, and we already don't know. So, let me show you this. Here, for example, can you see my screen? Yes. So, I think you are not sharing. Okay, you see this. So, this is behind this. As I told you, it's an LM with RG, and it's used to use the documentation you are. So, it will have an OTC. So, there is not service description. So, if we call, for example, here, how LDS support... I don't know, but it's updating. So, what this is doing, it's to see in the left side, is just the links that it found some kind of information, but it's not doing something on the right side. It's the summary. I try to create some kind of response. Nevertheless, when it is then really undone with all that information that is creating, of course, all that information is based on the documentation of the OTC. So, because we have these as spaces. At the end, when it is completely finished, you may see, for example, here, there's number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two are just a mixed sentences from between two. When I just want to go and see exactly if this answer is correct. I just here select the number one, and it forward me to the documentation, or else that it has been found this kind of information on that sentence. And the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It shows LN and also RG. That RG is just connected to these URL docs of the C systems. No more, no less. I think, principally, technically, it's more or less doing the same right. It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So, I guess, technically, there's not much difference in what you finally get. The question is, how complex is this Huawei 4-striple? Yes, yes, one is the cost. And what is the actual business model? In this case, this obviously being focused on end users. So, if you want to make this happen again for your end customers, if you're like, for example, I don't know, the system integrator or something like this. You have to be either the partner of M-Bus search then again, or you have to make a commercial model with them to sell this to your own end customers. So, this can be relatively complex and then also become a matter of cost related to that. Since I don't know how end users are charging and what they kind of invoke in business model means. And I have also no answer for the actual business model that is behind this. For the moment, I think, anyway, these are the things that we would have to compare. I mean, I do have a sense of it. I mean, it's not the technology set. The answer is also the business quality output. How should I compare this now? I have no idea. Can you say this will be better or who worries about it? I think it's difficult to say. This I can show you. What is the difference? Also, one big difference of this solution. You can see here. I just ask in English, because you see that the documentation is also in English related. So, but I can also ask the same question in German. And I would get the answer in German, also with the reference in English. So, I think similar questions, similar way, I'm trying to translate them. German, you are not there. You are German. I did some mistakes. How does it work? I think the question is good. The answer is that I see so far on the left side are not like that applicable. But I think. In the right side where it's giving the answer is looks good. So far. It looks like a prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. And what do you think is that if I get a question, and I can't see it, so I can't find the answer. I am not really confident with English or so on, so I can just select it. And I have exactly the reference to all of this answer of yours. So, it depends on the answer. And the question. The truth. The truth is, If you have this also with your solution integrated, I'll say a similar way of it. Of course, I'm very good. We have, we are now personal for it, and I'm pretty sure we have still on the in-general, customers that are looking also for this kind of solution. And for example, yes, for your question, like what's the difference between us and the embersage? We mentioned they use the open source model to return the, return the model. Yeah, they have their own embedding function. They have built their own knowledge bases. Yes, you can always use that in the open source. You can build an end to end solution. But with all using all the open source solutions, yes, there's no problem. I can tell you that. Basically, you can build everything with open source. Now, why people still go to the commercial? Why people buy the open source, when they have the open search, you know, CSS, open search. Yeah, even though open search is open source, and they still go to Amazon to buy it. Why? Yeah, we have different, we can see in different angles. Yes, the open source is cheap, but as I mentioned before, cheap, free cost most. When the server is done, when the server is misfunction, nobody, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong, where SIE will help you answer the question. Now we also have me to help you build a take a look if it was your problem, give you some advice to just know the commercial does. So, a similar story here. Yes. Good question to you, Michelle. I like it. And I don't say that it's wrong, on the wrong, no? I would like to hear from you or Thomas, what we can also offer with the coupon, something like this. I mean, for English, in German, like you see, because I think that more will be really helpful. Yes, exactly. And if that more will be very helpful, let me something like this. I mean, open source, okay, fine for me, but if you can achieve such quality with open source like this, it could be very good. I will propose also your solution because if you achieve such kind of source, why not? I wouldn't be the last one that I was able to say no. Yeah, I mean, do you think I'm going to prepare a demo and if you find something like this? I thought I was actually doing quite good for my first, this pet. And yes, I can go back to Andy and, find a demo for you and see how they are working on it. But currently, it's not very, the large language model is very, not very good at German, so when you speak German to them, you probably will just reply English or just randomly mumble something. That's one of the drawbacks. But I think what can I do? But most likely, is demo will be English. If it's English, so I think it would be good start, because I think we are here in Europe, so most of the people that are interconnected, they speak English, so that would be very, very, very start. So we can extend it later, but for the first version, that would be amazing. Okay, let's continue with your presentation. I have another question of what the CSS says. This is just one example for our health center. And do you believe that our another use cases also related to this one that you are presenting? Yes. What I'm presenting now is the co-sert, is CSS for IG solution. And currently, it's, like I say, it's only for IG solution. So only IG is strongly related. And for your question, if you can use in other scenarios, any IG use cases can buy our CSS with databases, with databases. And the one of the core competently, this is, I'm not sure, am I screened? It says, socialize, especially reviews. So we didn't start again. Yeah. One of the very competitive for our CSS is, oh, I think I was offline, sorry, let me reconnect it with the network. Okay. Just because you changed the... You can see, I thought I was your partner. Can you see my screen? No, no, but it will become. What do you... Let me just reconnect into the... Just join the session. Join the session, yes. So during this time, guys, from the team, what do you think about this solution from your job? It would be nice to know how the customer can make use of this. So whether this is an individual product or they can use this and they go to the CSS page or something like that, or how can they access this? I'm not sure. I understand your question correctly. So you say how people going to use this co-sert, right? This is our box service. So it is self-user service. Okay, so this is a product you can find on the console? Yes, you can go to the hallways, latest CSS version right now. I believe you can see something similar to it. But to actually SSC, you need to register for permission. My permission is now available yet. That's why I can't show you the demo. Okay, that's it. I have some awesome access to the Go over cloud. Yeah, access to the Go over cloud. I'm also really curious because I like it. For me honest, I really like it. What do you present? Now when we are all sitting to Edborough, we will have the chance to see it. So this is since CSS right to SS. Yes, yes, yes. Okay. And then I am in the right region, so I am from over here, it's fine. I'm not sure if you would change it to Beijing. Okay, let's change to Beijing. Just Beijing 1 is Beijing 1 or Beijing 4. Did you feel the closer to suddenly this peer? Yes, this peer introduced a bit to you. I think you have to use the how? International. No international. China mainland. Upper or right corner? I mean we change the access capabilities. But if you are able to choose Beijing 1, it's in China mainland. Otherwise it wouldn't be... But our country is not. The country is international. It may not be available international in the right now. But I can show you my. Okay, let's see, I would stop sharing. We have different kinds of accounts globally. I see that. You see that accounts for China mainland and international. They have different provisions. Okay, let's see. But this is supposed to be also available for me or... I don't know. They don't like me. I mean I don't even have access to China mainland anymore. I'm only allowed to use Europe as an employee. Only the region where you are usually working actually. So this is what the Joshua also just mentioned for me. It's actually very difficult at the moment to get access for Chinese resources. That's because latency. No, no. It's just like... I would say... You're on the market. You're on the market. Ah, yes, yes. So Joshua, you are sharing? I'm actually going to tell you what you are not sharing. Oh, I'm not sharing. What time did you work on this? You see this is Beijing for region. And this is the CS console right now. I have the cool search document, the platform. If you click this, you will ask you if you don't have permission. You have a press of permission. I don't have this permission, so I cannot assess it anywhere. So my story ends here. No. Okay, go talk. But this is that also said. And I have company talking. So that's basically what you are using in an app. Yeah. Then maybe you share your experience with other sources. Do we mention that before the MLB could be also component behind the scenes? I can't believe it. Maybe I missed that part. So in order to have this, we would have to have an app. No. I mean, principally, yes, but not as a service presented to the customer. Right? This is what we discussed before. Yeah. Okay, question. I saw I see that your who. Yeah, that's the story. I can try to get permission and see if me or somebody else are going to show you this demo. Yes. Perfect. My key message is our CSS for RIG solution. This is a Q-ring writing and a result with ranking function. And even without those, even without the PANGOO, itself is a very good with data basis. And here is you. Let me show you the GitHub for benchmark. This is the. This is a. A pop's made nearly neighbor. Near to the neighbor search function is a. It's a search function in the. A benchmark. It compare with all those. Aggressor or. No, no, algorithm. This is all the. Search engine. Yes. This. This. This. Files. This is also what republic. You see 20 AKs made by the Facebook and. Compare all of them. You can see. Our Huawei's. Searching algorithm is QS GN GT. This. I don't even know how to spell it. This is. This is always. Aggressor is inside. Is inside. CSS. Yeah. You see. QS GN GT. And this is the. Performance. You see. Is green X here. On the very top. So they are sorted from the best. I mean, the list with colors on the right side is. The. The. The best. The. The rest of here is the. It's like which one represent the. Which. Which graph. Yes. Yes. And necessarily by order. You can only see that it's very. Second. So the more queries they do, the better. Yes. In the same record rate, the more. Q. Second is better. So you see. At the same record rate, our. Quarrel. CSS searching performance is always the top. High list. Yeah. See this line. Here. And horizontally. The same speed. The Q. We call speed. You guys. Number of percent. Right. The higher record. Higher record will be better. Okay. All know what record you. Right. The check. So the guys. Access to this. Copy. Offload. The digest. Right. Yes. Yes. Sure. So the guys has not to type this. It's. Where's the. Sorry. I just looking for. Oh, yeah. Would you put it on the. So that I can put it on check. Oh, okay. So that will be. I think we must. It's part. And. Yeah. And this. This repository is no maintained by Huawei. And you can see it's already. It's also very active. Couple days ago. Yeah. Yeah. And this. This repository is no maintained by Huawei. And you can see it's already. It's also very active. Couple days ago. Yeah. Not the last year. And for this ago. Yeah. Yeah. So I think. You can also show. That. Our. Search engine is already. Have. Coomin something. Yeah. Coopie some competitive. This. And the rest of them. The rest of the. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Image is also similar story. Uh. Uh. But for different tasks. Uh. Those are all tasks. And you can see. Uh. Always. The QS something is. Uh. Also. Uh. Kind of. Uh. Competit. Be something. Yeah. Competitivity. Okay. Yeah. So that's one of the main point. The other point is already down in the. Uh. Uh. Uh. CSS. Uh. Revisual. And. And. CSS. Promotion. Guy slice. All those stuff is there. So. Even without a. Uh. Pango mode of CSS itself could be something. So that. That's. That's all. For the. This. CSS. Uh. Story. And. My represent. My presentation. Uh. You should be. And here if you don't have any other question, we have any other question. Guys. Okay, problem. Good. I think I said we was the close session. Thank you so much for joining. I think. Meal and ass. if the IG can use for the health center chatbot. Am I understanding correctly? Okay, this was just basically I have the same question already brought up. I have to go out. Oh, okay. We saw it. It's very nice. Yeah, my question, my answer will be yes. No, there's no problem to build this and it's nothing hard. I've been one small demo before. You see there is for OCR's documentation. Good research is nothing hard. And so that's all you'll be. The document is all English. It could be doing well. Yeah, that's all for my presentation. And based on my online, my very last topic is a little bit small discussion with the model asker marketing. It's a brainstorm stuff. See if we want to talk about this because you know the model ask is on his way doing the upgrades smoothly. And it will soon a later upgrade to the latest. Now we have a chance on the asking us if you want to add any feature anything to make it more sellable in Europe. Anything you can check the call Google sales, how it sells, how Amazon sell their similar similar part and give them any advice they can see if you have a walk around or solution or just add this feature and they start developing right now. We have a we have this chance. So we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there's only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS with all other similar products? I know this is Saga Maker, then in Facebook. That's my guy. Wait, Google, it's called I think Google, I think it's like I think it's for HR or Google is V something. But I mean, if you have some kind of benchmark compared with similar MN solutions, then it will be more simple to figure out which session show we see the problem? It's right. It's a little bit different. ModOS is now like CSS. CSS we compare with the speed and the record. It's very clear because CSS only do such. And ModOS is too machine learning and we don't have this benchmark for machine learning. I don't, I don't. Yes, it's more about the features that compare itself. Yes. But what they might offer what we don't currently? Yes, what they might offer, what we don't, what we see, there is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. You can still know what the new version or the kind of port, you know, the port jump is still not know what it will have. You can do it in several set once we can get the release. Now second, you can go to the Huawei Cloud and check out the latest ModOS directly. The latest feature version, the Huawei Cloud is running? That's a really matter. If you see it's good, then we upgrade it now. Then you can always demanit and edit to the latest version. Now the window is open. What we can do is following because I know, I mean, I am also the same opinion as they were because we already know that all the other in their regions, they offer different versions. Just go to Beijing for exactly. But would you provide us this which region has the same version or similar version as we will get on the Odyssey so that we can just get and better. I mean, we can test everything of course, but we will never have the chance to test APE or this ModOS in this case. So just give us an idea which region and Huawei Cloud has the current version that we will get there later. But really also the feature level. And we can also view out or see what is the difference because we know release notes, okay, fine for me. But we need to touch it to check it. And also for example, we have here no team met and fairly or short or vnet or I don't know. All the determinants could also just check it and see what features are there. Really running we can see. And probably also evaluate if there is some kind of, I mean, after that when we have the list of these features, we can just see with customers if they are looking for another features than this ModOS team. I was thinking. I think I missed the point the first time. So what Josha you're saying is that now we have a time frame where Model X R&D is giving us the opportunity to give feedback on what we would like to have in the future, right? Yes indeed. So I was thinking differently. So I was thinking, you feel, see, our Amazon have this feature I think is good. Google have this feature I think is also good. Just list what you think is good. And let the RDSays is available. Yes or no, do we have a workaround or do we have redeveloping something? That's my point. Okay, for this week I use the public model. I'm saying that it doesn't really matter. Yes, it doesn't really matter. So it would be maybe months or first months, but maybe half a year or so before this appears on ODC whatever we request, right? Okay, do you know how long this window is open? Yesterday. I know they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now I tell Andy say, hey, your AI framework is related. Oh, I would like to have some feature deck and have latest framework, latest driver, CUDA, PyTorch, TensorFlow, latest version. I want to customize. I would like to make my decision which one is good. Which choose which framework. Yeah, I would like this feature. Now I bring these to them. And I also want to have some idea. Like at this feature, the OTC can customize their own image. Like inference with Lama 3 or training with Lama 3 those images and OTC can develop this image and make it available to customers. So the customers just won't click and they can deploy the Lama 3 already. I also want to have this feature. But I have those things in my mind. But I do want some input from your guys. That's what I want to talk about. And if Gipa's, I think some time, two weeks, I don't know how long will it be? Yeah, as soon as possible. Yeah, because developing also needs sometimes. OK, yes. Well, we'll try to. So how about we do this? So our next string starts on next Monday. So we allocate maybe one or two days from you guys. So in this case, so Matt, Joel, Perry, so maybe each of you spend a fun day comparing this stuff. So I don't know if you guys have access to Bobbick out. If you don't, then Hector could provide you an user account or maybe an even I could. I don't know. Yeah, maybe Hector can provide me an account as well. OK, yes, guys. OK, so we can give you an account. You spend one or two days comparing the GCP, Azure, and so on. Yes. And in, let's say, the me character, we head together again. And we talk about this. OK, five for me. Great. That was great. And this one, like one edition or one more topic for which it would help us going to market. It's a simple logo made for Europe or certified by for European usage or leverage for Germany or something. I think you are totally right. Mattias, let me work. I think unfortunately it's a little difficult because we have no such stamp that we can get for officials stages right now. I think the best thing we have for the moment is AIC4, right? And I had actually an interview with Aniston and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principle of cloud certification. Yeah. And AIC4 is nothing that we audit at the moment. But Ernst and Young at that time was already planning to offer to the systems to audit against AIC4. Or whatever comes in future in addition. So things like AI act, etc. So I think it's like a matter of time when OTC will have to review exactly this again and raise their hand and say, guys, now we have I don't know. Soc, C5, IT conchords, please audit and compliance. What the next thing we should do is AIC4 audit or whatever it applies to have an official extent, right? I'm already looking for budget. OK. You may have to make an appointment. Mm-hmm. OK, guys, then it's now time for launch. Thank you so much for joining this session. Gert, would you just let me know who should then add to the Huawei tenant for next week to take care of these wall alerts. And I will then add them to Huawei Cloud. This is it. I think. OK. This great, my version, very, and that. OK. It's all for a man. OK. Yeah. OK. OK. Great. Thanks for your time, colleagues. Thank you. Thank you, though. Nice to meet you. Thank you. Bye. Bye. Thank you. Bye. So let's go for launch, I think. I'm going to go ahead. Nice presentation. Thank you, Josh. Josh, thank you. I like it. Oh, yeah.
It seems like the conversation is about a software or platform called ModelArts (ModOS) and its upcoming upgrade. The team discussed the possibility of adding new features to make the product more competitive in the European market, especially compared to offerings from GCP, Azure, and other providers.

* Josh brought up the topic of allowing users to customize their AI framework images with the latest versions of CUDA, PyTorch, TensorFlow, etc.
* There was a suggestion for an "AI Framework Certification" or a logo that signifies compliance with European standards or certification for usage in Germany/Europe. However, it was noted that obtaining such a stamp is currently difficult and AIC4 might be the best they have at this moment.
* The team decided to allocate time during their next sprint (starting Monday) to compare GCP, Azure, etc., against ModelArts' capabilities and identify potential new features.
* Hector offered to provide accounts for Mattias, Joel, Perry, and others to facilitate the comparison process.
* They plan to reconvene after a couple of days to discuss their findings.

The conversation ended with some technical issues and goodbyes as people prepared to leave.torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 13, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmplh5mynfr
临时文件夹地址：./tmplh5mynfr
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, 10 years from this, we started working with the presentation. It was regarding as we all remember CSS. It's in RIG, also, Pongo Semantic, Modern for that subject. Yes, sure. Share your slides. So, so that everyone knows what you are talking. Yes, exactly. We stay here. Yeah, we stay here. Competitiveness between CSS, Solution and Open AR, right? Yes, we do have some competitiveness with the existing large-led grid model, but this is nonsense. You don't, you don't, you don't look this because it's only for Chinese embedding. We don't have the conquer accuracy for English embedding yet. But, yet. But my point is CSS can itself do no need to show you with this embedding model or any Pongo lingerie, large-led grid model itself is a very good data basis and Victor, beta, Victor databases. I will show you the competitiveness of CSS itself to other open source CSS later. Yeah, I don't have that much left to talk about with this slide. This is a successful story, you CSS with this IG solution to be a customer service assistance. I believe we are all very familiar with this kind of story, like a user IG to search the most correlated response, like how to deal with angry customer. And it will just generate the most proper answer based on the current situation. And just like a cold ass tab, you generate cold, you generate the answer. Basically, it's the same thing. I will give you the slide to read after the meeting. Demo, I don't have the demo yet. I was no able to access to the demo. You feel free to click this link, but I don't think it's going anywhere. So, it's called cold search. Yeah, it's called cold search indeed. It's so that means what cold search it is this it's called this solution integrate the combo with CSS. It's called cold search. Yes, indeed. I don't ask me why is coco search somebody that decides coco search and this coco search. Okay, the next question is since a combo. Pango is something that we don't have here and all this thing. Pango exists already since two years or a while ago because I remember last year. I was not in this world of ice summit, but one year before he got the main stage and percent something about combo for this electricity stove with electricity. Yes, the electricity with power. Yes, there. So, the question is since that was more than a two in what are the current use cases that you already have with this solution. Real use cases and real customers. Real use cases and real customer. So, this is more like a bridge stone part. It's not like a bridge stone part. Yes, we have a lot of different Pango model. As you may already know, we have the CV different Pango model for different AI test. For example, CV, we have the electricity tower, we have the TFDS. Those are actually have customer in using of those. And CSS and Pango. I mean, we're talking about the normal tango cold search. I mean, for course, it just showed the case. Yeah, I just showed the cases. But it's not a real customer. This is a real customer. It's a real customer. It's a real customer. The real customer is doing what? Using this RHE to build a customer server's assistance. Like a support. Yeah, customer support. Or help center. What kind of customers began with the bank or what? Yes, a bank. Well, however, we have a lot of customer with bank. So, you've seen CSS, which is the RHE. Yes, Pango, together, and they are using what's injected on this RHE. What's injected in the, you mean, injecting to this IGE base? Is the customer's servers, his historical chat record? Like, basically, this is chosen by this database, is chosen by human. How to deal with angry customer? How to answer this question? Confircant QA question. And all those data are put together and fitted to this IGE. So, when a customer, when a customer finds your customer's servers, they always want those kind of things, right? I go charge, I don't know how to use this. And those are mostly of the answers in the frequent RQA. And they just don't bother to read it. So, this IGE will help the customer's servers, to get the correct response to those customer. So, the worry of this is in both the efficiency and customer's services. So, it's a fashion. Yes. But this, from what we've done, we've also done without CSS, and using just a simple LLM with RG on top, or on this. So, what is the difference? You see the... I just give a second. I'm sorry, I didn't... I have a nowadays, what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they have a... They train, they have a model. They put on this model the documentation of what I'm from the OTC. And with this, this is the RG part, so that they do condemn the use case. It's to develop a chatbot. With this chatbot, the same as here. You have your help center. You start asking questions, and it will be to give you the right answer. Also with the reference. Let me show you exactly what I mean, only that you know this, and then you can tell me what is the difference. For me, it's important to understand what is the difference, because otherwise, what if your solution is better, and we already don't know. So, let me show you this. Here, for example, can you see my screen? Yes. So, I think you are not sharing. Okay, you see this. So, this is behind this. As I told you, it's an LM with RG, and it's used to use the documentation you are. So, it will have an OTC. So, there is not service description. So, if we call, for example, here, how LDS support... I don't know, but it's updating. So, what this is doing, it's to see in the left side, is just the links that it found some kind of information, but it's not doing something on the right side. It's the summary. I try to create some kind of response. Nevertheless, when it is then really undone with all that information that is creating, of course, all that information is based on the documentation of the OTC. So, because we have these as spaces. At the end, when it is completely finished, you may see, for example, here, there's number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two are just a mixed sentences from between two. When I just want to go and see exactly if this answer is correct. I just here select the number one, and it forward me to the documentation, or else that it has been found this kind of information on that sentence. And the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It shows LN and also RG. That RG is just connected to these URL docs of the C systems. No more, no less. I think, principally, technically, it's more or less doing the same right. It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So, I guess, technically, there's not much difference in what you finally get. The question is, how complex is this Huawei 4-striple? Yes, yes, one is the cost. And what is the actual business model? In this case, this obviously being focused on end users. So, if you want to make this happen again for your end customers, if you're like, for example, I don't know, the system integrator or something like this. You have to be either the partner of M-Bus search then again, or you have to make a commercial model with them to sell this to your own end customers. So, this can be relatively complex and then also become a matter of cost related to that. Since I don't know how end users are charging and what they kind of invoke in business model means. And I have also no answer for the actual business model that is behind this. For the moment, I think, anyway, these are the things that we would have to compare. I mean, I do have a sense of it. I mean, it's not the technology set. The answer is also the business quality output. How should I compare this now? I have no idea. Can you say this will be better or who worries about it? I think it's difficult to say. This I can show you. What is the difference? Also, one big difference of this solution. You can see here. I just ask in English, because you see that the documentation is also in English related. So, but I can also ask the same question in German. And I would get the answer in German, also with the reference in English. So, I think similar questions, similar way, I'm trying to translate them. German, you are not there. You are German. I did some mistakes. How does it work? I think the question is good. The answer is that I see so far on the left side are not like that applicable. But I think. In the right side where it's giving the answer is looks good. So far. It looks like a prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. A prime. And when you cognitively understand it. Or when you have to już rejection of a good decision that you're wrong. It is frustrating to you because bad things happen. And that's an important thing. But again, when you connect to the success substance between one, or another, If you have this also with your solution integrated, I'll say a similar way of it. Of course, I'm very good. We have, we are now personal for it, and I'm pretty sure we have still on the in-general, customers that are looking also for this kind of solution. And for example, yes, for your question, like what's the difference between us and the embersage? We mentioned they use the open source model to return the, return the model. Yeah, they have their own embedding function. They have built their own knowledge bases. Yes, you can always use that in the open source. You can build an end to end solution. But with all using all the open source solutions, yes, there's no problem. I can tell you that. Basically, you can build everything with open source. Now, why people still go to the commercial? Why people buy the open source, when they have the open search, you know, CSS, open search. Yeah, even though open search is open source, and they still go to Amazon to buy it. Why? Yeah, we have different, we can see in different angles. Yes, the open source is cheap, but as I mentioned before, cheap, free cost most. When the server is done, when the server is misfunction, nobody, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong, where SIE will help you answer the question. Now we also have me to help you build a take a look if it was your problem, give you some advice to just know the commercial does. So, a similar story here. Yes. Good question to you, Michelle. I like it. And I don't say that it's wrong, on the wrong, no? I would like to hear from you or Thomas, what we can also offer with the coupon, something like this. I mean, for English, in German, like you see, because I think that more will be really helpful. Yes, exactly. And if that more will be very helpful, let me something like this. I mean, open source, okay, fine for me, but if you can achieve such quality with open source like this, it could be very good. I will propose also your solution because if you achieve such kind of source, why not? I wouldn't be the last one that I was able to say no. Yeah, I mean, do you think I'm going to prepare a demo and if you find something like this? I thought I was actually doing quite good for my first, this pet. And yes, I can go back to Andy and, find a demo for you and see how they are working on it. But currently, it's not very, the large language model is very, not very good at German, so when you speak German to them, you probably will just reply English or just randomly mumble something. That's one of the drawbacks. But I think what can I do? But most likely, is demo will be English. If it's English, so I think it would be good start, because I think we are here in Europe, so most of the people that are interconnected, they speak English, so that would be very, very, very start. So we can extend it later, but for the first version, that would be amazing. Okay, let's continue with your presentation. I have another question of what the CSS says. This is just one example for our health center. And do you believe that our another use cases also related to this one that you are presenting? Yes. What I'm presenting now is the co-sert, is CSS for IG solution. And currently, it's, like I say, it's only for IG solution. So only IG is strongly related. And for your question, if you can use in other scenarios, any IG use cases can buy our CSS with databases, with databases. And the one of the core competently, this is, I'm not sure, am I screened? It says, socialize, especially reviews. So we didn't start again. Yeah. One of the very competitive for our CSS is, oh, I think I was offline, sorry, let me reconnect it with the network. Okay. Just because you changed the... You can see, I thought I was your partner. Can you see my screen? No, no, but it will become. What do you... Let me just reconnect into the... Just join the session. Join the session, yes. So during this time, guys, from the team, what do you think about this solution from your job? It would be nice to know how the customer can make use of this. So whether this is an individual product or they can use this and they go to the CSS page or something like that, or how can they access this? I'm not sure. I understand your question correctly. So you say how people going to use this co-sert, right? This is our box service. So it is self-user service. Okay, so this is a product you can find on the console? Yes, you can go to the hallways, latest CSS version right now. I believe you can see something similar to it. But to actually SSC, you need to register for permission. My permission is now available yet. That's why I can't show you the demo. Okay, that's it. I have some awesome access to the Go over cloud. Yeah, access to the Go over cloud. I'm also really curious because I like it. For me honest, I really like it. What do you present? Now when we are all sitting to Edborough, we will have the chance to see it. So this is since CSS right to SS. Yes, yes, yes. Okay. And then I am in the right region, so I am from over here, it's fine. I'm not sure if you would change it to Beijing. Okay, let's change to Beijing. Just Beijing 1 is Beijing 1 or Beijing 4. Did you feel the closer to suddenly this peer? Yes, this peer introduced a bit to you. I think you have to use the how? International. No international. China mainland. Upper or right corner? I mean we change the access capabilities. But if you are able to choose Beijing 1, it's in China mainland. Otherwise it wouldn't be... But our country is not. The country is international. It may not be available international in the right now. But I can show you my. Okay, let's see, I would stop sharing. We have different kinds of accounts globally. I see that. You see that accounts for China mainland and international. They have different provisions. Okay, let's see. But this is supposed to be also available for me or... I don't know. They don't like me. I mean I don't even have access to China mainland anymore. I'm only allowed to use Europe as an employee. Only the region where you are usually working actually. So this is what the Joshua also just mentioned for me. It's actually very difficult at the moment to get access for Chinese resources. That's because latency. No, no. It's just like... I would say... You're on the market. You're on the market. Ah, yes, yes. So Joshua, you are sharing? I'm actually going to tell you what you are not sharing. Oh, I'm not sharing. What time did you work on this? You see this is Beijing for region. And this is the CS console right now. I have the cool search document, the platform. If you click this, you will ask you if you don't have permission. You have a press of permission. I don't have this permission, so I cannot assess it anywhere. So my story ends here. No. Okay, go talk. But this is that also said. And I have company talking. So that's basically what you are using in an app. Yeah. Then maybe you share your experience with other sources. Do we mention that before the MLB could be also component behind the scenes? I can't believe it. Maybe I missed that part. So in order to have this, we would have to have an app. No. I mean, principally, yes, but not as a service presented to the customer. Right? This is what we discussed before. Yeah. Okay, question. I saw I see that your who. Yeah, that's the story. I can try to get permission and see if me or somebody else are going to show you this demo. Yes. Perfect. My key message is our CSS for RIG solution. This is a Q-ring writing and a result with ranking function. And even without those, even without the PANGOO, itself is a very good with data basis. And here is you. Let me show you the GitHub for benchmark. This is the. This is a. A pop's made nearly neighbor. Near to the neighbor search function is a. It's a search function in the. A benchmark. It compare with all those. Aggressor or. No, no, algorithm. This is all the. Search engine. Yes. This. This. This. Files. This is also what republic. You see 20 AKs made by the Facebook and. Compare all of them. You can see. Our Huawei's. Searching algorithm is QS GN GT. This. I don't even know how to spell it. This is. This is always. Aggressor is inside. Is inside. CSS. Yeah. You see. QS GN GT. And this is the. Performance. You see. Is green X here. On the very top. So they are sorted from the best. I mean, the list with colors on the right side is. The. The. The best. The. The rest of here is the. It's like which one represent the. Which. Which graph. Yes. Yes. And necessarily by order. You can only see that it's very. Second. So the more queries they do, the better. Yes. In the same record rate, the more. Q. Second is better. So you see. At the same record rate, our. Quarrel. CSS searching performance is always the top. High list. Yeah. See this line. Here. And horizontally. The same speed. The Q. We call speed. You guys. Number of percent. Right. The higher record. Higher record will be better. Okay. All know what record you. Right. The check. So the guys. Access to this. Copy. Offload. The digest. Right. Yes. Yes. Sure. So the guys has not to type this. It's. Where's the. Sorry. I just looking for. Oh, yeah. Would you put it on the. So that I can put it on check. Oh, okay. So that will be. I think we must. It's part. And. Yeah. And this. This repository is no maintained by Huawei. And you can see it's already. It's also very active. Couple days ago. Yeah. Yeah. And this. This repository is no maintained by Huawei. And you can see it's already. It's also very active. Couple days ago. Yeah. Not the last year. And for this ago. Yeah. Yeah. So I think. You can also show. That. Our. Search engine is already. Have. Coomin something. Yeah. Coopie some competitive. This. And the rest of them. The rest of the. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Uh. Image is also similar story. Uh. Uh. But for different tasks. Uh. Those are all tasks. And you can see. Uh. Always. The QS something is. Uh. Also. Uh. Kind of. Uh. Competit. Be something. Yeah. Competitivity. Okay. Yeah. So that's one of the main point. The other point is already down in the. Uh. Uh. Uh. CSS. Uh. Revisual. And. And. CSS. Promotion. Guy slice. All those stuff is there. So. Even without a. Uh. Pango mode of CSS itself could be something. So that. That's. That's all. For the. This. CSS. Uh. Story. And. My represent. My presentation. Okay. I think. Thank you. Yeah. I think. I think. It should be. And here. If you don't have any other question, do we have any other question? Guys. Okay. Good. Okay guys. We will close the session. Thank you so much for joining. I think. Meal and ask. The. Is. How. And. Is. I think. Uh. I. Can use for the. Help Center Chat Board. Am I understanding correctly? Okay. Is. Or. Oh, okay. If anyone, Yeah, my question. My answer will be, yes, no, there's no problem to. and it's nothing hard. I've been one small demo before. You'll see there for OCR's documentation. QA search is nothing hard. And so that's how you'll be. Yes, documents all English could be doing well. That's all for my presentation. And based on my online, my very last topic is a little bit small discussion with the model asker marketing. It's a brainstorm stuff. See if we want to talk about this. Because you know, the model ask is on his way doing the upgrades smoothly. And it will soon or later upgrade to the latest. Now we have a chance on the asking us if you want to add any feature, anything, to make it more sellable in Europe. Anything you can check the call Google sales, how it sells, how Amazon sell the similar part and give them any advice they can see if you have a workaround or solution or just edit this feature and they start developing right now. We have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. Just me this way now, I believe there's only just one way to find this out. Do you have a kind of benchmark of the current version from all of us? Compared for example with AWS, with all other similar products. I know this is Saga Maker, then in Google, it's called I think. Google, I think it's for Hera, the Google is V-Samsin. But if you have some kind of benchmark, compare it with similar ML solutions, then it will be more simple to figure out in which session should we see the problem. It's a little bit different. Model R is known like CSS, we compare with the speed and the recoil. It's very clear because CSS only do search. And model R is two machine learning and we don't have this benchmark for machine learning. I don't, I don't, I don't. It's more about the features that comparison. Yes indeed. But what they might offer but we don't currently. Yes, what they might offer, what we don't, what we see, there is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. You still don't know what the new version or the kind of port, you know, the port jump is still not know what it will have. You can, we can do it in several, one we can get the release. No second, you can go to the Huawei Cloud and check out the latest model R directly. The latest figure of one version, the Huawei Cloud is running. That's a, that's a very limited. If you see it's good, then we are crazy now. Then you can always, uh, demand it and edit, edit to the latest version. Now the window is open. What we can do is follow in because I know, I mean, I am also the same opinion as they were because we all know that all it out in their regions, they offer different versions. Uh, just go to the beginning for time. Exactly. But you could provide us this, which region has the same version or similar version as we will get on the Odyssey so that we can just get and better, I mean, we can test everything, of course, but we will never have the chance to test APE, but APE, so in this case, so just give us an idea which region and what we cloud has the current version that we will get there a little later, but really also the feature level. And we come also throughout or see what is the difference because you know, release notes, okay, fine for me, but we need to touch it to check it and also, for example, we have here no team met and fairly or short or vnet or either all the minutes, we'll also just check it and see what features are there really running we can see. And probably also evaluate if there's some kind of, I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature than this I was thinking. I think I missed the point the first time. So, what just you're saying is that now we have a time frame where what are the R&D is giving us the opportunity to give feedback on what we would like to have in the future, right? Yes indeed. So I was thinking differently, so I was thinking like you feel, see, our Amazon have this feature I think it's good. Google have this feature I think it's also good. Just list what you think is good and let the RDS says it's available yes or no, do we have a workaround or do we have to redeveloping something? Yeah, that's my point. Okay, for this week I use the public example that I'm saying that it doesn't really matter. Yes, it doesn't really matter. It would be maybe months or for first months, but maybe half a year or so before this appears on ODC, whatever we request, right? Okay, we can do that. Do you know how long this window is open? Yes, yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind, so I was bringing up the customized image, this topic to them. I do hope we can add more good features inside it. I don't know if I make my point clear. Now I tell Andy, AI framework is related. I would like to have some feature deck and have latest framework, latest driver, CUDA, PyTorch, Tens of Flores, latest version. I want to customer, I would like to my decision which one is good, choose which framework. I would like this feature. Now I'm bringing this to them and I also want to have some idea like at this feature that ODC can customize their own image like inference with Lama 3 or training with Lama 3 those images and ODC can develop this image and make it available to customers. So the customer just won't click and they can deploy the Lama 3 already. I also want to have this feature, but I have those things in my mind, but I do want some input from your guys, that's what I want to talk about. Yes, and Gipel, I think some time, two weeks, I don't know how long will it be? As soon as possible, because developing also needs sometimes. Okay, yes. So what we will try to do is, so our next string starts on next Monday, so we allocate maybe on or two days or from you guys. So in this case, so map, the jolt, ferry, so maybe each of you spend a fun day comparing this stuff. So I don't know if you guys have access to Bobbick out if you don't. An actor could provide you a user account or maybe an either I could, I don't know. Maybe Hidok can provide me an account as well. Okay, yes guys. So we can give you an account, you spend one or two days comparing the with a GCP, Acer and so on. Yes. And in let's say the me character, we head together again, and we talk about this. Five more minutes. Great. Sounds great. And this one, we have one edition or one small topic for which it would help us going to market. It's a simple logo made for Europe or certified by or European usage or leverage for Germany or something. I think you are totally right, Mattias, they can work. I think unfortunately it's a little difficult because we have no such stamp that we can get from officials status right now. I think the best thing we have for the moment is AIC4, right? And I had actually an interview with Anderson and Jan after the last audit. They invited me for an interview and you know we have currently C5. This is our principle cloud certification. And AIC4 is nothing that we audit at the moment, but Ernst and Young at that time was already planning to offer to the systems to audit against AIC4 or whatever comes in future in addition. So things like like AI, etc. So I think it's like a matter of time when OTC will have to review exactly this again and raise the hand and say guys now we have I don't know sock C5, IT gunshots, please audit and compliance. What the next thing we should do is AIC4 audit or whatever applies to have an official stamp, right? Okay guys, then it's now time for launch. Thank you so much for joining this session. I'm going to let me know who should then add to the Huawei tenant for next week to take care of this wall alerts and I will then add them to Huawei cloud and this is it. I think. Okay, this great one for short, Pairy and Matt. Okay, short for Matt. Okay, yeah. Okay, great. Thanks for your time colleagues. Thank you. Thank you. Thanks. Bye. Bye. Bye. So let's go for lunch I think. Okay. Now I'm going to go to lunch. Nice presentation. Thank you, Joshua. Joshua. Thank you. I like it. Thank you. Okay.
Meeting Minutes

**Date:** Unspecified  
**Time:** Unspecified  
**Location:** Virtual Meeting  
**Attendees:** [Names not provided] - Attendees included representatives from sales, engineering, product management, and customer support.  
**Chairperson:** Unspecified  

---

### Agenda Items:
1. Comparison of ModelArts with AWS Sagemaker and Google Vertex AI
2. Feature Requests for the Next Version of ModelArts
3. Access to Huawei Cloud for Benchmarking Purposes
4. Timeframe for Feature Suggestions
5. Request for a European or German-specific Compliance Logo

### Discussion Details:

**1. Comparison of ModelArts with AWS Sagemaker and Google Vertex AI**
   - The team discussed the need to benchmark ModelArts against competitors such as AWS Sagemaker and Google Vertex AI.
   - It was suggested that each participant could spend one to two days comparing features, functionalities, and compliance aspects.

**2. Feature Requests for the Next Version of ModelArts**
   - Input from sales, engineering, product management, and customer support teams was requested regarding new feature ideas for ModelArts' next version.
   - Customizable image creation capabilities were proposed as a key enhancement.

**3. Access to Huawei Cloud for Benchmarking Purposes**
   - Discussions included logistics on providing access to Huawei Cloud for benchmarking purposes.
   - An account provision plan was outlined to facilitate the comparison process between ModelArts and competing platforms.

**4. Timeframe for Feature Suggestions**
   - The timeframe for submitting feature requests was set as soon as possible, with a suggested deadline of two weeks from the meeting date.

**5. Request for a European or German-specific Compliance Logo**
   - A request was made to develop a compliance logo that certifies ModelArts' adherence to European standards.
   - It was noted that current certifications do not fully address this need, and AIC4 (Audit Information Cloud 4) certification was discussed as a potential future compliance standard.

### Decisions and Action Items:

- Attendees will allocate time in their schedules for benchmarking activities against AWS Sagemaker and Google Vertex AI.
   - **Action Item:** Each participant to spend one or two days comparing ModelArts with competitors.  
   - **Responsible Person:** All participants.  
   - **Deadline:** Two weeks from the meeting date (unspecified).

- Access will be granted to Huawei Cloud for benchmarking purposes.
   - **Action Item:** Provide accounts on Huawei Cloud to all required personnel for comparison activities.  
   - **Responsible Person:** Hidok and Actor (names assumed).  
   - **Deadline:** Immediate, to enable benchmarking within the next two weeks.

- A follow-up meeting will be held post-benchmarking.
   - **Action Item:** Schedule a review meeting to discuss findings from benchmarking activities.  
   - **Responsible Person:** Chairperson or Meeting Coordinator.  
   - **Deadline:** Immediately following the completion of benchmarking tasks (within three weeks).

### Other Matters:

- The next steps regarding compliance logos and certifications will be explored, focusing on AIC4 as a potential audit standard.
   - **Action Item:** Research and planning for achieving an official stamp or certification that meets European standards.  
   - **Responsible Person:** Unspecified, potentially the Compliance Officer or equivalent role.  
   - **Deadline:** Not specified.

Meeting concluded with lunch plans following the session.

---  

*Note: Specific names and dates were not provided in the transcription and have been generalized for this meeting minutes format.*torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpuutuvjiu
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
  0%|                                              | 0.00/1.42G [00:00<?, ?iB/s]  0%|                                     | 4.84M/1.42G [00:00<00:29, 50.8MiB/s]  1%|▍                                     | 19.0M/1.42G [00:00<00:13, 108MiB/s]  2%|▊                                     | 32.0M/1.42G [00:00<00:12, 116MiB/s]  3%|█                                     | 43.1M/1.42G [00:00<00:14, 103MiB/s]  4%|█▍                                    | 54.5M/1.42G [00:00<00:13, 109MiB/s]  5%|█▋                                    | 66.6M/1.42G [00:00<00:12, 114MiB/s]  5%|██                                    | 79.0M/1.42G [00:00<00:12, 119MiB/s]  6%|██▎                                   | 90.5M/1.42G [00:00<00:12, 117MiB/s]  7%|██▋                                    | 102M/1.42G [00:01<00:14, 101MiB/s]  8%|███                                    | 113M/1.42G [00:01<00:13, 105MiB/s]  8%|███▎                                   | 124M/1.42G [00:01<00:12, 108MiB/s]  9%|███▋                                   | 136M/1.42G [00:01<00:12, 113MiB/s] 10%|███▉                                   | 147M/1.42G [00:01<00:12, 111MiB/s] 11%|████▎                                  | 160M/1.42G [00:01<00:11, 119MiB/s] 12%|████▌                                  | 172M/1.42G [00:01<00:12, 110MiB/s] 13%|████▉                                  | 185M/1.42G [00:01<00:11, 118MiB/s] 13%|█████▎                                 | 196M/1.42G [00:01<00:11, 118MiB/s] 14%|█████▌                                 | 208M/1.42G [00:01<00:11, 113MiB/s] 15%|█████▊                                 | 219M/1.42G [00:02<00:12, 108MiB/s] 16%|██████▏                                | 231M/1.42G [00:02<00:11, 115MiB/s] 17%|██████▎                               | 243M/1.42G [00:02<00:13, 91.3MiB/s] 17%|██████▋                               | 255M/1.42G [00:02<00:12, 99.6MiB/s] 18%|██████▉                               | 265M/1.42G [00:02<00:12, 97.0MiB/s] 19%|███████▏                              | 275M/1.42G [00:02<00:12, 96.0MiB/s] 19%|███████▍                              | 284M/1.42G [00:02<00:12, 96.1MiB/s] 20%|███████▉                               | 295M/1.42G [00:02<00:11, 102MiB/s] 21%|████████▏                              | 305M/1.42G [00:03<00:11, 101MiB/s] 22%|████████▏                             | 315M/1.42G [00:03<00:15, 77.3MiB/s] 22%|████████▍                             | 323M/1.42G [00:03<00:14, 79.3MiB/s] 23%|████████▋                             | 334M/1.42G [00:03<00:13, 88.2MiB/s] 24%|████████▉                             | 344M/1.42G [00:03<00:12, 92.4MiB/s] 24%|█████████▏                            | 354M/1.42G [00:03<00:13, 88.9MiB/s] 25%|█████████▊                             | 367M/1.42G [00:03<00:11, 103MiB/s] 26%|█████████▊                            | 377M/1.42G [00:03<00:13, 83.8MiB/s] 26%|██████████                            | 386M/1.42G [00:04<00:15, 71.1MiB/s] 27%|██████████▎                           | 397M/1.42G [00:04<00:13, 81.8MiB/s] 28%|██████████▌                           | 406M/1.42G [00:04<00:13, 81.7MiB/s] 28%|██████████▊                           | 415M/1.42G [00:04<00:12, 84.2MiB/s] 29%|███████████                           | 424M/1.42G [00:04<00:12, 83.6MiB/s] 30%|███████████▎                          | 432M/1.42G [00:04<00:14, 74.1MiB/s] 30%|███████████▌                          | 441M/1.42G [00:04<00:13, 78.6MiB/s] 31%|███████████▋                          | 450M/1.42G [00:04<00:12, 82.4MiB/s] 32%|████████████                          | 461M/1.42G [00:04<00:11, 92.1MiB/s] 32%|████████████▎                         | 472M/1.42G [00:05<00:10, 98.0MiB/s] 33%|████████████▌                         | 482M/1.42G [00:05<00:11, 89.7MiB/s] 34%|████████████▊                         | 493M/1.42G [00:05<00:10, 97.0MiB/s] 35%|█████████████▍                         | 504M/1.42G [00:05<00:09, 102MiB/s] 35%|█████████████▍                        | 514M/1.42G [00:05<00:10, 95.3MiB/s] 36%|██████████████                         | 525M/1.42G [00:05<00:09, 102MiB/s] 37%|██████████████▎                        | 536M/1.42G [00:05<00:09, 106MiB/s] 38%|██████████████▋                        | 547M/1.42G [00:05<00:08, 108MiB/s] 38%|██████████████▉                        | 558M/1.42G [00:05<00:08, 108MiB/s] 39%|██████████████▊                       | 568M/1.42G [00:06<00:09, 94.4MiB/s] 40%|███████████████                       | 577M/1.42G [00:06<00:10, 90.2MiB/s] 40%|███████████████▎                      | 589M/1.42G [00:06<00:09, 97.8MiB/s] 41%|████████████████                       | 601M/1.42G [00:06<00:08, 105MiB/s] 42%|████████████████▎                      | 611M/1.42G [00:06<00:08, 107MiB/s] 43%|████████████████▋                      | 624M/1.42G [00:06<00:07, 115MiB/s] 44%|████████████████▉                      | 635M/1.42G [00:06<00:08, 105MiB/s] 44%|████████████████▊                     | 645M/1.42G [00:06<00:08, 98.9MiB/s] 45%|█████████████████▌                     | 657M/1.42G [00:06<00:08, 104MiB/s] 46%|█████████████████▊                     | 667M/1.42G [00:07<00:08, 103MiB/s] 46%|█████████████████▋                    | 677M/1.42G [00:07<00:09, 89.5MiB/s] 47%|█████████████████▉                    | 688M/1.42G [00:07<00:08, 96.5MiB/s] 48%|██████████████████▏                   | 698M/1.42G [00:07<00:08, 93.5MiB/s] 49%|███████████████████                    | 710M/1.42G [00:07<00:07, 103MiB/s] 49%|███████████████████▎                   | 721M/1.42G [00:07<00:07, 106MiB/s] 50%|███████████████████▋                   | 734M/1.42G [00:07<00:06, 116MiB/s] 51%|███████████████████▉                   | 745M/1.42G [00:07<00:06, 116MiB/s] 52%|████████████████████▎                  | 760M/1.42G [00:07<00:05, 127MiB/s] 53%|████████████████████▋                  | 772M/1.42G [00:08<00:05, 124MiB/s] 54%|████████████████████▉                  | 784M/1.42G [00:08<00:06, 105MiB/s] 55%|█████████████████████▎                 | 795M/1.42G [00:08<00:06, 104MiB/s] 55%|█████████████████████▌                 | 807M/1.42G [00:08<00:06, 110MiB/s] 56%|█████████████████████▉                 | 818M/1.42G [00:08<00:06, 111MiB/s] 57%|██████████████████████▎                | 832M/1.42G [00:08<00:05, 121MiB/s] 58%|██████████████████████▌                | 844M/1.42G [00:08<00:05, 120MiB/s] 59%|██████████████████████▉                | 855M/1.42G [00:08<00:05, 110MiB/s] 59%|██████████████████████▌               | 866M/1.42G [00:09<00:06, 95.6MiB/s] 60%|██████████████████████▊               | 876M/1.42G [00:09<00:07, 83.5MiB/s] 61%|███████████████████████               | 884M/1.42G [00:09<00:08, 67.3MiB/s] 62%|███████████████████████▎              | 896M/1.42G [00:09<00:07, 79.6MiB/s] 62%|███████████████████████▌              | 906M/1.42G [00:09<00:06, 84.9MiB/s] 63%|███████████████████████▉              | 916M/1.42G [00:09<00:06, 90.5MiB/s] 64%|████████████████████████▏             | 926M/1.42G [00:10<00:12, 43.2MiB/s] 65%|████████████████████████▊             | 953M/1.42G [00:10<00:06, 80.2MiB/s] 66%|█████████████████████████▏            | 967M/1.42G [00:10<00:06, 83.2MiB/s] 67%|█████████████████████████▌            | 979M/1.42G [00:10<00:05, 87.9MiB/s] 68%|█████████████████████████▉            | 992M/1.42G [00:10<00:04, 99.3MiB/s] 69%|██████████████████████████▏           | 0.98G/1.42G [00:10<00:04, 101MiB/s] 70%|██████████████████████████▍           | 0.99G/1.42G [00:10<00:04, 105MiB/s] 70%|██████████████████████████▊           | 1.00G/1.42G [00:11<00:04, 101MiB/s] 71%|███████████████████████████           | 1.02G/1.42G [00:11<00:04, 109MiB/s] 72%|███████████████████████████▍          | 1.03G/1.42G [00:11<00:04, 104MiB/s] 73%|███████████████████████████▋          | 1.04G/1.42G [00:11<00:03, 111MiB/s] 74%|████████████████████████████          | 1.05G/1.42G [00:11<00:03, 111MiB/s] 75%|████████████████████████████▎         | 1.06G/1.42G [00:11<00:03, 116MiB/s] 75%|███████████████████████████▉         | 1.07G/1.42G [00:11<00:03, 95.1MiB/s] 76%|████████████████████████████▏        | 1.08G/1.42G [00:11<00:04, 85.4MiB/s] 77%|████████████████████████████▍        | 1.09G/1.42G [00:12<00:03, 94.1MiB/s] 78%|█████████████████████████████▌        | 1.11G/1.42G [00:12<00:03, 105MiB/s] 79%|█████████████████████████████▊        | 1.12G/1.42G [00:12<00:03, 106MiB/s] 79%|██████████████████████████████        | 1.13G/1.42G [00:12<00:03, 105MiB/s] 80%|██████████████████████████████▍       | 1.14G/1.42G [00:12<00:02, 114MiB/s] 81%|██████████████████████████████▊       | 1.15G/1.42G [00:12<00:02, 110MiB/s] 82%|███████████████████████████████       | 1.16G/1.42G [00:12<00:02, 110MiB/s] 82%|███████████████████████████████▎      | 1.17G/1.42G [00:12<00:02, 106MiB/s] 83%|███████████████████████████████▌      | 1.18G/1.42G [00:12<00:02, 109MiB/s] 84%|███████████████████████████████▉      | 1.20G/1.42G [00:13<00:02, 112MiB/s] 85%|████████████████████████████████▏     | 1.21G/1.42G [00:13<00:02, 110MiB/s] 85%|████████████████████████████████▍     | 1.22G/1.42G [00:13<00:02, 109MiB/s] 86%|███████████████████████████████▉     | 1.23G/1.42G [00:13<00:02, 99.7MiB/s] 87%|████████████████████████████████▏    | 1.24G/1.42G [00:13<00:02, 96.1MiB/s] 88%|█████████████████████████████████▎    | 1.25G/1.42G [00:13<00:01, 107MiB/s] 88%|█████████████████████████████████▌    | 1.26G/1.42G [00:13<00:01, 102MiB/s] 89%|████████████████████████████████▉    | 1.27G/1.42G [00:13<00:01, 99.2MiB/s] 90%|██████████████████████████████████▏   | 1.28G/1.42G [00:13<00:01, 100MiB/s] 90%|█████████████████████████████████▍   | 1.29G/1.42G [00:14<00:01, 94.6MiB/s] 91%|█████████████████████████████████▋   | 1.30G/1.42G [00:14<00:01, 95.4MiB/s] 92%|█████████████████████████████████▉   | 1.31G/1.42G [00:14<00:01, 97.3MiB/s] 93%|███████████████████████████████████▏  | 1.32G/1.42G [00:14<00:01, 107MiB/s] 93%|██████████████████████████████████▌  | 1.33G/1.42G [00:14<00:01, 97.7MiB/s] 94%|███████████████████████████████████▊  | 1.34G/1.42G [00:14<00:00, 104MiB/s] 95%|████████████████████████████████████  | 1.35G/1.42G [00:14<00:00, 112MiB/s] 96%|████████████████████████████████████▍ | 1.36G/1.42G [00:14<00:00, 117MiB/s] 97%|████████████████████████████████████▋ | 1.38G/1.42G [00:14<00:00, 109MiB/s] 97%|█████████████████████████████████████ | 1.39G/1.42G [00:14<00:00, 112MiB/s] 98%|█████████████████████████████████████▎| 1.40G/1.42G [00:15<00:00, 115MiB/s] 99%|█████████████████████████████████████▌| 1.41G/1.42G [00:15<00:00, 110MiB/s]100%|█████████████████████████████████████▉| 1.42G/1.42G [00:15<00:00, 109MiB/s]100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 99.6MiB/s]
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. I'm about to go to bed. Nice presentation. Thank you Joshua. Joshua. Thank you. I like it. Thank you. Thank you.
Meeting Minutes

**Meeting Overview**
- Date: Not specified in the provided transcription
- Time: Not specified in the provided transcription
- Location: Virtual meeting (no physical location mentioned)
- Attendees: Matthias, Matt, Jolt, Ferry, Gergud, Hector, Joshua, and others not named but present.
- Chairperson: Not explicitly identified; assumedly Gergud leads the discussion.

**Agenda Items**
1. Discussing Huawei Cloud ModelArts version requirements for OTC
2. Requesting features from public cloud providers (Amazon, Google) for comparison with Huawei Cloud
3. Customized image and feature requests for the ModelArts platform on OTC
4. Timeframe for feedback submission regarding future updates and features for OTC's ModelArts
5. Certification and compliance stamp discussion (AIC4, C5, IT Grundschutz)

**Discussion Details**
- There is a consensus that Huawei Cloud offers different versions in various regions, making it challenging to test the exact version coming to OTC.
- A suggestion was made to identify which region's Huawei Cloud version closely matches what will be available on OTC for testing purposes.
- Participants were encouraged to list features offered by Amazon and Google cloud services they consider valuable to be included in ModelArts.
- Customized image requests, including the latest frameworks, drivers, CUDA, Python, TensorFlow versions, were discussed as desirable additions to ModelArts' capabilities on OTC.
- A timeframe for submitting feedback was not explicitly defined but mentioned to be "as soon as possible" with a suggestion of two weeks.

**Decisions and Action Items**
1. Matt, Jolt, and Ferry are assigned one or two days each during the next sprint (starting Monday) to compare GCP, Azure, etc., with ModelArts.
2. Hector will provide access credentials for Huawei Cloud's public version to Matt, Jolt, and Ferry by the end of this week.
3. A follow-up meeting is scheduled for the week after to discuss comparisons and feature requests.
4. Matthias raised a point about obtaining certification stamps or compliance marks relevant to Europe/Germany; however, it was acknowledged that official audits might be required (e.g., AIC4).

**Other Matters**
- The group expressed interest in having ModelArts on OTC certified with a European or German-specific compliance stamp, like AIC4. However, no immediate solution or plan was outlined for obtaining such certification.

*Note: Specific dates and deadlines were not mentioned within the provided transcription; therefore, they are omitted from these meeting minutes.*torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
torchvision is not available - cannot save figures
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpohymqcor
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. What? What? What? What? That's what I was looking for. Okay. Bye! So, let's go for lunch, I think. Now I'm gonna put the roll on. Nice presentation. Thank you, Joshua. Joshua. Thank you. I like it. Thank you.
Meeting Minutes

**1. Meeting Overview**
   - **Date & Time:** [Insert Date & Time Here]
   - **Location:** Virtual (Zoom)
   - **Attendees:** Gergud, Matthias, Matt, Jolt, Ferry, Hector
   - **Chairperson:** Gergud

**2. Agenda Items**
   - Feature Requests for OTC Huawei Cloud ModelArts Update
   - Comparison of Public Cloud Features and Capabilities
   - Market Differentiation Strategy Discussion
   - Compliance and Certification Updates

**3. Discussion Details**

   **Feature Requests:**
      - The team discussed the need to request additional features for the upcoming update of OTC Huawei Cloud's ModelArts service.
      - Suggestions included support for customized images with specific frameworks, drivers, CUDA versions, Python, TensorFlow, etc., allowing users more flexibility in choosing their preferred configuration.

   **Comparison of Public Cloud Features:**
      - It was agreed that Matt, Jolt, and Ferry would spend time comparing features across GCP, Azure, and other public clouds to identify gaps or opportunities for improvement in OTC Huawei Cloud's offerings.
      - Access to public cloud environments will be provided by Hector.

   **Market Differentiation Strategy:**
      - Matthias raised the point about having a European or Germany-specific compliance logo that could help differentiate OTC Huawei Cloud's services in the market.

   **Compliance and Certification Updates:**
      - It was noted that while AIC4 certification is not currently audited, Ernst and Jan are planning to offer T-systems audits against it.
      - The team discussed the need for OTC Huawei Cloud to prepare for future compliance requirements such as AI Act and other relevant standards.

**4. Decisions and Action Items**

   - **Action Item 1:** Matt, Jolt, and Ferry will compare GCP, Azure, etc., features with a deadline of one or two days from the next sprint start (next Monday).
      - **Responsible Person(s):** Matt, Jolt, Ferry
      - **Deadline:** One to Two Days After Next Sprint Start

   - **Action Item 2:** Hector will provide access credentials for Matt, Jolt, and Ferry to Huawei Cloud's public environment.
      - **Responsible Person:** Hector
      - **Deadline:** Immediately Following the Meeting

**5. Other Matters**

   - Additional notes or matters of discussion were not mentioned in this summary.

Meeting Adjourned at [Insert Time Here].Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 7, in <module>
    from main import get_transcription
  File "/home/linux/meeting_whisper/main.py", line 1, in <module>
    import whisperx
ModuleNotFoundError: No module named 'whisperx'
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpp63nehdo
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. I'm a little wet. Nice presentation. Thank you Joshua. Joshua. Thank you. I like it. Thank you. Thank you.
Meeting Minutes

**Meeting Overview**
- **Date**: [Insert Date]
- **Time**: [Insert Time]
- **Location**: Virtual Meeting via Video Conference
- **Attendees**: Gergud, Matt, Ferry, Jolt, Matthias, Hector (Representative from Huawei Cloud)
- **Chairperson**: Gergud

**Agenda Items**
1. Review of Huawei Cloud ModelArts Customization Capabilities and Feature Requests.
2. Discuss Integration of Latest AI Frameworks and Tools in Huawei Cloud Services.
3. Market Positioning and Certification for European Markets.

**Discussion Details**

1. **Review of Huawei Cloud ModelArts:**
   - Acknowledgment that different regions offer varying versions of Huawei Cloud services, including ModelArts.
   - Agreement to identify which region's version most closely matches the OTC (OTC not explicitly defined in the provided text) release for testing purposes.
   - Decision to compile a list of features available on Amazon and Google platforms deemed valuable by the team for potential inclusion.

2. **Integration of Latest AI Frameworks:**
   - Desire expressed to have ModelArts incorporate the latest versions of frameworks, drivers, CUDA, Python, TensorFlow, etc., allowing users to customize their choice.
   - Suggestion to develop specific/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmpmh_80im8
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. I'm a little wet. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Hey, look at me! Supa剛才講m Dakine wording, you need성ée. Absolutely. Why do you keep saying a opposed Thanks for watching!
Meeting Minutes

Date: [Insert Date]
Time: [Insert Time]
Location: [Insert Location]
Chairperson: Gergud
Attendees: Matt, Jolt, Ferry, Matthias, Hector

1. Meeting Overview:
   The meeting was chaired by Gergud and attended by Matt, Jolt, Ferry, Matthias, and Hector. The purpose of the gathering was to discuss feedback for Huawei Cloud ModelArts enhancements, feature requests based on comparisons with other cloud providers, and market readiness in Europe.

2. Agenda Items:
   - Feature Requests for Huawei Cloud ModelArts
   - Comparing Huawei Cloud with GCP, Azure
   - Market Readiness and European Certifications

3. Discussion Details:

   a. Feature Requests for Huawei Cloud ModelArts:
      - Participants discussed the need to request features based on comparisons with Google Cloud Platform (GCP), Microsoft Azure, and Amazon Web Services (AWS).
      - Matt brought up the topic of customizable images for frameworks, drivers, CUDA, Python, TensorFlow versions.
      - Jolt suggested adding more good feature integrations inside Huawei Cloud ModelArts.

   b. Comparing Huawei Cloud with GCP, Azure:
      - The team decided to allocate time during their next sprint (starting on Monday) to compare features of different cloud platforms.
      - Matt, Jolt, and Ferry volunteered to spend a day each comparing Google Cloud Platform (GCP), Azure, and AWS services against Huawei Cloud.

   c. Market Readiness and European Certifications:
      - Matthias raised the importance of having a logo or certification for European usage or specific country leverage like Germany.
      - Hector mentioned that while there is no official stamp available currently, AIC4 could be considered as an audit standard in future audits by T-Systems.

4. Decisions and Action Items:

   a. Hector will provide Matt, Jolt, and Ferry with accounts on Huawei Cloud to conduct comparisons during their next sprint.
      - Deadline: As soon as possible before the week after next Monday's meeting.

   b. The team will reconvene the following week for an update on feature requests for ModelArts based on the comparisons conducted by Matt, Jolt, and Ferry.
      - Responsible Person(s): Matt, Jolt, Ferry
      - Deadline: Next Week

5. Other Matters:
   - No additional points were raised during this meeting.

Meeting Adjournment:
The meeting was adjourned after lunch plans were made. The next meeting will focus on the progress of feature comparisons and requests for Huawei Cloud ModelArts enhancements.
 
End of Meeting Minutes/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 7, in <module>
    from main import get_transcription, delete_tmp_folders
ImportError: cannot import name 'delete_tmp_folders' from 'main' (/home/linux/meeting_whisper/main.py)
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB

To create a public link, set `share=True` in `launch()`.
Deleted folder: /home/linux/meeting_whisper/tmpp63nehdo
Deleted folder: /home/linux/meeting_whisper/tmpnveeas7_
Deleted folder: /home/linux/meeting_whisper/tmpohymqcor
Deleted folder: /home/linux/meeting_whisper/tmplh5mynfr
Deleted folder: /home/linux/meeting_whisper/tmpy0iyeaqq
Deleted folder: /home/linux/meeting_whisper/tmpuutuvjiu
Deleted folder: /home/linux/meeting_whisper/tmpfu_p26v0
Deleted folder: /home/linux/meeting_whisper/tmp6tb4x59p
Deleted folder: /home/linux/meeting_whisper/tmpcvbcvt7z
临时文件夹地址：./tmppdc3pdcd
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. We got water all wet. Nice presentation. Thank you Joshua. Joshua, thank you. I like it. Thank you.
Meeting Minutes

1. Meeting Overview:
   - Date & Time: [Insert Date & Time]
   - Location: Virtual Meeting via [Platform Used]
   - Attendees: Gergud, Matthias, Matt, Ferry, Hector, Jolt, Perry
   - Chairperson: Gergud

2. Agenda Items:
   - Discussion on Huawei Cloud ModelArts Latest Version Features.
   - Feedback Gathering for Future Enhancements in OTC (Operator Transformation Center).
   - Certification and Compliance Updates.

3. Discussion Details:

   **Huawei Cloud ModelArts Latest Version Features:**
   - Acknowledged that different Huawei cloud regions offer varying versions of services.
   - Suggested comparing features available on Amazon, Google, and Azure to identify desirable functionalities for OTC integration.
   - Highlighted the importance of testing features practically rather than relying solely on release notes.

   **Feedback Gathering for Future Enhancements:**
   - Proposed that attendees list good features from competitors' cloud platforms.
   - Agreed to provide feedback on desired features such as customized images, latest frameworks, and drivers for OTC's future versions.

   **Certification and Compliance Updates:**
   - Matthias requested a European or German-specific certification logo for marketing purposes.
   - Discussed current certifications like C5 and the upcoming AIC4 audit by T-systems to assess compliance with AI Act and similar regulations.

4. Decisions and Action Items:

   - Decision: Attendees will compare features of GCP, Azure, etc., focusing on ModelArts functionalities for OTC improvement.
     * Action Item: Matt, Jolt, and Ferry are allocated one or two days each to conduct the comparison.
     * Responsible Persons: Matt, Jolt, Ferry
     * Deadline: Next meeting (date not specified)
   
   - Decision: Accounts will be created for attendees on Huawei Cloud.
     * Action Item: Hector will provide accounts to Jolt, Perry, and Matt for access to public models on Huawei Cloud.
     * Responsible Person: Hector
     * Deadline: ASAP

5. Other Matters:
   - A reminder was made regarding the importance of time management in executing development tasks based on feedback.

Meeting Adjournment:
- The meeting was concluded with an announcement for lunch, and attendees were thanked for their participation.Meeting Minutes

1. Meeting Overview:
   - Date & Time: [Insert Date & Time]
   - Location: Virtual Meeting via [Platform Used]
   - Attendees: Gergud, Matthias, Matt, Ferry, Hector, Jolt, Perry
   - Chairperson: Gergud

2. Agenda Items:
   - Discussion on Huawei Cloud ModelArts Latest Version Features.
   - Feedback Gathering for Future Enhancements in OTC (Operator Transformation Center).
   - Certification and Compliance Updates.

3. Discussion Details:

   **Huawei Cloud ModelArts Latest Version Features:**
   - Acknowledged that different Huawei cloud regions offer varying versions of services.
   - Suggested comparing features available on Amazon, Google, and Azure to identify desirable functionalities for OTC integration.
   - Highlighted the importance of testing features practically rather than relying solely on release notes.

   **Feedback Gathering for Future Enhancements:**
   - Proposed that attendees list good features from competitors' cloud platforms.
   - Agreed to provide feedback on desired features such as customized images, latest frameworks, and drivers for OTC's future versions.

   **Certification and Compliance Updates:**
   - Matthias requested a European or German-specific certification logo for marketing purposes.
   - Discussed current certifications like C5 and the upcoming AIC4 audit by T-systems to assess compliance with AI Act and similar regulations.

4. Decisions and Action Items:

   - Decision: Attendees will compare features of GCP, Azure, etc., focusing on ModelArts functionalities for OTC improvement.
     * Action Item: Matt, Jolt, and Ferry are allocated one or two days each to conduct the comparison.
     * Responsible Persons: Matt, Jolt, Ferry
     * Deadline: Next meeting (date not specified)
   
   - Decision: Accounts will be created for attendees on Huawei Cloud.
     * Action Item: Hector will provide accounts to Jolt, Perry, and Matt for access to public models on Huawei Cloud.
     * Responsible Person: Hector
     * Deadline: ASAP

5. Other Matters:
   - A reminder was made regarding the importance of time management in executing development tasks based on feedback.

Meeting Adjournment:
- The meeting was concluded with an announcement for lunch, and attendees were thanked for their participation.
./tmppdc3pdcd/20240510_121130.m4a
临时文件夹地址：./tmppdc3pdcd
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. Wow. Okay. So let's go for lunch, I think. I don't know what the roll wants. Nice presentation. Thank you Joshua. Joshua, thank you. I like it. Thank you.
Meeting Minutes

**Meeting Overview**
- **Date & Time:** Not specified in the provided text; time not mentioned
- **Location:** Not explicitly stated; possibly a virtual meeting given context clues about cloud services and remote access requests
- **Attendees:** Matthias, Gergud, Andy, Matt, Jolt, Ferry, Hector (possibly others not named)
- **Chairperson:** Not identified; likely Gergud or another senior member present

**Agenda Items**
1. Comparison of Huawei Cloud ModelArts with Competitors' Features
2. Feature Requests for ModelArts on OTC
3. Customized Image Features and Availability in the European Market
4. Compliance and Certification for Europe/Germany (AIC4)

**Discussion Details**

1. **Comparison of Huawei Cloud ModelArts with Competitors:** The team discussed comparing features available on Huawei Cloud's ModelArts platform with those from competitors like Amazon and Google to identify gaps and potential improvements.

2. **Feature Requests for ModelArts on OTC:** It was noted that different regions have varying versions of ModelArts, leading to a request for information about which region has the most current version available. The team expressed interest in testing features firsthand rather than relying solely on release notes.

3. **Customized Image Features and Availability:** There was a discussion around adding more customized image options to OTC, including support for newer frameworks, drivers, CUDA, Python, TensorFlow versions, allowing users more choice and flexibility.

4. **Compliance and Certification:** Matthias raised the need for Huawei Cloud services in Europe to have a certification or logo that indicates compliance with European standards. It was acknowledged that obtaining an official AIC4 stamp could be challenging but is being considered as part of future audits.

**Decisions and Action Items**
1. Matt, Jolt, and Ferry will spend one or two days each comparing features between GCP, Azure, and ModelArts on the public cloud. This task should begin in the upcoming week.
2. Hector (or another team member) will provide Matt, Jolt, and Ferry with access to Huawei Cloud for their comparison tasks.
3. The team will reconvene after one week to discuss findings and feature requests.
4. Gergud will coordinate providing access on behalf of OTC.

**Other Matters**
- Matthias mentioned the importance of an EU or Germany-specific certification/logo for better market acceptance in Europe, indicating that the current C5 audit might expand to include AIC4 compliance audits in the future.  File "/home/linux/meeting_whisper/whisper_console.py", line 42
    global tmpdir
    ^^^^^^^^^^^^^
SyntaxError: name 'tmpdir' is used prior to global declaration
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 15, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 43, in generate_file
    FileName=os.path.basename(file_obj.name)
AttributeError: 'NoneType' object has no attribute 'name'
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
Deleted folder: /home/linux/meeting_whisper/tmpmh_80im8
临时文件夹地址：./tmp0o5jusjv
临时文件夹地址：./tmp0o5jusjv
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
  0%|                                               | 0.00/461M [00:00<?, ?iB/s]  0%|▏                                     | 2.25M/461M [00:00<00:20, 23.6MiB/s]  2%|▋                                     | 8.05M/461M [00:00<00:10, 45.4MiB/s]  3%|█                                     | 12.4M/461M [00:00<00:15, 31.4MiB/s]  3%|█▎                                    | 16.0M/461M [00:00<00:14, 32.7MiB/s]  4%|█▋                                    | 19.8M/461M [00:00<00:13, 34.8MiB/s]  5%|██                                    | 24.4M/461M [00:00<00:11, 38.7MiB/s]  6%|██▎                                   | 28.2M/461M [00:00<00:12, 35.9MiB/s]  7%|██▋                                   | 32.0M/461M [00:00<00:12, 35.2MiB/s]  8%|██▉                                   | 35.5M/461M [00:01<00:27, 16.3MiB/s]  8%|███▏                                  | 38.1M/461M [00:01<00:28, 15.7MiB/s]  9%|███▎                                  | 40.4M/461M [00:01<00:25, 17.1MiB/s] 10%|███▋                                  | 44.1M/461M [00:01<00:20, 20.9MiB/s] 10%|███▉                                  | 48.3M/461M [00:01<00:16, 25.7MiB/s] 11%|████▏                                 | 51.4M/461M [00:02<00:16, 25.7MiB/s] 12%|████▋                                 | 56.3M/461M [00:02<00:13, 31.8MiB/s] 13%|████▉                                 | 59.8M/461M [00:02<00:12, 33.1MiB/s] 14%|█████▎                                | 65.0M/461M [00:02<00:10, 38.7MiB/s] 15%|█████▊                                | 71.1M/461M [00:02<00:08, 45.5MiB/s] 16%|██████▏                               | 75.7M/461M [00:02<00:08, 45.1MiB/s] 18%|██████▋                               | 80.9M/461M [00:02<00:08, 47.7MiB/s] 19%|███████                               | 86.3M/461M [00:02<00:07, 49.5MiB/s] 20%|███████▌                              | 91.1M/461M [00:02<00:08, 44.4MiB/s] 21%|████████                              | 97.4M/461M [00:03<00:07, 49.9MiB/s] 23%|████████▊                              | 104M/461M [00:03<00:06, 55.4MiB/s] 24%|█████████▎                             | 109M/461M [00:03<00:07, 49.2MiB/s] 25%|█████████▋                             | 114M/461M [00:03<00:07, 47.3MiB/s] 26%|██████████▏                            | 120M/461M [00:03<00:07, 50.4MiB/s] 27%|██████████▌                            | 125M/461M [00:03<00:08, 41.2MiB/s] 28%|██████████▉                            | 129M/461M [00:04<00:19, 17.7MiB/s] 29%|███████████▏                           | 133M/461M [00:05<00:35, 9.73MiB/s] 29%|███████████▌                           | 136M/461M [00:05<00:28, 11.8MiB/s] 30%|███████████▋                           | 139M/461M [00:05<00:25, 13.1MiB/s] 31%|████████████                           | 143M/461M [00:05<00:19, 16.8MiB/s] 32%|████████████▎                          | 146M/461M [00:05<00:17, 19.3MiB/s] 33%|████████████▊                          | 152M/461M [00:05<00:11, 27.3MiB/s] 34%|█████████████▏                         | 156M/461M [00:05<00:10, 29.4MiB/s] 35%|█████████████▌                         | 161M/461M [00:06<00:09, 33.6MiB/s] 36%|██████████████                         | 166M/461M [00:06<00:07, 39.0MiB/s] 37%|██████████████▍                        | 170M/461M [00:06<00:07, 39.6MiB/s] 38%|██████████████▉                        | 176M/461M [00:06<00:06, 45.3MiB/s] 39%|███████████████▎                       | 181M/461M [00:06<00:09, 30.0MiB/s] 40%|███████████████▋                       | 185M/461M [00:07<00:15, 18.7MiB/s] 41%|███████████████▊                       | 188M/461M [00:07<00:14, 20.1MiB/s] 42%|████████████████▎                      | 193M/461M [00:07<00:11, 25.4MiB/s] 43%|████████████████▌                      | 196M/461M [00:07<00:13, 20.4MiB/s] 43%|████████████████▊                      | 199M/461M [00:07<00:15, 17.6MiB/s] 44%|█████████████████                      | 201M/461M [00:08<00:23, 11.4MiB/s] 44%|█████████████████▏                     | 203M/461M [00:08<00:22, 12.1MiB/s] 45%|█████████████████▎                     | 205M/461M [00:08<00:19, 13.8MiB/s] 45%|█████████████████▋                     | 209M/461M [00:08<00:15, 17.5MiB/s] 46%|█████████████████▊                     | 211M/461M [00:08<00:19, 13.5MiB/s] 46%|██████████████████                     | 213M/461M [00:09<00:17, 15.2MiB/s] 47%|██████████████████▎                    | 216M/461M [00:09<00:14, 18.1MiB/s] 47%|██████████████████▍                    | 219M/461M [00:09<00:14, 17.8MiB/s] 48%|██████████████████▊                    | 223M/461M [00:09<00:10, 24.1MiB/s] 49%|███████████████████                    | 226M/461M [00:09<00:12, 19.1MiB/s] 50%|███████████████████▎                   | 229M/461M [00:09<00:11, 21.9MiB/s] 50%|███████████████████▋                   | 232M/461M [00:09<00:09, 24.7MiB/s] 51%|███████████████████▉                   | 235M/461M [00:09<00:09, 24.9MiB/s] 52%|████████████████████▎                  | 240M/461M [00:10<00:07, 31.4MiB/s] 53%|████████████████████▌                  | 243M/461M [00:10<00:08, 25.8MiB/s] 54%|████████████████████▉                  | 248M/461M [00:10<00:07, 30.1MiB/s] 54%|█████████████████████▏                 | 251M/461M [00:10<00:08, 25.1MiB/s] 55%|█████████████████████▍                 | 254M/461M [00:10<00:10, 20.6MiB/s] 56%|█████████████████████▋                 | 256M/461M [00:10<00:09, 22.0MiB/s] 56%|█████████████████████▊                 | 259M/461M [00:11<00:10, 21.0MiB/s] 57%|██████████████████████▏                | 262M/461M [00:11<00:08, 24.9MiB/s] 57%|██████████████████████▍                | 265M/461M [00:11<00:08, 25.2MiB/s] 58%|██████████████████████▊                | 270M/461M [00:11<00:06, 31.3MiB/s] 59%|███████████████████████                | 273M/461M [00:11<00:06, 32.8MiB/s] 60%|███████████████████████▍               | 277M/461M [00:11<00:05, 33.4MiB/s] 61%|███████████████████████▋               | 280M/461M [00:11<00:05, 33.9MiB/s] 61%|███████████████████████▉               | 283M/461M [00:11<00:07, 26.1MiB/s] 62%|████████████████████████▏              | 287M/461M [00:11<00:06, 27.9MiB/s] 63%|████████████████████████▍              | 289M/461M [00:12<00:06, 26.2MiB/s] 64%|█████████████████████████              | 296M/461M [00:12<00:04, 36.2MiB/s] 65%|█████████████████████████▎             | 300M/461M [00:12<00:07, 23.2MiB/s] 66%|█████████████████████████▊             | 305M/461M [00:12<00:05, 28.3MiB/s] 67%|██████████████████████████             | 308M/461M [00:12<00:05, 30.8MiB/s] 68%|██████████████████████████▍            | 313M/461M [00:12<00:04, 33.9MiB/s] 69%|██████████████████████████▊            | 317M/461M [00:12<00:04, 36.6MiB/s] 70%|███████████████████████████▏           | 321M/461M [00:13<00:04, 34.0MiB/s] 71%|███████████████████████████▌           | 326M/461M [00:13<00:03, 38.4MiB/s] 72%|███████████████████████████▉           | 330M/461M [00:13<00:03, 34.5MiB/s] 73%|████████████████████████████▎          | 335M/461M [00:13<00:03, 40.0MiB/s] 74%|████████████████████████████▋          | 339M/461M [00:13<00:04, 31.4MiB/s] 75%|█████████████████████████████          | 344M/461M [00:13<00:03, 35.1MiB/s] 75%|█████████████████████████████▍         | 348M/461M [00:14<00:05, 22.7MiB/s] 76%|█████████████████████████████▊         | 352M/461M [00:14<00:04, 26.0MiB/s] 77%|██████████████████████████████         | 355M/461M [00:14<00:04, 26.5MiB/s] 78%|██████████████████████████████▍        | 359M/461M [00:14<00:03, 30.2MiB/s] 79%|██████████████████████████████▊        | 364M/461M [00:14<00:03, 33.9MiB/s] 80%|███████████████████████████████▏       | 368M/461M [00:14<00:02, 37.1MiB/s] 81%|███████████████████████████████▍       | 372M/461M [00:14<00:03, 24.2MiB/s] 82%|███████████████████████████████▊       | 376M/461M [00:15<00:03, 28.0MiB/s] 82%|████████████████████████████████       | 380M/461M [00:15<00:03, 22.2MiB/s] 84%|████████████████████████████████▌      | 385M/461M [00:15<00:02, 28.4MiB/s] 85%|█████████████████████████████████▏     | 392M/461M [00:15<00:01, 37.3MiB/s] 86%|█████████████████████████████████▌     | 396M/461M [00:15<00:01, 37.1MiB/s] 87%|█████████████████████████████████▉     | 401M/461M [00:15<00:01, 38.5MiB/s] 88%|██████████████████████████████████▏    | 405M/461M [00:15<00:01, 35.3MiB/s] 89%|██████████████████████████████████▌    | 409M/461M [00:15<00:01, 37.2MiB/s] 90%|██████████████████████████████████▉    | 413M/461M [00:16<00:01, 36.6MiB/s] 90%|███████████████████████████████████▎   | 417M/461M [00:16<00:01, 38.2MiB/s] 92%|███████████████████████████████████▋   | 423M/461M [00:16<00:00, 43.8MiB/s] 93%|████████████████████████████████████   | 427M/461M [00:16<00:00, 36.4MiB/s] 94%|████████████████████████████████████▌  | 433M/461M [00:16<00:00, 42.4MiB/s] 95%|█████████████████████████████████████  | 438M/461M [00:16<00:00, 44.5MiB/s] 96%|█████████████████████████████████████▍ | 442M/461M [00:16<00:00, 44.3MiB/s] 97%|█████████████████████████████████████▉ | 448M/461M [00:16<00:00, 50.2MiB/s] 98%|██████████████████████████████████████▎| 453M/461M [00:17<00:00, 48.0MiB/s] 99%|██████████████████████████████████████▋| 458M/461M [00:17<00:00, 46.7MiB/s]100%|███████████████████████████████████████| 461M/461M [00:17<00:00, 28.2MiB/s]
 We're back. Thank you. Please continue with your presentation. It was regarding as we all remember as CSS using RIG also Pango Semantic model for that solution. Please share your slides. So, but everyone knows what you are talking. Yes, exactly. We'll stay here. We'll stay here. Competitiveness between CSS, Solution and OpenAR, right? Yes, we do have some competitiveness with the insisting large language model, but this is nonsense. You don't look this because it's only for Chinese embedding. We don't have the conqueror accuracy for English embedding yet. But my point is CSS can itself do no need to associate with this embedding model or any Pango language and large language model. It self is a very good databases and Victor databases. I will show you the competitiveness of CSS itself to any other open source CSS later. I don't have much left to talk about with this slide. This is a successful story. Use CSS with this RIG solution to build a customer service assistance. I believe we're all very familiar with this kind of story. Like use RIG to search the most co-related response, like how to deal with angry customers. It will just generate the most proper answer based on the current situation. Just like a code R step, you generate a code, you generate the answer. Basically, it's the same thing. I will give you this slide to read after the meeting. I don't have the demo yet. I was not able to access to the demo. Feel free to click this link, but I don't think it will go anywhere. So it's called call search? Yes, it's called call search, indeed. So that means what call search? It is called this solution, integrate Pango with CSS. It's called call search. Yes, indeed. Don't ask me why it's called call search. Somebody decided it's called call search and it's called call search. The next question is Pango. Pango is something that we don't have here in OTC. But Pango exists already since two years ago. Oh, probably because I remember last year, Thomas was not in this world of I.S. Summit, but one year before he got in the main stage and present something about Pango. So for this electricity stuff with electricity with power. Yes, there. So the question is, since Pango is more than mature, what are the current use cases that you are really having with this solution? I mean real use cases and real customers. Real use cases are real customers. So this is more like a brainstorm part. It's not like a brainstorm part. But yes, we have a lot of different Pango models, as you may already know. We have the CV, different Pango model for different AI tasks. For example, CV, we have the electricity tower. We have the TFDS. Those actually have customers in using of those. And CSS and Pango? I mean, we're talking about the now known Pango, called SIRT. I mean, for close-ups, you just show the case. Yeah, I just show the cases. But it's not a real customer? I'm not. This is a real customer. It's a real customer. It's a real customer. And the real customer is doing what? What? Using these RIG to build customer service assistance. Like support. Yeah, customer support. Or help center. Help center, yes, indeed. What kind of customers, again, was the bank or what was it? Yes, a bank. Huawei have a lot of customers with bank. So you've seen CSS, which is the RIG, yes, Pango together and they are used. What's injected on this RIG? What's injected in the, you mean injecting to these IHG knowledge basis is the customers servers, historical chat record. Like, basically this is chosen by, this database is chosen by human. Yeah. How to deal with angry customer? How to answer this question? Come frequent QA question and all those data put together and fit into the RIG. So when a customer, when the customer found your customer service, they always want like those kind of thing, right? I go charge. I don't know that how to use this and that. Those are most of the answers in the frequent, frequently asked QA and they just don't bother to read this or this IHG will help the customer service people to get the correct response to those customers. So the worry of this is improve the efficiency and customer satisfaction. Yes. But this, from a point of view, this can be also done without CSS and using just a simple LM with RIG on top or on this. So what is the difference? You've seen the cause. Can you just give a second please? I'm sorry, I didn't. I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they have a train, they have a model. They put on this model the documentation of what I have from the OTC. And with this, this is the RIG part so that they do can then the use case. It's to develop a chatbot with this chatbot, the same as here. You have your help center, you start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean, only that you know this and then you can tell me what is the difference. For me it's important to understand what is the difference because otherwise what if your solution is better and we already don't know. So let me show you this here. For example, can you see my screen? Yes. So I think you are not sharing. No, you are sharing. Okay, you see this in here. So this is behind this. As I told you, it's LLM with RIG and it's using only use the documentation URLs that we have on OTC. So there is no service description and so on. So if we call for example here how LTS support high, I don't know, high availability. So what this is doing it, it's you see in the left side is just the links that it found some kind of information but it's not doing something. And on the right side it's the this summary. I just try to creating some kind of response. Nevertheless, when it is then ready and done with all that information that is creating, of course all that information is based on the documentation of the OTC. So because we have this as basis. At the end, when it is completely finished, you may see for example here this number one. Number one is a reference that has been used for this answer for this part here. Number two refers to this one and three and two is just a mix these sentences from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been find this kind of information on that on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It shows LN and also RRG that RRG is just connected to these URL docs OTC systems comes no more. I think principally it's technically it's more or less doing the same right. It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. So I guess technically there's not much difference in what you finally get. The question is how complex is this hallway approach to build? Yes. What is the cost and what is the actual business model? Because in this case, this obviously being focused on end users. So if you want to make this happen again for your end customers, if you're like, for example, I don't know, a system integrator or something like this, you have to be either the partner of Mba search then again, or you have to make a commercial model with them to sell this to your own end customers. So this can be relatively complex and then also become a matter of cost related to that. Since I don't know how Mba search is charging and what they kind of invoke in business model means. And I have also no answer for the actual business model that is behind this moment. I think anyway, these are the things that we would have to compare. I mean, I guess it's not the technology set. The answer is also the business quality output. Also, how should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also, one of the big difference of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. So, but I can also ask the same question in German and I will get the answer in German, also with the reference in English. I think it's similar question in the same way. I'm trying to translate in German. You are German. You know, if I did some mistakes. It works in areas of football. I think the question is good. The answers that I see so far on the left side are not like that applicable. But I think on the right side, where it's still giving the answer is, looks good so far. Just looks primary, stand by, so fail over. So, you see, in this solution, I just got this and you may see here the reference. Also, I have a reference, but when we select the reference, it will be forward. Me to the documentation, state in English. So, that means this model can use for German and English and you see also a way to, even if I'm German and I don't, I'm not really confident with English and so on. So, I can just select it and I have exactly the reference to all of these answers here. So, it depends on the answer and the question. You may see all of this. So, if you have this also with your solution integrated, a similar way, we of course are very good. We have, we are now customers for it and I'm pretty sure we have still on the in German customers that are looking also for this kind of solution. For example. Yes, for your question, like what's the difference between us and the embossage? You mentioned they use the open source model to return the, return the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. You can build the end-to-end solution with all using all the open source solution. Yes, there's no problem. I can tell you that. Basically, you can build everything with open source nowadays. But why people still go to the commercial? Why people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? Yeah, we have different, we can see in different angle. Yes, the open source is cheap. But as I mentioned before, cheaply free cost most. When the server is down, when the server is misfunction, nobody, nobody care. You take all the risk, you yourself, if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Where SIE will help you answer the question. We also have me to help you build, take a look with what's your problem, give you some advice. That's all the commercial does. Similar story here. Yes. My question to you, I like it. I don't say that it's wrong. That we're wrong now. I would like to hear from you or Thomas or Boi if we can also offer with the Kulpagu something like this. I mean similar with English, German, like you see. Because I think demo will be really helpful. Yes, exactly. And a demo will be very helpful. Let me say something like this. I mean, open source, okay, fine for me. But if you can achieve such quality with open source like this, it could be a very good, I will propose also your solution because if you achieve such kind of resource, why not? I will be the last one that I will say no. I need to try to prepare a demo. I mean, if you find something like this. I saw the M-Bus Search, they are doing quite good for my first and yes, I can go back to Andy and find a demo for you and see how they are working on. But currently, the large language model is not very good at German. So when you speak German to them, you probably will just reply English or just randomly mumble something. That's one of the drawbacks. But I see what can I do. But most likely, demo will be English. If it's English, I think it will be a good start. Because we are here in Europe. So most of the people that are interconnected, they speak English. So that will be the very best start. So we can extend it later. But for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for our help center. And do you believe there are other use cases also related to this one that you are presenting? What I'm presenting now is the KUSA, the CSS for IG solution. Currently, it's only for IG solution. So only IG is strongly related. For your question, if you can use it in other scenarios, any IG use cases can buy our CSS with databases. One of the code competitive needs is... I'm not sure on my screen. It says Joshua starts the question. Maybe you stop it and start again. One of the very competitive for our CSS is... I think I was offline. Sorry, let me reconnect it to the network. Ah, just because you changed the... Can you see my screen? No, no, but it will become... Let me just reconnect it to the session. Join the session and rejoin the session. Yes. So during this time, guys from the team, what do you think about this solution from Gizia? It would be nice to know how the customer can make use of this. So whether this is an individual product or they can use this and they go to the CSS page or something like that, or how can they access this? I'm not sure I understood your question correctly. So you say how people are going to use this cool search. This is our box service. So it itself is a service. Okay, so this is a product you can find on the console? Yes, you can go to the Huawei's latest CSS version right now. I believe you can see something similar to it. But actually, to access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the Huawei Cloud. Yeah, access to the Huawei Cloud. And let's see. I'm also really curious because I like it. To be honest, I really like it. You are what you present. Now when we are all sitting together, you will have the chance to say it. So this is in CSS, right? Yes, in CSS. Okay. And then in the right region, so I'm from the region, it's fine? Oh, no. Or should I change it to Beijing? Change it to Beijing. Okay, let's change to Beijing. Okay. Just Beijing one as a Beijing one or Beijing four? Oh, did you see the cool search suddenly disappear? Yes, disappear just a little bit. I think you have to use the no international. China mainland. China mainland. Up on our right corner, I mean we change the access capabilities. But if you are able to choose Beijing one, he is in China mainland already. Otherwise, he wouldn't be able to. But the account is not. The account is international. So it may not be available international in the run up. But I can show you my. You can show us. Okay, let's see. I would stop sharing that. We have different kinds of accounts globally. I see that the Chinese account is missing. Accounts for China mainland and international. And they have different permissions. Okay, let's see. But this is supposed to be also available for me. I don't know. But they don't like me. I mean, I don't even have access to China mainland anymore. I'm only allowed to use euro as an employee. Only the region where you are usually working actually. So this is what Joshua also just mentioned for me. It's actually very difficult at the moment to get access for Chinese resources. That's because latency. No, no, this is just like I would say bureaucracy and budget. Ah, CSS. So Joshua, as you are sharing, I want to tell you you are not sharing. Oh, I'm not sharing. Okay. But I'm pretty sure you were on this. You see, this is the Beijing four region. And this is the CSS console right now. I have the cool search document. Platform. If you click this, it will ask you if you don't have permission. A platform permission. Yeah, I don't have this permission. So I cannot access it anywhere. So my story ends here. Yeah. Okay. Go to. But this is that's also said. An FB is our name. Yeah, then take this out. Using an FB service? Yeah. Then maybe you share your opinion. We are also using. Ah, look. The permissions. Are you having to say? Can we mention that before the MLP could be also a component behind the scenes? I can't. Maybe I missed that part. So in order to have this, we would have to have an FB as well. No. I mean, principally yes, but not as a service presented to the customer. Right. This is what we discussed before. Yeah. Okay. Question. Okay. Ah, I saw I see that you're cool. Yeah, that's the story. I can try to get permission and see for me or somebody else going to show you this demo. Yes. Perfect. The my key message is our CSS for RIG solution have this Q-Ring rewriting and result rewriting function. And even without those, even without the pangu itself is a very good vector databases. And here is you. Let me let me show you the GitHub for benchmark. This is the this is the that approximating nearly a neighbor, near to the neighbor search function is a is a search function in the benchmark. It compare with all those algorithm or or no, no algorithm. This is all the Search engine. Search engine. Yes. This this fast is very also very popular. You see 28k is made by the Facebook and it compare all of them. You can see our Huawei's searching algorithm is QSGN GT. I this I don't even know how to spell it. This is this is Huawei's algorithm is inside is inside the CSS. Yeah, you see QSGN GT. And this is the performance. You see it's green X here on the very top. So they are sorted from the best. I mean the list with colors on the right side is the ranking the best. The rest are here is the is like which one represent which graph. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do the better. Yes, in the same record rate, the more QRIT per second is better. So you see at the same record rate our Huawei's CSS searching performance is always the top highest. Yeah, see this line here. And horizontally the same speed the QRIT per second we will call it speed. Number per second right. The higher record will be better. We all know what record is. So the guys have access to this. Copy the address. Yes, yes. Sure. So the guys have not to type this. It's speed. Where is the... Sorry, I just looking for... If you put it on the... So leave then I can put it on chat. Oh, okay. So that will be I think the most is Spark and then we have it. Yeah, and this this repository is now maintained by Huawei and you can see it's a red... It's also very active a couple days ago. That's the last year and four days ago. So I think you can also show that our Huawei's searching engine is already have... Could mean something. Yeah, could be some competitive news. And the rest of them the rest of the... Image is also a similar story. But for different tasks. Those are all tasks and you can see how is the QS something something is also... Kind of competitive. Be something competitive. Okay, fine. Yeah, so that's one of the main point. The other point is already down in the CSS release note and the CSS promotion, guy slice, all those stuff is there. So even without the Pangu model CSS itself could be something. So that's all for the CSS... Sorry, and my presentation should be end here if you don't have any other question. Do we have any other question? Guys? Nothing from me. Good. Okay guys, then we will close this session. Thank you so much for joining. Hey, wait, I think Milan asked... Oh no, Martin is asked if the IG can use for the help center chat board. Am I understanding correctly? Okay, I suppose I basically have the same question already brought up by Ecuador. Oh, okay. Result, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem for business. Yeah, you see there is for OCR documentation. QSH is nothing hard. And yeah, so the answer will be yes. The documents are all English, it could be doing very well. Yeah, that's all for my presentation. Based on my outline, my very last topic is a little bit small discussion with the model us go out marketing. It's a brainstorm stuff. See if we want to talk about this because you know the model us is on his way of doing the upgrades smoothly and it will sooner or later upgrade to the latest. Now we have a chance on the asking us if you want to add any feature anything to make it more sellable in Europe. Anything you can check the how Google sells, how Israel sells, how Amazon sell their similar product and give them any advice they can see if we have a workaround or solution or just add this feature and they study very well. Right now, yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there's only just one way to find this out. Do you have a kind of benchmark of the current version for model us compared for example with AWS with all other similar products? Now you know this is Sange maker then in Azure. Google it's called machine learning. I think machine learning is for Israel. The Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions then it will be more simple to figure out in which session should we see the improvement on it. It's a little bit different. Model us is not like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do such. Model us is to machine learning and we don't have this benchmark for machine learning. It's more about the features that comparison. Yes, yes indeed. But what they might offer what we don't currently? Yes, what they might offer what we don't what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. Yeah, now the window is open. We still don't know what the new version or the fourth jump is still don't know what it will have. You can do it in several steps once we can get the release. No second you can go to the Huawei cloud and check out the latest model also directly. The latest version the Power BI cloud is running? Doesn't really matter. If you see it's good then when you upgrade it's no then you can always demand it and edit to the latest version. Now the window is open. What we can do is following because I know. I mean I am also the same opinion as Gervo because we all know that Huawei clouds in their regions they offer different versions. Oh just go to Beijing for time. Exactly but you could provide us with which region has the same version or similar version as we will get on the OTC so that we can just get a better I mean we can test everything of course but we will never have the chance to test APELs or Vodados in this case. So just give us an idea of which region and Huawei cloud has the current version that we will get the lever but really also the feature level and we can also figure out or see what is the difference because you know release notes okay fine for me but we need to touch it to check it and also for example we have here on our team Matt and Ferry or Shold or VNet or I don't know all the team members could also just check it and see what features are there really running we can see and probably also evaluate if there is some kind of I mean after that when we have the list of these features we can just see with customers if they are looking for another features then this one. I was thinking I think I missed the point the first time so what Joshua you're saying is that now we have a time frame Vodados R&D is giving us the opportunity to give feedback on what we would like to have in the future right yes indeed so I was thinking differently so I was thinking like if you see or Amazon have this feature I think it's cool Google have this feature I think it's also good just a little what you think is good and let R&D say it's available yes or no or do we have a workaround or do we have the do we have redeveloping something yeah that's my point. Okay for this we can use the public thought model and say it doesn't really matter. Yes it doesn't really matter. It will be maybe months or of course months but maybe half a year or so before this appears on OTC whatever we request right okay we can do that do you know how long this window is open? Yesterday now they have some session hosts and tell us to give them feedback I don't have anything on my mind so I will spring up the customized image this topic to them and I do hope we can add more good features inside it and so I don't know if I make my point clear now I tell R&D say hey your AI framework is related oh I would like to have some feature there can have latest framework latest driver CUDA, Pytosh, TensorFlow latest version I want to customize I would like to my decision which one is good which we choose which framework yeah I would like to have this feature now I bring these to them and I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lama 3 or training with Lama 3 those images and OTC can develop this image and make it available to customers so the customer just one click and they can deploy the Lama 3 already I also want to have this feature but I have those things in my mind but I do want some input from you guys that's that's that's what I wanted to talk about and it gives us I think some time two weeks I don't know how long yeah as soon as possible yeah because developing also needs some time okay yes we will try our best how about so how about we do this so our next screen starts on next Monday so we allocate maybe one or two days or from you guys so in this case so Matt, Joel, Ferry so maybe each of you spends one day comparing these stuff so I don't know if you guys have access to Bobbitt Club if you don't then Hector could provide you a user account or maybe even I could I don't know yes maybe Hector can provide me an account as well okay yes guys so we can give you an account you spend one or two days comparing GCP, Azure and so on yes and let's say the week after we get together again and we talk about this 5M on this one addition or one small topic for which would help us going to market it's a simple logo made for Europe or certified by for European usage or leveraged for Germany or something I think you are totally right Matthias, we can work I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now I think the best thing we have for the moment is AIC4 right and I had actually an interview with Ernest and Jan after the last audit they invited me for an interview and you know we have currently C5 this is our principal cloud certification yeah and AIC4 is nothing that we audit at the moment but Ernest and Jan at that time was already planning to offer to J-Systems to audit against AIC4 or whatever comes in future in addition so things like like AI Act etc so I think it's like a matter of time when OTC will have to review exactly this again and raise the hand and say guys now we have I don't know SOC C5 IT Grundschutz please audit and compliance what the next thing we should do is AIC4 audit or whatever it applies to have an official it's then right guys then it's now time for lunch thank you so much for joining this session um um Gero you just let me know who should then add to the Huawei Tenant for next week to take care of this model arts and I will then add them to Huawei cloud this is it I think okay this great one for short ferry and that okay short ferry map okay yeah okay okay great thanks for your time colleagues thank you thank you so let's go for lunch I think I'm going to go to what so nice presentation thank you Joshua Joshua thank you I like it thank you you
Meeting Minutes

Date: Unspecified  
Time: Unspecified  
Location: Virtual Meeting  
Attendees: Matthias, Joshua, Hector, Gero, Matt, Ferry, Shold, VNet (Team Members)  
Chairperson: Matthias  

### Agenda Items:
1. Discussion on Power BI Cloud Version and Features
2. Feedback Window for Future Feature Requests
3. Feature Comparison between Major Cloud Providers
4. Market Readiness and Compliance Certification

### Discussion Details:

#### Item 1: Power BI Cloud Version & Features
- The group discussed the importance of understanding which version of Huawei cloud services they will receive, akin to those available in regions like Beijing.
- A need for a test environment with similar features was highlighted to ensure compatibility and readiness.

#### Item 2: Feedback Window for Future Feature Requests
- Joshua explained that Vodados R&D has opened a feedback window to gather requests on desired future features for the AI framework.
- The team was encouraged to suggest features based on offerings from Amazon, Google, etc., for evaluation by R&D.
- Proposed ideas included customization options and integration with Lama 3.

#### Item 3: Feature Comparison between Major Cloud Providers
- It was decided that Matt, Joel, Ferry would spend time comparing features of GCP, Azure, etc., to provide valuable input for feature requests within the next two weeks.

#### Item 4: Market Readiness and Compliance Certification
- Matthias raised a point about obtaining a certification or stamp indicating European compliance for marketing purposes.
- The current principal cloud certification (C5) was mentioned as an example of existing compliance measures.

### Decisions and Action Items:

1. **Feature Comparison:**  
   - Matt, Joel, Ferry to allocate one day each to compare features from major cloud providers against Huawei Cloud's offerings by next Monday.  
2. **Feedback Submission:**  
   - Joshua will compile the team’s feature requests for submission to Vodados R&D within the feedback window.
3. **Account Access:**  
   - Hector and Matthias to provide access to Bobbitt Club accounts for Matt, Joel, Ferry as needed.

### Other Matters:
- Matthias suggested pursuing an AIC4 audit or equivalent certification for future compliance requirements, aligning with European standards and regulations.

Meeting Adjournment: The session concluded with plans for follow-up meetings to review progress on feature comparisons and feedback submissions. Participants were thanked for their time before proceeding to lunch.

---

*Note: Specific dates and times are unspecified in the provided transcript.*/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
Deleted folder: /home/linux/meeting_whisper/tmp2hlbj9ps
临时文件夹地址：./tmppo_cqvaw
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. Alright. What's another? Ooh,작alイ, this is suspicious. That's you for me. Oh, yeah, I was. Let's go to buy lunch. What do you think? No, go to right. What do you think about that? It's all or nothing. Nice presentation. Thank you Joshua. Joshua, thank you. I like it. Thank you.
Meeting Minutes

---

**Meeting Overview**

- **Date & Time:** Not specified in transcript
- **Location:** Not specified in transcript
- **Attendees:** Matthias, Hector, Gergud, Jolt, Ferry, Matt, and others (not explicitly named)
- **Chairperson:** Not identified; likely Gergud based on context clues

**Agenda Items**

1. Feedback Opportunity for Huawei Cloud Features
2. Requesting Customized Image Features for OTC
3. Market Differentiation via European Certification

**Discussion Details**

1. **Feedback Opportunity for Huawei Cloud Features**
   - A window is open to provide feedback on desired features for the upcoming version of Huawei Cloud.
   - Discussion focused on identifying regions with similar versions or feature sets as those expected in future releases, especially Beijing's region.
   - Requested a list of current features from other cloud providers like AWS and Google to compare against what Huawei could offer.

2. **Requesting Customized Image Features for OTC**
   - Highlighted need for customizable images that include latest frameworks (CUDA, Python, TensorFlow) as well as drivers.
   - Suggested addition of Lamar-free images for inference and training scenarios for easier deployment by customers.

3. **Market Differentiation via European Certification**
   - Matthias raised the point about having a logo or certification indicating compliance with European standards or Germany-specific requirements.
   - Mentioned that AIC4 audit could be a potential pathway towards obtaining such recognition, aligning with future AI Act regulations and certifications like SOC, C5.

**Decisions and Action Items**

- **Action Item 1:** Matt, Jolt, and Ferry are to spend one day each comparing features across GCP, Azure, and Huawei Cloud.
   - **Responsible Person(s):** Matt, Jolt, Perry
   - **Deadline:** Within the next week, before the upcoming spring (exact date not specified)
- **Action Item 2:** Gergud is responsible for adding Matt, Jolt, and Ferry to the Huawei tenant for access to ModelArts.
   - **Responsible Person:** Gergud
   - **Deadline:** Prior to the next meeting where they will discuss findings

**Other Matters**

- Lunch was announced as the conclusion of the formal meeting agenda.

--- 

Please note: Exact dates, times, and locations were not specified in the transcription provided; thus, placeholders or descriptions based on context clues have been used instead.Meeting Minutes

---

**Meeting Overview**

- **Date & Time:** Not specified in transcript
- **Location:** Not specified in transcript
- **Attendees:** Matthias, Hector, Gergud, Jolt, Ferry, Matt, and others (not explicitly named)
- **Chairperson:** Not identified; likely Gergud based on context clues

**Agenda Items**

1. Feedback Opportunity for Huawei Cloud Features
2. Requesting Customized Image Features for OTC
3. Market Differentiation via European Certification

**Discussion Details**

1. **Feedback Opportunity for Huawei Cloud Features**
   - A window is open to provide feedback on desired features for the upcoming version of Huawei Cloud.
   - Discussion focused on identifying regions with similar versions or feature sets as those expected in future releases, especially Beijing's region.
   - Requested a list of current features from other cloud providers like AWS and Google to compare against what Huawei could offer.

2. **Requesting Customized Image Features for OTC**
   - Highlighted need for customizable images that include latest frameworks (CUDA, Python, TensorFlow) as well as drivers.
   - Suggested addition of Lamar-free images for inference and training scenarios for easier deployment by customers.

3. **Market Differentiation via European Certification**
   - Matthias raised the point about having a logo or certification indicating compliance with European standards or Germany-specific requirements.
   - Mentioned that AIC4 audit could be a potential pathway towards obtaining such recognition, aligning with future AI Act regulations and certifications like SOC, C5.

**Decisions and Action Items**

- **Action Item 1:** Matt, Jolt, and Ferry are to spend one day each comparing features across GCP, Azure, and Huawei Cloud.
   - **Responsible Person(s):** Matt, Jolt, Perry
   - **Deadline:** Within the next week, before the upcoming spring (exact date not specified)
- **Action Item 2:** Gergud is responsible for adding Matt, Jolt, and Ferry to the Huawei tenant for access to ModelArts.
   - **Responsible Person:** Gergud
   - **Deadline:** Prior to the next meeting where they will discuss findings

**Other Matters**

- Lunch was announced as the conclusion of the formal meeting agenda.

--- 

Please note: Exact dates, times, and locations were not specified in the transcription provided; thus, placeholders or descriptions based on context clues have been used instead.
./tmppo_cqvaw/20240510_121130.m4a
临时文件夹地址：./tmppo_cqvaw
上传文件的地址：/tmp/gradio/570750b7c1c9cd933c2a6863963b8b62098326a1/安全周例会710.mp4
base name 安全周例会710.mp4
 We wrote about it I think, but I think we haven't talked about it last time about the EPS GA. As Tino explained, I think it was written also to you, I am not sure what Bruno said. I explained it to you because Tino also explained it to me. EPS offers its main functionality or its main advantage against IAM if it is used in more than one region. So we currently only have it active only for Aspiegel, yes, but we only have it in EOTE currently. For UNL it is basically activating the APIs there. There is no deployment, there are no nodes that need to be deployed there for enabling it in UNL, but we need to enable the APIs. So that is what would need to be done. But the bigger issue I think is that I just learned this morning that the APIs of EPS have never been tested on TSI. Well, Aspiegel is already using it for quite a while, so I hope they are not completely bad. But nevertheless, we would need to have some quality tests, except for the tests of the APIs from our testers. Or we can launch it in front of the other customers, definitely. So if I just check if I get it right. So quality tests, yes, sure, I agree to have a quality test. But quality tests at EOTE region or EOML region? We can do it at the EOTE region because it is testing the APIs. So the APIs will be the same for UNL and EOTE. So we could, with the already existing solution we have, we can do the testing, the functional testing of the APIs, the quality testing. So that is not an issue. When will the test be done? That is not so nice information because we do have the Cloud Firewall testing, right? And I don't want to delay the Cloud Firewall testing in order to have the EPS GA earlier. Yes, I know, but the Cloud Firewall is just one server and I don't think you don't have enough for them to do so, right? Because you have more than one QA. Ah, barely, barely, let's say so, right? So I have two, yeah, I have two and a half testers. Yes, that's more than enough. One of those is doing the quality testing, so testing the UI, testing everything working as intended and stuff like that. He is fully busy with Cloud Firewall testing it. Okay, that's cool. It is currently on vacation, but he is back, he will continue testing it. I have another tester who is focusing on the APIs, reviewing the documentation. He is also reviewing the EPS documentation you provided, so that is his job. And also testing all the APIs from the beginning to the end, right? Creating all these bugs and stuff like that, taking care that the bugs are handed over to T-Ball and that he also understands what is going on there and so on and so forth, right? And I have one tester that is shared with another squad, a database squad. So I only have 50% of him and he is quite new. He is with us now for three weeks, I think. And, yeah, almost four weeks, anyway. Almost four weeks. So he starts to really do testing, but he was in the onboarding first. And he is supporting then in the API testing, so Lukas in his part. But I need this one and a half, even if the new tester is fully in working mode, right? I need these one and a half testers full time to get the Cloud Firewall tested as soon as possible, right? Because the testing task is a task that can be parallelized very well for the APIs. I do the following APIs, you do the next one, right? And that is very good and that speeds up the testing progress there. So I would not say, OK, one of the testers is now doing the EPS API testing because the Cloud Firewall, I think, Ketino correct me if I'm wrong, but I think that's better business potential than going GA with EPS. EPS is free service. Yes, yes, it's free service indeed. But we're hiding the EPS for a long time and it causes a lot of problems when we're ever trying to GA any service, not just our squad, the other squad also have the similar problem. I guess now the problem is just testing, right? Otherwise, it's very used product by at least one customer. Question B, what is your timing for CFW testing and can we then directly continue with EPS? That's the goal, right? So the timing is, let me have a look. Let me open here. So the goal is to be done mid of September with the testing actually. So we planned the whole API for testing for the firewall and then it should be done. It depends a bit on how much we find there and so on and so forth, right? But it's realistic that we will be done mid of September with everything, QA, API testing and stuff like that. We're testing hopefully already having some fixes for some bugs we had. That's a bit pessimistic actually. So, being finished with the testing completely so that we can go live afterwards with the… so afterwards going live, so beginning of next API, go live with CFW. It depends of course a bit on there are some dependencies, right? If we see that the quality is not as expected, if we see that there are issues, especially in security testing but they finished security testing and they told me that there are no bigger issues. That should be fine. But if we see in the quality or in the functional testing that there are some unexpected issues, that something is not working as intended or whatever, then this might be delayed. But I don't expect that currently and I don't hope so. So that's just a word of warning of course that there might be delays in case such things happen. Yes, but I still think September is way too long. You have people working… If we are done earlier Joshua, then we are done earlier, right? So that's fair enough. But we need to do our testing. If my testers say I need to do it until the middle of September for testing it, then I trust them. I just hope your testers do their work. Do their work like five days per week. I hope you know what I'm saying. Right now it's early July and always betting time is September, which gives me a feeling that… Let me say it that way. My testers, especially Lukas, tested several services already. The timeline he provides me is of course biased by the fact that the APIs of the last service he got, that he needed to test were so bad, that there were so many bugs, that he needed to prolong the tests all the time. So if the API for the Cloud Firewall is very good, then he will be done earlier. That's fine. There's no issue at all. But based on the experiences we had, we'd rather plan a bit more time, instead of delaying the release of the feature again and again and again, because we have too many bugs that need to be fixed before we can launch. So it doesn't help us right now to say, yes, we are done. That thing is bad, yes, I hear enough, and I do hope we can give some detail. What is bad? Which server is bad? How is bad? We talked about planning. I haven't said that the API is bad, but we present more. It was. Have a look on the bugs we have opened for the HSS APIs. I can't even count them. There are so many. The major things we have fixed, it's all fine. It's all good. I don't want to complain. It delays our... After this meeting, I will ask my people to open the bug TV and see what exactly is going on there. Sure. That's fine, right? I don't want to tackle now half things. I don't want to hide about some things that happened in the past. Well, for HSS, there are still a lot of minor bugs opened, but they will be fixed in time sooner or later. That's okay. But for HSS, we also planned to launch way earlier. In the end, we needed to postpone it again and again because you know the story. In the end, both sides were angry. You want to free up your resources. I can completely understand that. On the other side, it was still the other side. Then also me afterwards, I wanted to get that done. I wanted to launch it. It doesn't help us if I say now, okay, yes, let's plan to launch CFW in August. We are in the same situation and we can't launch because nothing is ready. I rather say we test until mid-September because from what we experienced in the past, how many bugs we usually get in the testing there, I can only use this as a parameter for my planning. Then I say, okay, it takes longer than I want, than I'd like to, but I need to plan it accordingly. If we are then done two weeks earlier, fair enough. That's good. But delaying it again and again is something I'd like to avoid. Of course, we tell something to our customers and if we tell our customers, it will launch in September and then we need to tell them, sorry, no, we will launch in October, no, we will launch in November or something like that. That's bad. That's not good for our reputation. Yes, but that's not the point I want to talk about. Yes, I completely understand what you are saying, but I just want you to make sure your team, your QA is actually working. They are working. They are not creating bug tickets all of a sudden. So they are testing these things. Because from my experience in the last year, yes, from my side also have a bad experience. People gone for weeks, months, yes, months, disappear for the whole month. Nothing gets done. They just vanish, disappear. Not since I'm here, so I can't talk about that. I guess one of the people we kicked out. Yes, something bad and bad consequences will come, which is none of us will be willing to see that coming. So just make sure people are actually working and things going forward smoothly. Definitely. And also maybe one thing for you I'd like to improve a bit, because what I am a bit afraid of or what I had a feeling a bit in the past was regarding testing. They were a bit lacking this, okay, when is the testing phase ended? Testing phase ended. Yes, because if I tell a quality tester, please test the product, he can test it forever. Yes, indeed. He will always find bugs, new bugs here and new bugs there. It will never finish, the quality testing of anything. That's important for me that I together with the testers define clear goals. We say okay, until this point we do test and then it's done, then it's tested, and then we close the test case. Because that's currently not existing that precisely. I think that's important also for better planning for everyone. If we know okay, we test that much and then it's okay. That is also clearly communicated then also to you about our... Yes, we do have some common understanding with the OTC's management. It says what is a blocker, what is no blocker is very clearly written. What is no blocker is very clearly written down in some page in the reference. Yes, exactly, I know. If it's a blocker or something serious, we will take care of that immediately. But if it's quality, some minor stuff, I say we just create a back ticket and wait for R&D to fix it in the future version. That's clear, that's not what I'm referring to. For me it's like when do our testers stop testing? Because actually I should never launch a ticket because if the testers are still testing, they could still find blocker bugs. But it's not that likely anymore after a specific amount of time, after they are basically already tested with everything. But what does it mean I tested everything? You can never say I test everything. For APIs you can say okay, I have a routine, I test this, it's all fine. But especially quality you can never stop testing actually. Nevertheless, we need to define, I need to define with the testers something like now it's considered test is done, the initial test is done, it's fine, bugs are handed over to Huawei, you are fixing the most important ones, where the blocker is the highest priority things, and then we are only doing retesting. We check, okay, have the bugs been fixed or if a new functionality is added to some new update or whatsoever with a version upgrade, then we are doing the functional testing again in a limited amount, let's say so, with only things that can be affected with this update. That's what I was talking about. That's what I was referring to. But it's fine, we don't need to discuss it too much. I just wanted to inform you that we are also planning to do something in that regard because it's better for the predictability of the test in the future. Okay, we talked way more about EPSGA than I expected actually. I would suggest that we move over to HSS or do you want to talk about HSS first? No, one question would be just so, can we at least in uncommitted states, say then we can include some EPS task in the next PIP? Yes, yes, yes. Okay. In the next PIP, definitely, so probably even committed. Okay. Because we will not have too much stuff to be done for cloud firewall anymore in next PIP. Do we need anything from Joshua or Kibo for this task for EPS? Anything? Yes, but we are already preparing that currently in parallel a bit regarding what exactly we need to do to enable the APIs for UNL. But that should be a no-brainer actually, it should not be too much. Okay, so I could also put EPS on our roadmap somewhere at the end of this year. Yes. Okay. Good. Then I'm totally fine to move on with HSS because it's a bit, let's say, pressuring because as you saw Joshua, we announced the public webinar at the end of this month. So we better be prepared to show it live in the production environment. Yes, I will also, I'm also preparing the ransomware protection video. I'm recording a video and a short demo and hopefully you can also reproduce it. I was still working on that. And hopefully I will have some news today or tomorrow. That's nice. How could we get the ransomware that you have the ice fire there, the ice fire? Do I ever show you the ice fire? If you want it, I can send it to you. You can buy it in the black dark web. No, I'm kidding. I haven't been there yet. I will send you sometime in the future. Okay. Would be very interested in it to try it also out in some VM. Hopefully we can do the demo so that you can reproduce it. Perfect. Cool. Thank you. That's cool. Basically, I also showed HSS the current status to some sales colleagues last Friday as I told you. So basically I mostly received positive feedback that these kind of solutions are requested by customers because they want to see their, say, security posture and want to do things, vulnerability management and so on. But I received three main points where I opened also a bug ticket. I don't know if it's a bug or if it's working as designed. First of all, I guess you talked already about that one, is the compatibility with current operating systems. So the customers, we also advise them to only use or to update to the most current supported operating system. A lot of them use, for example, Windows Server 2022. And officially we are not supporting some newer versions of HSS. So HSS is supporting the newer version operating system. Yes, indeed. I haven't taken this with me, but I hope I can take this with me now. That would be really, really cool because I know there will be questions from the customers on this webinar. Like, OK, I have Windows Server 2022. When will it be supported? Because we support older versions, but the customers, they are not even allowed themselves to use, for example, Windows Server 2008. I guess that's out of support since, I don't know, a few years. And that would be really necessary to have up to date operating system support. That would be cool. OK, I will ask the HSS R&D later. Yes, that's great. Secondly, it's about the vulnerability database. I guess you will then update it once a month or what is the lifecycle because we haven't documented it somewhere in the docs page. Customers will see or ask. Currently, the database is two months old for vulnerabilities. When will it be updated and how often? I think you just answer yourself once per month, right? Is it, let's say, agreed, aligned? Can we document this in the help center somewhere? So is it fixed? Processed? This is more like maintenance stuff. Our SIE will help you update the HSS every month. Do you imply that they are not doing their job? No, no, no, no, no. What I imply is I want to have it documented because otherwise... You want to write it down somewhere, OK. Yeah, because the people are asking me when will it be updated and then the next day another guy is asking me when will it be updated. Then I can provide a link here in the doc center. It states once a month is the update cycle. You can also communicate this to customers. Please don't ask me again. This kind of way that we have this lifecycle of vulnerability database update somewhere in the help center. I mean, if you say once a month, is it like end of the month, start of the month or something? When do we usually do that? Because then I would ask... The official statement is as long as they have the update on the center, on the HSS, then you can upgrade it. You can, based on the HSS support center, you can do the upgrade. And the HSS support center is updated every month. OK, so I guess that's something that we need to discuss, Sebastian, when you would like to plan it. And then we say, OK, like every, I don't know, every last Friday of the month or every last week of the month, we update the database and put that one somewhere in the docs page. And then we kind of kill this question by different people. I would clarify that. That's good. OK. I'll write it down. I will ask the MD later. Probably tomorrow, day off earlier in Wednesday. Cool. And then I had the last thing. It's about if you install the agent or if you download the agent, at least on Windows, I don't know if it's only on Windows, and you double click on the X, you get a notification about unsigned software and that it is blocked. So people then asking why is it seen as unsecure? So is it possible to somehow sign this agent that you can just install it without any blocking by the operating system? Let me see if I get it right. So you install the agent, you double click the agent and you what? Let me see the story I shared with you as well. So I also shared some screenshots with you. Can you give me a screenshot later? I can do it now. You prepare a screenshot and I will see what's up with Andy. So just three things for HSSRI. One is supporting the latest operating system. Second thing is to upgrade the database. The third thing is whatever you just said. Then I have just one question. Because our documentation says HSS is working on cloud and off-cloud like on-premise and on different clouds. Theoretically it's doable. Okay, so practically we need to make the communication then available to the Internet, right? Yes, you need to. Based on R&D you need to have ECS ask the trans, what's that called? Transfers, transmin, transplats the message. You will have ECS on the OTC and taking care of the message that agent from other clouds send it to here. I didn't understand you. We need a proxy virtual machine? I think so. I think that's what it means. A POSTEC virtual machine. Do we have a documentation for customers how they can do it? Because customers are already asking, okay, can I protect my on-premise virtual machines? And based on our documentation the answer is yes, sure you can also protect your VMs on-premise with our solution. Of course, they pay the agent and if they also use the on-premise VMs it's more revenue for us. But we don't have any documentation how to do it because currently you download the agent and then it has some configuration. And this is just internally so it only works when you are inside OTC but not like on-premise or AWS or Azure or somewhere. Okay, just need a document. If you have any guideline how to make it work for on-premise VMs, like I install just the virtual machine on my laptop, I install HSS agent, how do I configure it to work with my tenant? Like what do you call it? Off-cloud, on-cloud, third party cloud, something like that. Okay, and that are the main points from my point which I received as feedback so far. I opened some other boxes in this ticket but these are not really blocker ones. And I will send you then the link with this signature thing after the meeting. One question for HSS I have is about file integrity management. Let me just open my tenant and then I share the screen. Okay, so I have a file integrity monitoring. So I have a file integrity monitoring. File integrity monitoring, what is that? Let me just open my tenant and then I share the screen. So when I go to HSS I have a lot of features and one of them is file integrity monitoring. What does it do? How can I enable it? In the documentation there is nothing to find about how to enable it. I tested it, it works just fine and it is hard to explain. Maybe I will show you a demo later. That would be nice because I have nothing to show and I have no... For web developer protection I can add a server but for file integrity monitoring I don't know. You need to get into the virtual machine and change some critical system file. If you change it it will trigger this function. I think automatically I am not quite sure. Okay, because again the documentation... If you go where is it? File integrity monitoring. You can view here but there is basically not that much and checking change details. But what is monitored? What is a critical file? What is the details? Which folder or which file is critical for HSS that is not documented? I don't know when it should even trigger if you know what I mean. I don't know what you mean. You said if you change some file... Which? System-wise file. You know you log into the Linux virtual machine, if you type ls it will list all the files under the folder right? This ls is system command. Somewhere in the system you have this system file. It is reasonable. If you go there, delete this ls and ls command and you will find that... Okay, I am a virtual fire. For example if I go to Windows and System33, these are system files here. So if I delete any of that on the virtual machine it will be identified. The question would be which folders are monitored? So what is a system file? It would be interesting to know which files are protected by it. Because for me if I see fire integrity monitoring I would also be interested in having something like an audit configuration to be protected. Because if someone is tampering around with my logging configurations, well it is interesting for me. I want to know. Is it now considered a system critical file? Maybe it is. But maybe it is not. What is monitored? What is a critical file? Maybe I can add a folder later? I don't know. I cannot use the system settings in HSS. It is just empty. But if you can give us some demo that would be really helpful to understand it and also show it to customers. Okay. Or maybe just a few screenshots. Also fine. Just to see how it works. Just one example. Okay. Cool. And I guess that is it from HSS side, from my part. Do you have anything on your mind Sebastian? I suppose the HSS is not... I want to try out to camper with my audit. Sorry, my contact. So to... Oh, I am mistyped. To... To check it. Yeah, actually. Anyway. But for HSS... ... on my page right now. Hi, Tibor. Hi, Tibor. We only have 15 minutes left, 40 minutes left. But we still have the topic of DWAF in UNL. Tino, you wanted to talk about? Was there a customer request? Yes, so I worked with customer impediment. And we just received a customer impediment for customers in the Netherlands. They also would... I guess it is not the second customer. They want also to have the dedicated DWAF on the Netherlands regions. Because they need to fulfill their requirements to use DWAF, but not put the web server in the internet. Which is necessary for the shared DWAF. And I guess either way, somehow later on we want to have feature parity. That all services we deploy on German region are also available on the Netherlands region. Otherwise, yeah, we do not attract customers to this region when a lot of services are missing. Question would be if and how we can also plan to deploy the dedicated DWAF on the Netherlands region. If that is something where we need a lot of effort, a lot of time. Because I mean we already have it live on the German region. What is necessary to start dedicated DWAF on the Netherlands region? So if it is something we can put on the roadmap in midterm. Yeah, yes. Can you say something about this Joshua? Is it possible that we can also focus on dedicated DWAF in the Netherlands region? The answer should be yes. But first it depends on the customer wise. Because I never hear this customer on our side. I don't know why and when and how much profit they are going to bring us. Basically, I mean the motivation to do this is sufficient. And the second thing is it's more like it's not a new service, right? It's already deployed on the UD. We just need to do some upgrades on the testbed. Is that upgrades on the testbed? No, no, no. The Netherlands doesn't have that, right? That's the new service delivery. That's no good. So I can answer you the first question. I mean officially you are not allowed to know customer names. I don't need their names, but I need their industry and... It's education and it's more like... you know Telus? Telus, yes, I know. It's a partner customer, let's say, from educational and meteorological sector. Let's say. You know this earth observation stuff. This kind of customer and they need to use dedicated DWAF. Because the shared DWAF would not fulfill their security requirements. They would be quiet by kind of end of this year. And if we cannot provide dedicated DWAF, then of course they use a third party solution. Yeah, for UNL we don't have a test environment as you know. Yes, for your information, and yes I kind of got the background. But I still think our side is not the main problem. But please aware we still have a lot of servers like CBH, like Seqmaster, like CCM. A lot of servers are in the queue. Which I don't see is prepared to deliver in this year anyhow. And you say if we don't get it at the end of this year, they will go to have third party solutions. So I think you should ask Sebastian what is his plan, whether he have enough people for doing that. Just for my understanding, basically as we have it live on Germany, it's not that much effort, right? Because I mean it's a known service or? We still have some effort because in Germany basically it means the testbed already have these servers. We can, at least now we can, we skip the testbed as standard procedure. We skip the testbed because testbed already have and deploy there into the Netherlands. And it will cause, still it's like a new source delivery. And you said I should further talk to Sebastian, so basically from yours? You, Sebastian, like give us an idea when you think you can do it. Sebastian, give me an idea of what he can, is it possible this year? Let's play the game further. I have no clue how much effort it is to implement it rather than even so. I need to analyze this for people. Yeah, if you calculated the previous one on UB, it was a lot of time especially with the testing. I already tested it, it's the same package which is already on production and deployed on production because we don't have tests. But I guess it still requires the test, right? Yes, but you can only test on production environment, right? Yes. Okay, so you... What we would need to do Tino is actually we would need to deploy it there. Unfortunately, your assumption is that to say, yeah, but we already did it, right? It should be the same and there should not be any surprises. I'm afraid that does not work that way. We are doing this, we are deploying on production anyway, we are hiding in the console and we did some simple small tests. We are supposed to be quicker, no death row, I mean, no death row, like a completely new server. It will be quicker but we are still doing some tests. But for example, we could put it on production and whitelist only this week and say, okay, it's live and beta status, we are still testing it. But we have it live in, I don't know, let's say October or November, December, whatever. So we have it there, it's still in testing phase but you can start to use it and do your proof of concept and whatever and in the meantime we are testing it. Next PI will have capacities for implementing this, Tino. That's not an issue, right? Yes. That's definitely fine. It depends on the speed of implementation, right? Because although we already implemented it in the UDE... The UDE is a bit different than EODE unfortunately. So it's not like, okay, we do the same thing just again, right? And everything will be working out fine. So there might be like, oh no, that does not work, we need to do something else. The network in NL is completely different to the EODE one, right? So especially with regards to communications, there might be some mess in the UNL and we might need to do troubleshooting and finding out, okay, together with the network connectivity squad. That can cause us delays of two months. Totally fine. Just want to... You know the deadlines by customers are not so strict usually, so nobody's dying. And if we say, okay, we plan it somewhere next quarter and you may get it, they may wait usually and say, okay, at least you have it on your roadmap and we can wait two months. That's totally fine. So it's a totally different story that we say, no, we don't do. Please go to the competitor. That's another story. So you have the capacity to have it in your... to deploy it in UNL from my perspective. So from implementation capacity point of view, right? If Huawei does have the capacity to support us there in the implementation, that is completely fine for me. Yeah. We tomorrow have the capacity to doing this. Can you? Tomorrow? No. You see? So give me a day. Yeah, that's right. Next TI. So mid of September we can start. Mid of September. Okay. I will say we keep this topic and discussion next next room and meeting. Okay. Totally fine. We don't have that much time left. I have two items. I would like just to ask it's about the DBSS support from MySQL. That's the plan for next TI, but will be done quicker, right? So that is somehow in progress already. MySQL is planned this TI. This PI. This PI. Okay. Let me check. Let me check. Instead of me talking something wrong, we are talking about pre-production only. Talk production that customer can use it. Okay. I am having pre-production will be doing this PI next PI production. Sorry. Okay. So this is still on track. And the other one is the DWAF support for WAF instance. That is planned for also this PI already. The WAF ERB mode, yes. Also having pre-production is this PI. And what next PI? Next hopefully because we are depending there on network services. No, network services support. Network services support for the ERB upgrade. Okay. They don't get that done. They planned to get that done with the PI, but uncommitted. Okay. Good. And then just one last thing. Joshua, you offered kind of again an introduction session for cloud-based channel CBH. Can we plan it for somewhere? I don't know. This week, next week? You call. Sorry? You call. You call the time. Okay. Tomorrow 11? Tomorrow? Tomorrow? I have time tomorrow. I don't know how about you. I have time. Friday? Friday is quite packed for me at least. I'd like to join. For me also. Then maybe next week after our meeting at 11? Yeah, that's fine. I will schedule something, okay? Okay. How much time do you need? One hour? One hour should be more than enough. Yeah, if you had done earlier then that's fine. So next week, Monday, next week, Monday 11 a.m. CBH introduction session. Yes, who else wants to join? So Kino, Joshua, me? I will forward the invite to the necessary people. Kino, someone from your side who needs to join? And if they are not available I will propose another time. Okay, perfect. I guess from our side just you and me to just get an overview of the service and the fit. Yeah, that's totally fine. Okay, I guess. Yeah, time is over. That's our invitation. Maybe we could talk about so much things. But then I would say we talk again next Monday for next topics. Just one second, do you have an extra minute? Yes, yes. Thank you. Alright. Thank you Kino, thank you Joshua. Thanks Kino, thanks Joshua. Thank you. I also wanted a minute of you Sebastian, can I also stay? If you are interested in it. So Kino, if it's not that secret that you don't want to share with Kino, then it's fine with me. Okay, see you. Alright Joshua, then take care, bye. Bye bye.
Meeting Minutes

Date: Not specified (assumed recent)
Time: Not specified
Location: Virtual meeting
Attendees: Kino, Joshua, Sebastian
Chairperson: Not mentioned (assumed Sebastian)

1. Meeting Overview:
   - The meeting was held virtually with participants including Kino, Joshua, and Sebastian.
   - No specific date or time was provided in the transcription.

2. Agenda Items:
   a) Analysis of Package Deployment on UB
   b) DBSS Support for MySQL
   c) DWAF Support for WAF Instance
   d) Introduction Session for Cloud-Based Channel CBH

3. Discussion Details:

   a) **Analysis of Package Deployment on UB:**
      - There was discussion regarding the time it takes to analyze and test packages, particularly with the deployment on UB.
      - It was mentioned that testing is necessary even when deploying an already tested package from production due to differences between environments.
      - The group acknowledged that testing in a production-like environment could provide better assurance of functionality.

   b) **DBSS Support for MySQL:**
      - DBSS support for MySQL is planned for the next Time Interval (TI), which may be completed earlier than scheduled.
      - The current plan is to have pre-production ready during this Performance Improvement (PI).

   c) **DWAF Support for WAF Instance:**
      - DWAF support for Web Application Firewall (WAF) instances was discussed, with a planned implementation in the current PI.
      - Pre-production phase is expected to be completed by this PI, with production readiness potentially delayed due to dependencies on network services.

   d) **Introduction Session for Cloud-Based Channel CBH:**
      - Joshua offered an introduction session for CBH and it was agreed that a one-hour session should suffice.
      - The session will take place next Monday at 11 am following the regular meeting, with additional attendees from relevant departments to be invited.

4. Decisions and Action Items:

   a) **Deployment of Package on UB:**
      - Decision: Testing is required even when deploying tested packages from production due to environment differences.
      - Action Item: Begin deployment in mid-September for testing purposes while allowing beta usage by customers.
      - Responsible Person: Not mentioned
      - Deadline: Mid-September

   b) **DBSS Support Implementation:**
      - Decision: Pre-production phase will be completed this PI, with production readiness scheduled for next PI.
      - Action Item: Monitor progress to ensure on-time delivery of DBSS support for MySQL.

   c) **DWAF Support for WAF Instance:**
      - Decision: Address network service dependencies to avoid delays in the production phase.
      - Action Item: Ensure pre-production is completed by this PI and prepare a contingency plan for potential delays.
      - Responsible Person: Not mentioned
      - Deadline: End of current PI

   d) **Introduction Session for CBH:**
      - Decision: Schedule a one-hour introduction session next Monday at 11 am following the regular meeting.
      - Action Item: Send invitations to necessary participants from relevant departments.
      - Responsible Person: Kino (or Sebastian if not explicitly mentioned)
      - Deadline: By Sunday before the scheduled session

5. Other Matters:

   - No additional points were noted in this summary.

Please note that specific details such as names, dates, and times are assumed or extrapolated based on context when not provided verbatim in the transcription./root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
临时文件夹地址：./tmp9p3lew4x
上传文件的地址：/tmp/gradio/570750b7c1c9cd933c2a6863963b8b62098326a1/安全周例会710.mp4
base name 安全周例会710.mp4
 We wrote about it I think, but I think we haven't talked about it last time about the EPS GA. As Tino explained, I think it was written also to you, I am not sure what Bruno said. I explained it to you because Tino also explained it to me. EPS offers its main functionality or its main advantage against IAM if it is used in more than one region. So we currently only have it active only for Aspiegel, yes, but we only have it in EOTE currently. For UNL it is basically activating the APIs there. There is no deployment, there are no nodes that need to be deployed there for enabling it in UNL, but we need to enable the APIs. So that is what would need to be done. But the bigger issue I think is that I just learned this morning that the APIs of EPS have never been tested on TSI. Well, Aspiegel is already using it for quite a while, so I hope they are not completely bad. But nevertheless, we would need to have some quality tests, except for the tests of the APIs from our testers. Or we can launch it in front of the other customers, definitely. So if I just check if I get it right. So quality tests, yes, sure, I agree to have a quality test. But quality tests at EOTE region or EOML region? We can do it at the EOTE region because it is testing the APIs. So the APIs will be the same for UNL and EOTE. So we could, with the already existing solution we have, we can do the testing, the functional testing of the APIs, the quality testing. So that is not an issue. When will the test be done? That is not so nice information because we do have the Cloud Firewall testing, right? And I don't want to delay the Cloud Firewall testing in order to have the EPS GA earlier. Yes, I know, but the Cloud Firewall is just one server and I don't think you don't have enough for them to do so, right? Because you have more than one QA. Ah, barely, barely, let's say so, right? So I have two, yeah, I have two and a half testers. Yes, that's more than enough. One of those is doing the quality testing, so testing the UI, testing everything working as intended and stuff like that. He is fully busy with Cloud Firewall testing it. Okay, that's cool. It is currently on vacation, but he is back, he will continue testing it. I have another tester who is focusing on the APIs, reviewing the documentation. He is also reviewing the EPS documentation you provided, so that is his job. And also testing all the APIs from the beginning to the end, right? Creating all these bugs and stuff like that, taking care that the bugs are handed over to T-Ball and that he also understands what is going on there and so on and so forth, right? And I have one tester that is shared with another squad, a database squad. So I only have 50% of him and he is quite new. He is with us now for three weeks, I think. And, yeah, almost four weeks, anyway. Almost four weeks. So he starts to really do testing, but he was in the onboarding first. And he is supporting then in the API testing, so Lukas in his part. But I need this one and a half, even if the new tester is fully in working mode, right? I need these one and a half testers full time to get the Cloud Firewall tested as soon as possible, right? Because the testing task is a task that can be parallelized very well for the APIs. I do the following APIs, you do the next one, right? And that is very good and that speeds up the testing progress there. So I would not say, OK, one of the testers is now doing the EPS API testing because the Cloud Firewall, I think, Ketino correct me if I'm wrong, but I think that's better business potential than going GA with EPS. EPS is free service. Yes, yes, it's free service indeed. But we're hiding the EPS for a long time and it causes a lot of problems when we're ever trying to GA any service, not just our squad, the other squad also have the similar problem. I guess now the problem is just testing, right? Otherwise, it's very used product by at least one customer. Question B, what is your timing for CFW testing and can we then directly continue with EPS? That's the goal, right? So the timing is, let me have a look. Let me open here. So the goal is to be done mid of September with the testing actually. So we planned the whole API for testing for the firewall and then it should be done. It depends a bit on how much we find there and so on and so forth, right? But it's realistic that we will be done mid of September with everything, QA, API testing and stuff like that. We're testing hopefully already having some fixes for some bugs we had. That's a bit pessimistic actually. So, being finished with the testing completely so that we can go live afterwards with the… so afterwards going live, so beginning of next API, go live with CFW. It depends of course a bit on there are some dependencies, right? If we see that the quality is not as expected, if we see that there are issues, especially in security testing but they finished security testing and they told me that there are no bigger issues. That should be fine. But if we see in the quality or in the functional testing that there are some unexpected issues, that something is not working as intended or whatever, then this might be delayed. But I don't expect that currently and I don't hope so. So that's just a word of warning of course that there might be delays in case such things happen. Yes, but I still think September is way too long. You have people working… If we are done earlier Joshua, then we are done earlier, right? So that's fair enough. But we need to do our testing. If my testers say I need to do it until the middle of September for testing it, then I trust them. I just hope your testers do their work. Do their work like five days per week. I hope you know what I'm saying. Right now it's early July and always betting time is September, which gives me a feeling that… Let me say it that way. My testers, especially Lukas, tested several services already. The timeline he provides me is of course biased by the fact that the APIs of the last service he got, that he needed to test were so bad, that there were so many bugs, that he needed to prolong the tests all the time. So if the API for the Cloud Firewall is very good, then he will be done earlier. That's fine. There's no issue at all. But based on the experiences we had, we'd rather plan a bit more time, instead of delaying the release of the feature again and again and again, because we have too many bugs that need to be fixed before we can launch. So it doesn't help us right now to say, yes, we are done. That thing is bad, yes, I hear enough, and I do hope we can give some detail. What is bad? Which server is bad? How is bad? We talked about planning. I haven't said that the API is bad, but we present more. It was. Have a look on the bugs we have opened for the HSS APIs. I can't even count them. There are so many. The major things we have fixed, it's all fine. It's all good. I don't want to complain. It delays our... After this meeting, I will ask my people to open the bug TV and see what exactly is going on there. Sure. That's fine, right? I don't want to tackle now half things. I don't want to hide about some things that happened in the past. Well, for HSS, there are still a lot of minor bugs opened, but they will be fixed in time sooner or later. That's okay. But for HSS, we also planned to launch way earlier. In the end, we needed to postpone it again and again because you know the story. In the end, both sides were angry. You want to free up your resources. I can completely understand that. On the other side, it was still the other side. Then also me afterwards, I wanted to get that done. I wanted to launch it. It doesn't help us if I say now, okay, yes, let's plan to launch CFW in August. We are in the same situation and we can't launch because nothing is ready. I rather say we test until mid-September because from what we experienced in the past, how many bugs we usually get in the testing there, I can only use this as a parameter for my planning. Then I say, okay, it takes longer than I want, than I'd like to, but I need to plan it accordingly. If we are then done two weeks earlier, fair enough. That's good. But delaying it again and again is something I'd like to avoid. Of course, we tell something to our customers and if we tell our customers, it will launch in September and then we need to tell them, sorry, no, we will launch in October, no, we will launch in November or something like that. That's bad. That's not good for our reputation. Yes, but that's not the point I want to talk about. Yes, I completely understand what you are saying, but I just want you to make sure your team, your QA is actually working. They are working. They are not creating bug tickets all of a sudden. So they are testing these things. Because from my experience in the last year, yes, from my side also have a bad experience. People gone for weeks, months, yes, months, disappear for the whole month. Nothing gets done. They just vanish, disappear. Not since I'm here, so I can't talk about that. I guess one of the people we kicked out. Yes, something bad and bad consequences will come, which is none of us will be willing to see that coming. So just make sure people are actually working and things going forward smoothly. Definitely. And also maybe one thing for you I'd like to improve a bit, because what I am a bit afraid of or what I had a feeling a bit in the past was regarding testing. They were a bit lacking this, okay, when is the testing phase ended? Testing phase ended. Yes, because if I tell a quality tester, please test the product, he can test it forever. Yes, indeed. He will always find bugs, new bugs here and new bugs there. It will never finish, the quality testing of anything. That's important for me that I together with the testers define clear goals. We say okay, until this point we do test and then it's done, then it's tested, and then we close the test case. Because that's currently not existing that precisely. I think that's important also for better planning for everyone. If we know okay, we test that much and then it's okay. That is also clearly communicated then also to you about our... Yes, we do have some common understanding with the OTC's management. It says what is a blocker, what is no blocker is very clearly written. What is no blocker is very clearly written down in some page in the reference. Yes, exactly, I know. If it's a blocker or something serious, we will take care of that immediately. But if it's quality, some minor stuff, I say we just create a back ticket and wait for R&D to fix it in the future version. That's clear, that's not what I'm referring to. For me it's like when do our testers stop testing? Because actually I should never launch a ticket because if the testers are still testing, they could still find blocker bugs. But it's not that likely anymore after a specific amount of time, after they are basically already tested with everything. But what does it mean I tested everything? You can never say I test everything. For APIs you can say okay, I have a routine, I test this, it's all fine. But especially quality you can never stop testing actually. Nevertheless, we need to define, I need to define with the testers something like now it's considered test is done, the initial test is done, it's fine, bugs are handed over to Huawei, you are fixing the most important ones, where the blocker is the highest priority things, and then we are only doing retesting. We check, okay, have the bugs been fixed or if a new functionality is added to some new update or whatsoever with a version upgrade, then we are doing the functional testing again in a limited amount, let's say so, with only things that can be affected with this update. That's what I was talking about. That's what I was referring to. But it's fine, we don't need to discuss it too much. I just wanted to inform you that we are also planning to do something in that regard because it's better for the predictability of the test in the future. Okay, we talked way more about EPSGA than I expected actually. I would suggest that we move over to HSS or do you want to talk about HSS first? No, one question would be just so, can we at least in uncommitted states say then we can include some EPS tasks in the next PIP? Yes, yes, yes. Okay. In the next PIP, definitely. So probably even committed. Okay. Because we will not have too much stuff to be done for Cloud Firewall anymore in next PIP. Do we need anything from Joshua or Kibo for this task for EPS? Anything? Yes, but we are already preparing that currently in parallel a bit regarding what exactly we need to do to enable the APIs for UNL. But that should be a no-brainer actually. It should not be too much. Okay, so I could also put EPS on our roadmap somewhere at the end of this year. Yes. Okay. Good. Then I'm totally fine to move on with HSS because it's a bit, let's say, pressuring because as you saw Joshua, we announced the public webinar at the end of this month. So we better be prepared to show it live in the production environment. Yes, I will also, I'm also preparing the ransomware protection video. I'm recording a video and a short demo and hopefully you can also reproduce it. I was still working on that. And hopefully I will have some news today or tomorrow. That's nice. How could we get the ransomware that you have the ice fire there, the ice fire? Do I ever show you the ice fire? If you want it, I can send it to you. You can buy it in the black dark web. No, I'm kidding. I haven't been there yet. I will send you sometime in the future. Okay. Would be very interested in it to try it also out in some VM. Hopefully we can do the demo so that you can reproduce it. Perfect. Cool. Thank you. That's cool. Basically, I also showed HSS the current status to some sales colleagues last Friday as I told you. So basically I mostly received positive feedback that these kind of solutions are requested by customers because they want to see their, say, security posture and want to do things, vulnerability management and so on. But I received three main points where I opened also a bug ticket. I don't know if it's a bug or if it's working as designed. First of all, I guess you talked already about that one, is the compatibility with current operating systems. So the customers, we also advise them to only use or to update to the most current supported operating system. A lot of them use, for example, Windows Server 2022. And officially we are not supporting some newer versions of HSS. So HSS is supporting the newer version operating system. Yes, indeed. I haven't taken this with me, but I hope I can take this with me now. That would be really, really cool because I know there will be questions from the customers on this webinar. Like, OK, I have Windows Server 2022. When will it be supported? Because we support older versions, but the customers, they are not even allowed themselves to use, for example, Windows Server 2008. I guess that's out of support since, I don't know, a few years. And that would be really necessary to have up to date operating system support. That would be cool. OK, I will ask the HSS R&D later. Yes, that's great. Secondly, it's about the vulnerability database. I guess you will then update it once a month or what is the lifecycle because we haven't documented it somewhere in the docs page. Customers will see or ask. Currently, the database is two months old for vulnerabilities. When will it be updated and how often? I think you just answer yourself once per month, right? Is it, let's say, agreed, aligned? Can we document this in the help center somewhere? So is it fixed? Processed? This is more like maintenance stuff. Our SIE will help you update the HSS every month. Do you imply that they are not doing their job? No, no, no, no, no. What I imply is I want to have it documented because otherwise... You want to write it down somewhere, OK. Yeah, because the people are asking me when will it be updated and then the next day another guy is asking me when will it be updated. Then I can provide a link here in the doc center. It states once a month is the update cycle. You can also communicate this to customers. Please don't ask me again. This kind of way that we have this lifecycle of vulnerability database update somewhere in the help center. I mean, if you say once a month, is it like end of the month, start of the month or something? When do we usually do that? Because then I would ask... The official statement is as long as they have the update on the center, on the HSS, then you can upgrade it. You can, based on the HSS support center, you can do the upgrade. And the HSS support center is updated every month. OK, so I guess that's something that we need to discuss, Sebastian, when you would like to plan it. And then we say, OK, like every, I don't know, every last Friday of the month or every last week of the month, we update the database and put that one somewhere in the docs page. And then we kind of kill this question by different people. I would clarify that. That's good. OK. I'll write it down. I will ask the MD later. Probably tomorrow, day off earlier in Wednesday. Cool. And then I had the last thing. It's about if you install the agent or if you download the agent, at least on Windows, I don't know if it's only on Windows, and you double click on the X, you get a notification about unsigned software and that it is blocked. So people then asking why is it seen as unsecure? So is it possible to somehow sign this agent that you can just install it without any blocking by the operating system? Let me see if I get it right. So you install the agent, you double click the agent and you what? Let me see the story I shared with you as well. So I also shared some screenshots with you. Can you give me a screenshot later? I can do it now. You prepare a screenshot and I will see what's up with Andy. So just three things for HSSRI. One is supporting the latest operating system. Second thing is to upgrade the database. The third thing is whatever you just said. Then I have just one question. Because our documentation says HSS is working on cloud and off-cloud like on-premise and on different clouds. Theoretically it's doable. Okay, so practically we need to make the communication then available to the Internet, right? Yes, you need to. Based on R&D you need to have ECS ask the trans, what's that called? Transfers, transmin, transplats the message. You will have ECS on the OTC and taking care of the message that agent from other clouds send it to here. I didn't understand you. We need a proxy virtual machine? I think so. I think that's what it means. A POSTEC virtual machine. Do we have a documentation for customers how they can do it? Because customers are already asking, okay, can I protect my on-premise virtual machines? And based on our documentation the answer is yes, sure you can also protect your VMs on-premise with our solution. Of course, they pay the agent and if they also use the on-premise VMs it's more revenue for us. But we don't have any documentation how to do it because currently you download the agent and then it has some configuration. And this is just internally so it only works when you are inside OTC but not like on-premise or AWS or Azure or somewhere. Okay, just need a document. If you have any guideline how to make it work for on-premise VMs, like I install just the virtual machine on my laptop, I install HSS agent, how do I configure it to work with my tenant? Like what do you call it? Off-cloud, on-cloud, third party cloud, something like that. Okay, and that are the main points from my point which I received as feedback so far. I opened some other boxes in this ticket but these are not really blocker ones. And I will send you then the link with this signature thing after the meeting. One question for HSS I have is about file integrity management. Let me just open my tenant and then I share the screen. Okay, so I have a file integrity monitoring. So I have a file integrity monitoring. File integrity monitoring, what is that? Let me just open my tenant and then I share the screen. So when I go to HSS I have a lot of features and one of them is file integrity monitoring. What does it do? How can I enable it? In the documentation there is nothing to find about how to enable it. I tested it, it works just fine and it is hard to explain. Maybe I will show you a demo later. That would be nice because I have nothing to show and I have no... For web developer protection I can add a server but for file integrity monitoring I don't know. You need to get into the virtual machine and change some critical system file. If you change it it will trigger this function. I think automatically I am not quite sure. Okay, because again the documentation... If you go where is it? File integrity monitoring. You can view here but there is basically not that much and checking change details. But what is monitored? What is a critical file? What is the details? Which folder or which file is critical for HSS that is not documented? I don't know when it should even trigger if you know what I mean. I don't know what you mean. You said if you change some file... Which? System-wise file. You know you log into the Linux virtual machine, if you type ls it will list all the files under the folder right? This ls is system command. Somewhere in the system you have this system file. It is reasonable. If you go there, delete this ls and ls command and you will find that... Okay, I am a virtual fire. For example if I go to Windows and System33, these are system files here. So if I delete any of that on the virtual machine it will be identified. The question would be which folders are monitored? So what is a system file? It would be interesting to know which files are protected by it. Because for me if I see fire integrity monitoring I would also be interested in having something like an audit configuration to be protected. Because if someone is tampering around with my logging configurations, well it is interesting for me. I want to know. Is it now considered a system critical file? Maybe it is. But maybe it is not. What is monitored? What is a critical file? Maybe I can add a folder later? I don't know. I cannot use the system settings in HSS. It is just empty. But if you can give us some demo that would be really helpful to understand it and also show it to customers. Okay. Or maybe just a few screenshots. Also fine. Just to see how it works. Just one example. Okay. Cool. And I guess that is it from HSS side, from my part. Do you have anything on your mind Sebastian? I suppose the HSS is not... I want to try out to camper with my audit. Sorry, my contact. So to... Oh, I am mistyped. To... To check it. Yeah, actually. Anyway. But for HSS... ... on my page right now. Hi, Tibor. Hi, Tibor. We only have 15 minutes left, 40 minutes left. But we still have the topic of DWAF in UNL. Tino, you wanted to talk about? Was there a customer request? Yes, so I worked with customer impediment. And we just received a customer impediment for customers in the Netherlands. They also would... I guess it is not the second customer. They want also to have the dedicated DWAF on the Netherlands regions. Because they need to fulfill their requirements to use DWAF, but not put the web server in the internet. Which is necessary for the shared DWAF. And I guess either way, somehow later on we want to have feature parity. That all services we deploy on German region are also available on the Netherlands region. Otherwise, yeah, we do not attract customers to this region when a lot of services are missing. Question would be if and how we can also plan to deploy the dedicated DWAF on the Netherlands region. If that is something where we need a lot of effort, a lot of time. Because I mean we already have it live on the German region. What is necessary to start dedicated DWAF on the Netherlands region? So if it is something we can put on the roadmap in midterm. Yeah, yes. Can you say something about this Joshua? Is it possible that we can also focus on dedicated DWAF in the Netherlands region? The answer should be yes. But first it depends on the customer wise. Because I never hear this customer on our side. I don't know why and when and how much profit they are going to bring us. Basically, I mean the motivation to do this is sufficient. And the second thing is it's more like it's not a new service, right? It's already deployed on the UD. We just need to do some upgrades on the testbed. Is that upgrades on the testbed? No, no, no. The Netherlands doesn't have that, right? That's the new service delivery. That's no good. So I can answer you the first question. I mean officially you are not allowed to know customer names. I don't need their names, but I need their industry and... It's education and it's more like... you know Telus? Telus, yes, I know. It's a partner customer, let's say, from educational and meteorological sector. Let's say. You know this earth observation stuff. This kind of customer and they need to use dedicated DWAF. Because the shared DWAF would not fulfill their security requirements. They would be quiet by kind of end of this year. And if we cannot provide dedicated DWAF, then of course they use a third party solution. Yeah, for UNL we don't have a test environment as you know. Yes, for your information, and yes I kind of got the background. But I still think our side is not the main problem. But please aware we still have a lot of servers like CBH, like Seqmaster, like CCM. A lot of servers are in the queue. Which I don't see is prepared to deliver in this year anyhow. And you say if we don't get it at the end of this year, they will go to have third party solutions. So I think you should ask Sebastian what is his plan, whether he have enough people for doing that. Just for my understanding, basically as we have it live on Germany, it's not that much effort, right? Because I mean it's a known service or? We still have some effort because in Germany basically it means the testbed already have these servers. We can, at least now we can, we skip the testbed as standard procedure. We skip the testbed because testbed already have and deploy there into the Netherlands. And it will cause, still it's like a new source delivery. And you said I should further talk to Sebastian, so basically from yours? You, Sebastian, like give us an idea when you think you can do it. Sebastian, give me an idea of what he can, is it possible this year? Let's play the game further. I have no clue how much effort it is to implement it rather than even so. I need to analyze this for people. Yeah, if you calculated the previous one on UB, it was a lot of time especially with the testing. I already tested it, it's the same package which is already on production and deployed on production because we don't have tests. But I guess it still requires the test, right? Yes, but you can only test on production environment, right? Yes. Okay, so you... What we would need to do Tino is actually we would need to deploy it there. Unfortunately, your assumption is that to say, yeah, but we already did it, right? It should be the same and there should not be any surprises. I'm afraid that does not work that way. We are doing this, we are deploying on production anyway, we are hiding in the console and we did some simple small tests. We are supposed to be quicker, no death row, I mean, no death row, like a completely new server. It will be quicker but we are still doing some tests. But for example, we could put it on production and whitelist only this week and say, okay, it's live and beta status, we are still testing it. But we have it live in, I don't know, let's say October or November, December, whatever. So we have it there, it's still in testing phase but you can start to use it and do your proof of concept and whatever and in the meantime we are testing it. Next PI will have capacities for implementing this, Tino. That's not an issue, right? Yes. That's definitely fine. It depends on the speed of implementation, right? Because although we already implemented it in the UDE... The UDE is a bit different than EODE unfortunately. So it's not like, okay, we do the same thing just again, right? And everything will be working out fine. So there might be like, oh no, that does not work, we need to do something else. The network in NL is completely different to the EODE one, right? So especially with regards to communications, there might be some mess in the UNL and we might need to do troubleshooting and finding out, okay, together with the network connectivity squad. That can cause us delays of two months. Totally fine. Just want to... You know the deadlines by customers are not so strict usually, so nobody's dying. And if we say, okay, we plan it somewhere next quarter and you may get it, they may wait usually and say, okay, at least you have it on your roadmap and we can wait two months. That's totally fine. So it's a totally different story that we say, no, we don't do. Please go to the competitor. That's another story. So you have the capacity to have it in your... to deploy it in UNL from my perspective. So from implementation capacity point of view, right? If Huawei does have the capacity to support us there in the implementation, that is completely fine for me. Yeah. We tomorrow have the capacity to doing this. Can you? Tomorrow? No. You see? So give me a day. Yeah, that's right. Next TI. So mid of September we can start. Mid of September. Okay. I will say we keep this topic and discussion next next room and meeting. Okay. Totally fine. We don't have that much time left. I have two items. I would like just to ask it's about the DBSS support from MySQL. That's the plan for next TI, but will be done quicker, right? So that is somehow in progress already. MySQL is planned this TI. This PI. This PI. Okay. Let me check. Let me check. Instead of me talking something wrong, we are talking about pre-production only. Talk production that customer can use it. Okay. I am having pre-production will be doing this PI next PI production. Sorry. Okay. So this is still on track. And the other one is the DWAF support for WAF instance. That is planned for also this PI already. The WAF ERB mode, yes. Also having pre-production is this PI. And what next PI? Next hopefully because we are depending there on network services. No, network services support. Network services support for the ERB upgrade. Okay. They don't get that done. They planned to get that done with the PI, but uncommitted. Okay. Good. And then just one last thing. Joshua, you offered kind of again an introduction session for cloud-based channel CBH. Can we plan it for somewhere? I don't know. This week, next week? You call. Sorry? You call. You call the time. Okay. Tomorrow 11? Tomorrow? Tomorrow? I have time tomorrow. I don't know how about you. I have time. Friday? Friday is quite packed for me at least. I'd like to join. For me also. Then maybe next week after our meeting at 11? Yeah, that's fine. I will schedule something, okay? Okay. How much time do you need? One hour? One hour should be more than enough. Yeah, if you had done earlier then that's fine. So next week, Monday, next week, Monday 11 a.m. CBH introduction session. Yes, who else wants to join? So Kino, Joshua, me? I will forward the invite to the necessary people. Kino, someone from your side who needs to join? And if they are not available I will propose another time. Okay, perfect. I guess from our side just you and me to just get an overview of the service and the fit. Yeah, that's totally fine. Okay, I guess. Yeah, time is over. That's our invitation. Maybe we could talk about so much things. But then I would say we talk again next Monday for next topics. Just one second, do you have an extra minute? Yes, yes. Thank you. Alright. Thank you Kino, thank you Joshua. Thanks Kino, thanks Joshua. Thank you. I also wanted a minute of you Sebastian, can I also stay? If you are interested in it. So Kino, if it's not that secret that you don't want to share with Kino, then it's fine with me. Okay, see you. Alright Joshua, then take care, bye. Bye bye.
________________________________________split transcription____________________________
Meeting Minutes

**1. Meeting Overview**
- **Date & Time:** Not specified in the transcript.
- **Location:** Virtual (implied from context).
- **Attendees:** Multiple team members including representatives from testing, management, R&D, and sales.
- **Chairperson:** Not explicitly mentioned.

**2. Agenda Items**
- EPSGA Project Status
- HSS (Hosted Security Services) Progress & Customer Feedback

**3. Discussion Details**

**EPSGA Project:**
- Discussed testing phases and the need for clear guidelines on when testing is considered complete.
- Team members expressed concerns about testers potentially finding new bugs indefinitely, emphasizing the importance of setting a deadline or specific criteria for ending initial testing phases.
- Agreed to define clearer goals with quality testers to ensure predictability in future planning.

**HSS Progress:**
- Positive feedback from sales colleagues regarding customer interest in security posture and vulnerability management solutions provided by HSS.
- Key issues raised:
  - Compatibility with current operating systems like Windows Server 2022, currently unsupported officially but requested by customers.
  - Updates to the vulnerability database were questioned due to its age (two months) without a clear update schedule.

**4. Decisions and Action Items**
- **EPSGA Project:**
  - [Action Item] Document and standardize testing phase completion criteria for better project management.
    - Responsible Person: Testing Team Lead
    - Deadline: Not specified

- **HSS Progress:**
  - [Decision] Address customer concerns regarding OS compatibility by pursuing support for newer operating systems like Windows Server 2022.
    - Responsible Person: R&D Manager
    - Deadline: To be determined after assessment of feasibility and prioritization.
  - [Action Item] Clarify the update frequency of the vulnerability database (monthly) in documentation and help center resources.
    - Responsible Person: Documentation Specialist
    - Deadline: Next release cycle

**5. Other Matters**
- Mentioned interest in obtaining malware samples for testing purposes, jokingly referred to as available on "the black dark web," but clarified through a more professional channel later.
- Positive reception of HSS during sales demonstrations highlighted the need for continuous improvement and alignment with customer expectations regarding OS compatibility and database updates.Meeting Overview:
- Date & Time: [Not specified]
- Location: Virtual Meeting
- Attendees: Tino, Sebastian, Joshua, Tibor
- Chairperson: Not identified

Agenda Items:
1. Logging Configuration Monitoring in HSS
2. Dedicated DWAF Deployment for Netherlands Region

Discussion Details:

1. **Logging Configuration Monitoring in HSS**
   - Concerns raised about potential tampering with logging configurations.
   - Questioned if such files should be considered system critical and monitored by the system settings.
   - Requested demonstrations or screenshots to better understand how it works and present this information to customers.

2. **Dedicated DWAF Deployment for Netherlands Region**
   - Customer request from education and meteorological sectors in the Netherlands for dedicated Distributed Web Application Firewall (DWAF).
   - Requirement driven by security concerns as shared DWAF does not meet their standards.
   - Discussion on aligning service offerings between German and Dutch regions to attract more customers.
   - Potential effort and time required to implement dedicated DWAF in UNL was a topic of discussion.

Decisions and Action Items:
- Sebastian will analyze the effort needed for implementing dedicated DWAF in the Netherlands region and provide an estimate.
- The team aims to have dedicated DWAF live on production with beta status by October/November, allowing customers to start using it while testing continues.
- Next Planning Increment (PI) will allocate capacities for this implementation.

Other Matters:
- Network differences between Dutch and German regions could potentially cause delays due to troubleshooting requirements.
- Customer deadlines were noted to be flexible; they are willing to wait if the service is on the roadmap.Meeting Minutes

**1. Meeting Overview**

- **Date & Time:** The meeting took place on an unspecified date; however, the next scheduled session is set for Monday at 11 a.m.
- **Location:** Unspecified location (likely virtual).
- **Attendees:** Sebastian, Tino, Kino, Joshua, and possibly others from their respective teams.
- **Chairperson:** The chairperson was not explicitly mentioned.

**2. Agenda Items**

- Source delivery implementation update
- DBSS support for MySQL pre-production plans
- DWAF support for WAF instance progress
- Introduction session for Cloud-based Channel (CBH)

**3. Discussion Details**

### 3.1 Source Delivery Implementation

- Sebastian to analyze the effort required for deployment and testing, aiming for a beta release by October or November.
- Tino confirmed capacity availability for implementation in mid-September but highlighted potential issues with network differences between UDE and EODE environments that could cause delays up to two months.
- A phased approach was discussed, involving initial deployment with restricted access for testing purposes before full-scale roll-out.

### 3.2 DBSS Support for MySQL

- Pre-production is planned for this PI (Performance Improvement), while production readiness is targeted for the next PI.
- Progress appears on track, but specifics were not detailed in the conversation.

### 3.3 DWAF Support for WAF Instance

- WAF ERB mode pre-production slated for this PI, with a tentative production phase in the next PI contingent upon network services support.
- Network service upgrades are uncommitted and could impact timelines.

### 3.4 CBH Introduction Session

- Joshua offered to conduct an introduction session on Cloud-based Channel (CBH) solutions, scheduled for Monday at 11 a.m. post-meeting.
- The session aims to provide an overview of the service and its fit within organizational needs.

**4. Decisions and Action Items**

- **Action Item:** Sebastian will analyze the source delivery implementation effort by mid-September; Tino to confirm deployment readiness in UNL, subject to network support from Huawei.
- **Deadline:** Mid-September for start of implementation activities.
- **Decision:** A phased beta release approach is approved with restricted access initially to facilitate testing and troubleshooting.

**5. Other Matters**

- Additional attendees for the CBH introduction session are pending Kino's team availability; another time slot will be proposed if necessary.
- The meeting closed with an invitation to discuss further topics in next Monday's scheduled meeting at 11 a.m.### Consolidated Meeting Minutes

**Meeting Overview**
- **Date & Time:** Unspecified; next scheduled session: Monday at 11 a.m.
- **Location:** Virtual Meeting (implied)
- **Attendees:** Sebastian, Tino, Joshua, Kino, and multiple team members from testing, management, R&D, sales
- **Chairperson:** Not identified

**Agenda Items**
- EPSGA Project Status
- HSS Progress & Customer Feedback
- Logging Configuration Monitoring in HSS
- Dedicated DWAF Deployment for Netherlands Region
- Source Delivery Implementation Update
- DBSS Support for MySQL Pre-production Plans
- DWAF Support for WAF Instance Progress
- Introduction Session for Cloud-based Channel (CBH)

**Discussion Details**

**EPSGA Project:**
- Discussed need for clear testing completion criteria, emphasizing predictability in planning.
- Agreed to standardize goals with quality testers.

**HSS Progress:**
- Positive sales feedback on customer interest in security posture and vulnerability management solutions.
- Key concerns:
  - Compatibility issues with Windows Server 2022.
  - Update frequency of the vulnerability database.

**Logging Configuration Monitoring in HSS:**
- Concerns over tampering, requesting demonstrations or screenshots to understand monitoring functionality better for customer presentations.

**Dedicated DWAF Deployment for Netherlands Region:**
- Customer requests from education and meteorological sectors for dedicated Distributed Web Application Firewall (DWAF).
- Aim for beta release by October/November post-testing.
- Next Planning Increment allocates capacity for implementation.

### Source Delivery Implementation
- Sebastian to analyze deployment effort; Tino confirms mid-September readiness, considering network differences between environments that might extend timelines up to two months.

### DBSS Support for MySQL Pre-production Plans
- Targeted for this PI with production readiness by next PI.

### DWAF Support for WAF Instance Progress
- ERB mode pre-production slated for this PI; tentative production phase contingent on network services support.

### CBH Introduction Session
- Joshua to conduct an introduction session on Cloud-based Channel (CBH) solutions, scheduled for Monday at 11 a.m.
- Additional attendees subject to Kino's team availability.

**Decisions and Action Items**
- **EPSGA Project:** Document standardized testing completion criteria.  
  - Responsible Person: Testing Team Lead
  - Deadline: Not specified

- **HSS Progress:** Address OS compatibility issues; clarify database update frequency in documentation.
  - R&D Manager to pursue support for newer operating systems like Windows Server 2022.
    - Responsible Person: R&D Manager
    - Deadline: TBD after feasibility assessment
  - Documentation Specialist to detail monthly database updates.
    - Responsible Person: Documentation Specialist
    - Deadline: Next release cycle

- **Dedicated DWAF Deployment for Netherlands Region:** Sebastian will analyze implementation effort; aim for phased beta release post-testing.
  - Responsible Person: Sebastian, Tino (for network support)
  - Deadline: Mid-September start of implementation activities

- **CBH Introduction Session:** Joshua to conduct session Monday at 11 a.m.; additional attendees subject to availability.
  - Responsible Person: Joshua
  - Deadline: Monday at 11 a.m.

**Other Matters**
- Further discussion topics in next scheduled meeting on Monday at 11 a.m.WARNING:  Invalid HTTP request received.
### Consolidated Meeting Minutes

**Meeting Overview**
- **Date & Time:** Unspecified; next scheduled session: Monday at 11 a.m.
- **Location:** Virtual Meeting (implied)
- **Attendees:** Sebastian, Tino, Joshua, Kino, and multiple team members from testing, management, R&D, sales
- **Chairperson:** Not identified

**Agenda Items**
- EPSGA Project Status
- HSS Progress & Customer Feedback
- Logging Configuration Monitoring in HSS
- Dedicated DWAF Deployment for Netherlands Region
- Source Delivery Implementation Update
- DBSS Support for MySQL Pre-production Plans
- DWAF Support for WAF Instance Progress
- Introduction Session for Cloud-based Channel (CBH)

**Discussion Details**

**EPSGA Project:**
- Discussed need for clear testing completion criteria, emphasizing predictability in planning.
- Agreed to standardize goals with quality testers.

**HSS Progress:**
- Positive sales feedback on customer interest in security posture and vulnerability management solutions.
- Key concerns:
  - Compatibility issues with Windows Server 2022.
  - Update frequency of the vulnerability database.

**Logging Configuration Monitoring in HSS:**
- Concerns over tampering, requesting demonstrations or screenshots to understand monitoring functionality better for customer presentations.

**Dedicated DWAF Deployment for Netherlands Region:**
- Customer requests from education and meteorological sectors for dedicated Distributed Web Application Firewall (DWAF).
- Aim for beta release by October/November post-testing.
- Next Planning Increment allocates capacity for implementation.

### Source Delivery Implementation
- Sebastian to analyze deployment effort; Tino confirms mid-September readiness, considering network differences between environments that might extend timelines up to two months.

### DBSS Support for MySQL Pre-production Plans
- Targeted for this PI with production readiness by next PI.

### DWAF Support for WAF Instance Progress
- ERB mode pre-production slated for this PI; tentative production phase contingent on network services support.

### CBH Introduction Session
- Joshua to conduct an introduction session on Cloud-based Channel (CBH) solutions, scheduled for Monday at 11 a.m.
- Additional attendees subject to Kino's team availability.

**Decisions and Action Items**
- **EPSGA Project:** Document standardized testing completion criteria.  
  - Responsible Person: Testing Team Lead
  - Deadline: Not specified

- **HSS Progress:** Address OS compatibility issues; clarify database update frequency in documentation.
  - R&D Manager to pursue support for newer operating systems like Windows Server 2022.
    - Responsible Person: R&D Manager
    - Deadline: TBD after feasibility assessment
  - Documentation Specialist to detail monthly database updates.
    - Responsible Person: Documentation Specialist
    - Deadline: Next release cycle

- **Dedicated DWAF Deployment for Netherlands Region:** Sebastian will analyze implementation effort; aim for phased beta release post-testing.
  - Responsible Person: Sebastian, Tino (for network support)
  - Deadline: Mid-September start of implementation activities

- **CBH Introduction Session:** Joshua to conduct session Monday at 11 a.m.; additional attendees subject to availability.
  - Responsible Person: Joshua
  - Deadline: Monday at 11 a.m.

**Other Matters**
- Further discussion topics in next scheduled meeting on Monday at 11 a.m.
./tmp9p3lew4x/安全周例会710.mp4
临时文件夹地址：./tmp9p3lew4x
上传文件的地址：/tmp/gradio/e3fc9b6e67999c26fb3243254856976f36c6c029/20240510_121130.m4a
base name 20240510_121130.m4a
 We're back, thank you for your time. We continue with the presentation. It was regarding, as we all remember, CSS using RIG and also pongo semantic model for that solution. Please share your slides. So everyone knows what you are talking about. Yes, exactly. We stay here. We stay here. Competitiveness between CSS solution and OpenAI, right? Yes, we do have some competitiveness with the existing large language model, but this is nonsense. You don't look at this because it's only for Chinese embedding. We don't have the concur accuracy for English embedding yet. But my point is CSS itself does not need to associate with this embedding model or any large language model itself. It's a very good databases and vector databases. I will show you the competitiveness of CSS itself to any other open source CSS. Yes, yes, yes. Later. I don't have that much left to talk about with this slide. This is a successful story using CSS with this RIG solution to build customer service assistance. I believe we are all very familiar with this kind of story. Use RIG to search the most correlated response, like how to deal with an angry customer. It will generate the most proper answer based on the current situation. Just like a codus dev, you generate a code, you generate an answer. Basically, it's the same thing. I will give you the slides to read after the meeting. Demo, I don't have the demo yet. I was not able to access the demo. Feel free to click this link, but I don't think it will go anywhere. It's called code search. Yes, it's code search indeed. So that means what code search? It's called this solution to integrate Pangu with CSS. It's called code search. Yes, indeed. Don't ask me why it's called code search. Somebody decides it's called code search and it's called code search. The next question is since Pangu. Pangu is something that we don't have here in OTC. Pangu exists already since two years on Huawei. Probably because I remember last year, Thomas was not in this world of I assume it, but one year before he got in the main stage and presented something about Pangu. For this electricity stuff with... Electricity with power. Yes, there. So the question is since Pangu is more than mature, what are the current use cases that you already have with this solution? I mean real use cases and real customers. Real use cases and real customers. So this is more like a brainstormer. It's not like brainstormer, but... Yes, we have a lot of different Pangu models as you may already know. We have CV, different Pangu models for different AI tasks. For example, CV we have the electricity tower, we have the TFDS. Those actually have customers in using those. CSS and Tango. I mean we're talking about now Tango code search. You mean for code search you just show the case? Yes, I just show the cases. But it's not a real customer? This is a real customer. It's a real customer. And the real customer is doing what? Using these RAG to build customer service assistance. Like... Support? Yes, customer support. Or help center. Help center, yes indeed. So what customers begin with? The bank or what is it? Yes, the bank. We have a lot of customers with the bank. So they receive CSS with the RAG and Tango together and they are just... What's injected on this RAG? What's injected into this RAG's knowledge basis is the customer's historical chat record. Like... Basically this database is chosen by humans. How to deal with angry customers, how to answer this question, how to answer frequent QA questions. And all those data are put together and fed into this RAG. So when a customer finds your customer's numbers, they always want those kinds of things, right? I go to the charger, I don't know how to use this and that. Most of the answers are in the frequently asked QA. And they just don't bother to read it. So this RAG will help the customer service people to get the correct response to those customers. So the worry of this is to improve the efficiency and customer's... Satisfaction. Satisfaction, yes. But this... For my point of view, this can be also done without CSS and using just a simple element with RAG on top or on this... So what is the difference? Using the... Just give me a second, please. Sorry, I didn't... I have no idea what is exactly the real use case that we're doing on the OTC. On the OTC, we have this part, our search. With this our search, what they are doing is they train, they have a model. They put on this model the documentation of the OTC. And with this, this is the ROG part so that you can then... The use case is to develop a chatbot. With this chatbot, the same as here, you have your help center. You start asking questions and it will give you the right answer also with the reference. Let me show you exactly what I mean. Only that you know this and then you can tell me what is the difference. For me, it's important to understand what is the difference because otherwise, what if your solution is better and we really don't know? So let me show you this here, for example. Can you see my screen? Yes. No, I think you are not sharing. No, you are sharing. Okay, you see this in... So this is... Behind this, as I told you, it's LLM with RRG and it's using only the documentation URLs that we have on the OTC. So there is no service description and so on. So if we call, for example, here... How LTS support high availability. High availability. So what this is doing, you see in the left side, it's just the links that it found some kind of information, but it's still not doing something. On the right side, it's the... Summer recovery. So this is trying to create some kind of response. Nevertheless, when it is then ready and done with all that information that it's creating, of course, all that information is based on the documentation of the OTC because we have this as basis. At the end, when it is completely finished, you may see, for example, here is number one. Number one is a reference that has been used for this part here. Number two refers to this one. Three and two is just a mix. These sentences are from between three and two. When I just want to go and see exactly if this answer is correct, I just here select the number one and it forward me to the documentation URL that it has been... I find this kind of information on that sentence and the same also for the other ones. As you see, I didn't use CSS. I'm not using also vector database. It's just LN and also RRG. That RRG is just connected to this URL box of the OTC systems. No more, no less. I think principally, technically, it's more or less doing the same, right? It's just like involving the partner in the search. I don't know what is their pricing model or cost at all. I guess technically, there's not much difference in what you finally get. The question is how complex is this Huawei approach to build? Yes. What is the cost and what is the actual business model? In this case, this is obviously being focused on end users. If you want to make this happen again for your end customers, if you are like, for example, a system integrator or something like this, you have to be either the partner of Embar Search then again or you have to make a commercial model with them to sell this to your own end customers. This can be relatively complex and then also become a matter of cost related to that. Since I don't know how Embar Search is charging and what they kind of invoke in business model means, and I have also no answer for the actual business model that is behind this for the moment, I think anyway these are the things that we would have to compare. I mean, yes, exactly. I mean, it's not the technology itself. The answer is also the business. I mean, quality output is also a problem. How should I compare this now? I have no idea. Can you say this will be better or worse in quality? I think it's difficult to say. Yes, I can show you what is the difference. Also one of the big differences of this solution. You can see here, I just asked in English because you see that the documentation is also in English related. Correct. But I can also ask the same question in German and I will get the answer in German also with the reference in English. Okay. I think similar question, similar way. I will try to translate in German. You are German. I just want to know if I did some mistakes. How does it work in high availability? I think the question is good. The answers that I see so far on the left side are not like that applicable, but I think on the right side, the way it's giving the answers looks good so far. It looks primary, standby, failover. So you see, in this solution, I just got this and you may see here the reference also. I have a reference, but when we select the reference, it will be forwarded to the documentation still in English. So that means this model can support German and English and you see also a way to, even if I'm German and I'm not really confident with English and so on, so I can just select it and I have exactly the reference to all of these answers here. So it depends on the answer and the question, but you may see all of this. So if you have this also with your solution integrated in a similar way, it will be of course very good. We are not a customer for it. I'm pretty sure we have still German customers that are looking also for this kind of solution. For example. Yes, for your question, what's the difference between us and Amber Search? You mentioned they use the open source model to retrain the model. They have their own embedding function. They have built their own knowledge basis. Yes, you can always use that with the open source. So you can build an end-to-end solution product with all using all the open source solutions. Yes, there's no problem. I can tell you that. Basically, you can basically build everything with open source nowadays. But why do people still go to the commercial? Why do people buy the open source? When they have the open search, you know, CSS open search. Even though open search is open source and they still go to Amazon to buy it. Why? We have different, we can see in different angles. Yes, the open source is cheaper, but as I mentioned before, cheaper, free cost most. When the service is down, when the service is misfunction, nobody cares. You take all the responsibility yourself if you use open source. But if you use commercial, then at least our SIE will take a look when something goes wrong. Our SIE will help you answer the question. We also have me to help you build, take a look with you. What's your problem? Give you some advice. That's all the commercial does. So similar story here. My question to you, Joshua. I like it. I don't say that it's wrong. Or that we're wrong, no. I would like to hear from you or Thomas or Bobby if we can also offer with the Kulpangu software that is. I mean similar to English, German, like you see. I think a demo would be really helpful. Yes, a demo would be very helpful. If there's something like this, open source, okay, fine for me. But if you can achieve such quality with open source like this, it would be very good. I would propose also your solution because if you achieve such kind of resources, why not? It would be the last one that I would say no. I mean, do you need time to prepare a demo? I mean, if you find something like this. I saw that they are doing quite good for my first... Yes, I can go back to R&D and find a demo for you and see how they are working on. But currently the large language model is not very good at German. So when you speak German to them, they probably will just reply in English or just render a memo or something. That's one of the drawbacks. But I think what can I do? But most likely the demo will be in English. If it's in English, I think it would be a good start. We are here in Europe, so most of the people that are interconnected, they speak English. So that would be the very best start. So we can extend it later, but for the first version, that would be amazing. Okay, please continue with your presentation. I have another question about the CSS. This is just one example for a help center. Do you believe that there are other use cases also related to this one that you are presenting? What I'm presenting now is the cool search, the CSS for IG solution. Currently, like I said, it's only for IG solution, so only IG is strongly related. And for your question, if you can use it in other scenarios, any IG use cases can buy our CSS vector databases. And one of the cool competitors is... I'm not sure if it's on my screen. It says, Joshua, let me stop it and start again. One of the very competitive for our CSS is... I think I was offline. Let me reconnect it to the network. I guess because you changed the... Can you see my screen? No, but it will become... Let me just reconnect it to the... Join the session and rejoin the session. During this time, guys, from the team, what do you think about this solution from Joshua? It would be nice to know how the customer can make use of this so that they can use this and they go to the CSS page or something like that. Is it an individual product or can they use this and they go to the CSS page or something like that? Or how can they access this? I'm not sure I understood your question correctly. So you're saying how people are going to use this cool search, right? This is outboxed server. So it itself is a server. So this is a product you can find on the console? Yes, you can go to the latest CSS version right now. I believe you can see something similar to it. But to actually access it, you need to register for permission. My permission is not available yet. That's why I can't show you the demo. I have some access to the GoAuth cloud. Access to the Huawei cloud. Let's see. I'm also really curious because I like it. To be honest, I really like what you present. Now when we are all sitting to Elvro, you will have the chance to see it. So this is in CSS, right? Yes, in CSS. Okay. I'm in the right region, so I'm in Hong Kong region. No, you should change to Beijing. Okay, let's change to Beijing. Is Beijing 1 or Beijing 4? Did you see the cool search suddenly disappear? Yes, disappeared. I think you have to use the... International? No, international. China, mainland. About our right corner, I mean we changed the access capabilities. But if you are able to choose Beijing 1, it is in China, mainland already. Otherwise it wouldn't be... But the account is not. The account is international. So it may not be available internationally right now. But I can show you my... Okay, let's see. I will stop sharing. We have different kinds of accounts globally. I see that the European account is missing. Accounts for China, mainland and international. They have different permissions. Okay, let's see. But this is supposed to be available for me, or? I don't know. They don't like me. I mean I don't even have access to China, mainland anymore. I'm only allowed to use Europe. Europe? As employee only the region where you are usually working actually. So this is what Joshua also just mentioned. For me it's actually very difficult at the moment to get access for Chinese resources. Oh, that's because Latin Seema. No, no. It's just like... bureaucracy and budget. Ah, CSS. So Joshua, you are sharing. I want to tell you you are not sharing. Oh, I'm not sharing, okay. But I'm pretty sure you were on... You see this is the Beijing 4 region. And this is the CSS console right now. I have the cool search document, platform. If you click this, it will ask you if you don't have permission. Da da da da da. A platform permission. Yeah, I don't have this permission so I cannot access it anywhere. So my story ends here. Yeah. Okay, go to... But this is... That also said NFTs are changing. So they are taking it using an LP service? Yeah. Then maybe you share your screen and play out those solutions. Play out those solutions. Can we mention that before the MLP could be also a component behind the scenes? I got the same... Maybe I missed that part. So in order to have this, we would have to have an LP as well. No. I mean principally yes, but not as a service presented to the customer, right? This is what we discussed before. Yeah. Okay, gotcha. I saw I see that you're who. Yeah, that's the story. I can try to get the permission and see if me or somebody else is going to show you this demo. Yes, perfect. My key message is our CSS for RIG solution have this Q-ring rewriting and result re-ranking function. And even without the PANQ itself is a very good vector databases. And here is... Let me show you the GitHub for benchmark. This is the approximate nearest neighbor search function. It's a search function in the benchmark. It compares with all those algorithms. No, no algorithm. This is all the search engine. Search engine, yes. This is fast. It's also very popular. You see 28K is made by Facebook. It compares all of them. You can see our Huawei's search algorithm is QSGNGTI. I don't even know how to spell it. This is a Huawei's algorithm. It's inside the CSS. You see QSGNGTI. And this is the performance. You see it's a green X here on the very top. So they are sorted from the best... I mean the list with colors on the right side is the ranking. The best to the... The right side here is like which one represents which graph. Yes, yes, I know. It's not necessarily by order. You can only see that it's queries per second. So the more queries they do, the better. Yes, in the same record rate, the more queries per second is better. So you see at the same record rate, our Huawei's CSS search engine performance is always the top. Highest. See this line here. And horizontally, the same speed, the query per second, we call it speed. Number per second, right? The higher record will be better. We all know what record is, right? They check so that the guys can access to this. Copy the... The edges, right? Yes, yes. Ah, sure. So the guys have to type this. It's good. Where's the... Sorry, I'm just looking for... If you put it on Solib, then I can put it on chat. Oh, okay. So that's already... I think the most is Spark and then we have it. Yeah, and this... This repository is not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. It's not maintained. This repository is now maintained by Huawei. And you can see it's also very active a couple of days ago. Not the last year, the four days ago. Yeah, so I think you can also show that our Huawei's search engine is already... Could mean something. Yeah, could be some competitiveness. And the rest of them, the rest of the... Image is also a similar story. Yeah, but for different tasks. Those are all tasks. Yes, yes. And you can see how is the QS something, something is also... Kind of competitive, be something, yeah, competitive. Okay, fine. Yeah, so that's one of the main points. The other point is all written down in the CSS release node and CSS promotions, guides, slides. All those stuff is there. So even without the PAN-GU model, CSS itself could be something. So that's all for the CSS story. And my presentation should be end here if you don't have any other questions. Do we have any other questions? Guys? Nothing from me. Good. Okay, guys, then we will close this session. Thank you so much for joining. Wait, I think Milan asked... Milan? Oh, no, Martin is asking if the IG can use for the Help Center Chatbot. Am I understanding correctly? It was just basically the same question already brought up by Ektor. Oh, okay. Resolve, many thanks. Yeah, my answer will be yes. There's no problem to build this and it's nothing hard. I built one small demo before. No problem, yes, yes. You see there is for OCRs documentation. QA search is nothing hard. So the answer will be yes. The document is all English. It could be doing very well. Yeah, that's all for my presentation. And based on my outline, my very last topic is a little bit small discussion with the model asco marketing. It's a brainstorm stuff. See if we want to talk about this because it's a little bit complicated. See if we want to talk about this because you know the model as is on his way doing the upgrade smoothly and it will soon or later upgrade to the latest. Now we have Transl and they're asking us if you want to add any feature, anything to make it more sellable in Europe. Anything you can you can check the how Google sells, how it sells, how Amazon sells their similar similar product and give them any advice. They can see if they have a workaround or solution or just add this feature and they start developing right now. Yeah, we have this chance so we can have a small brainstorm in this session or maybe find another session to talk about this. If you ask me this right now, I believe there is only just one way to find this out. Do you have a kind of benchmark of the current version from all of us compared for example with AWS or other similar products? AWS is SangeMaker, then in Azure, Google, it's called I think. I think machine learning is for Azure, Google is V something. But I mean if you have some kind of benchmark compared with similar ML solutions, then it would be more simple to figure out in which direction should we see the improvement on it, right? It's a little bit different. But model R is no like CSS. CSS we compare with the speed and the recall. It's very clear because CSS only do search. And model R is to machine learning and we don't have this benchmark for machine learning. I don't. It's more about the feature set comparison, right? Yes, indeed. But what they might offer but we don't currently. Yes, or they might offer what we see that is a good feature. Maybe we would like to edit it. Now is a good chance to talk about it. And now the window is open. We still don't know what the new version or the fourth jump is. We still don't know what it will have. We can do it in several ways. One, we can get the release now. Second, you can go to the Huawei cloud and check out the latest model R directly. The latest. Do you know what version the public cloud is running? It doesn't really matter. If you see it's good and the upgrade is no, then you can always demand it and add it to the latest version. Now the window is open. What we can do is following because I know. I mean, I am also the same opinion as you because we all know that Huawei clouds in their regions, they offer different versions. Just go to Beijing for that. Exactly. But you could provide us is which region has the same version or similar version as we will get on the OTC so that we can just get a better. I mean, we can test everything, of course, but we will never have the chance to test apples with apples in this case. So just give us an idea which region Huawei cloud has the current version that we will get there later. But really also the feature level. And we can also see what is the difference because we know release notes. OK, fine for me, but we need to touch it to check it. And also, for example, we have here on our team, Matt and the ferry or short or in it or I don't know, all the members could also just check it and see what what features are there. Really running. We can see and probably also evaluate if there is some kind of. I mean, after that, when we have the list of these features, we can just see with customers if they are looking for another feature. Then this model. I was thinking I think I missed the point the first time. So what you're saying is that now we have a time frame for the last hour and is giving us the opportunity to give feedback on what we would like to have in the future. Right. Yes, indeed. So I was thinking differently. So I was thinking if you see how Amazon have this feature, I think it's good. Google has this feature. I think it's also good. Just list all what you think is good and let the audience say is available. Yes or no. Do we have a walk around or do we have the do we have redeveloping something? Yeah, that's my point. OK, for this we can use the public model. It doesn't really matter. Yes, it doesn't really matter. It will be maybe months or of course months, but maybe half a year or so before this appears on OTC. Whatever we request, right? OK, we can do that. Do you know how long this window is open? Yesterday. Now they have some session host and tell us to give them feedback. I don't have anything on my mind. So I was bringing up the customized image this topic to them. And I do hope we can add more good feature inside it. And so I don't know if I make my point clear. Now, now, now I tell Andy say, hey, your. I frame more is related. Oh, I would like to have some feature that can have latest framework, latest driver, CUDA, Python, TensorFlow, latest version I want to customize. I would like to my decision which one is good, which we choose, which framework I would like to have this feature. Now I bring this to them. And I also want to have some some idea like add this feature that OTC can customize their own image like inference with Lamar free or training with Lamar free. Those image and OTC can develop this image and make it available to customers. So the customer just one click and they can deploy the Lamar free already. I also want to have this feature. But I have those things in my mind. But I do want some input from you guys. That's that's what I want to talk about. And give us I think some time, two weeks. I don't know how long. As soon as possible. Yes, because developing also needs some time. Yes, we will try. How about so how about we do this? So our next spring starts on next Monday. So we allocate maybe one or two days or from you guys. So in this case, so Matt, Jolt, Ferry. So maybe each of you spend one day comparing this stuff. So I don't know if you guys have access to public if you don't. And Hector could provide you a user account or maybe even I could. I don't know. Maybe Hector can provide me an account as well. OK, yes, guys. So we can give you an account. You spend one or two days comparing the GCP, Azure and so on. Yes. And let's say the week after we get together again and we talk about this. Five minutes. Great. Sounds great. And just one addition or one small topic for which would help us going to market. It's a simple logo made for Europe or certified by European usage. Or leveraged for Germany or something. I think you are totally right, Matthias. I think unfortunately it's a little difficult because we have no such stamp that we can get from official stages right now. I think the best thing we have for the moment is AIC4. Right. And I had actually an interview with Ernest and Jan after the last audit. They invited me for an interview. And you know, we have currently C5. This is our principal cloud certification. And AIC4 is nothing that we audit at the moment. But Ernst and Jan at that time was already planning to offer to T-systems to audit against AIC4. Or whatever comes in future in addition. So things like AI Act, etc. So I think it's like a matter of time when OTC will have to review exactly this again. And raise their hand and say, guys, now we have, I don't know, SOC, C5, IT Grundschutz. Please audit and compliance what the next thing we should do is AIC4 audit or whatever applies to have an official stamp. Right. I'm already looking forward to it. Okay. We have to make that right. Okay. Okay, guys, then it's now time for lunch. Thank you so much for joining this session. Gergud, you just let me know who should then add to the Huawei tenant for next week to take care of this model arts. And I will then add them to Huawei cloud. That's it, I think. Okay. Please create one for Jolt, Perry and Matt. Okay. Jolt, Perry and Matt. Okay. Yeah. Okay. Okay. Great. Thanks for your time, colleagues. Thank you. Thank you. Bye. Bye. So let's go for lunch, I think. I'm still waiting. Oh, good night. Okay. Good night. Good晚. Good night. Nice presentation. Thank you Joshua. Joshua, thank you. I like it. Thank you.
Meeting Minutes

Date: [Insert Date]
Time: [Insert Time]
Location: Virtual Meeting via Video Conference
Chairperson: Gergud
Attendees: Jolt, Ferry, Matt, Matthias, Andy, Hector

Agenda Items:
1. Feature Requests for ModelArts on OTC
2. Comparison of Huawei Cloud with Competitors
3. Customization of Images and Frameworks
4. Compliance and Certification for European Market

Discussion Details:

1. Feature Requests for ModelArts on OTC: 
   - Gergud mentioned the opportunity to provide feedback on desired features for ModelArts.
   - The team agreed to list features available in other cloud platforms (Amazon, Google) that they would like to see in ModelArts.
   - The aim is to improve the feature set and have a comparable version on OTC.

2. Comparison of Huawei Cloud with Competitors:
   - Jolt, Ferry, and Matt volunteered to compare Huawei Cloud's services with GCP and Azure for one or two days.
   - Access to public Huawei cloud accounts was discussed to facilitate comparison.

3. Customization of Images and Frameworks:
   - Andy raised the idea of customization options for images and frameworks on OTC, requesting latest versions of CUDA, Python, TensorFlow, etc.
   - There was a discussion about providing pre-configured images like inference with Lamar free or training with Lamar free to ease customer deployment.

4. Compliance and Certification for European Market:
   - Matthias mentioned the need for a logo certifying compliance with European standards.
   - It was noted that obtaining an official stamp would be challenging but that AIC4 certification is being considered by Ernst and Jan at T-systems for future audits.

Decisions and Action Items:

1. Jolt, Ferry, and Matt will compare Huawei Cloud's services with competitors (GCP and Azure) during the next sprint.
   - Each member will spend one day comparing features.
   - Next meeting to discuss comparisons is scheduled a week later.

2. Gergud will provide accounts for Jolt, Perry, and Matt on public Huawei cloud to facilitate feature comparison.
   - Deadline: Before the start of the next sprint.

3. The team will compile a list of desired features from other cloud platforms to request for ModelArts on OTC.
   - Deadline: End of the week.

Other Matters:
- Matthias expressed anticipation for future audits that could lead to AIC4 certification, signaling improved compliance in the European market.
- Meeting concluded with thanks and an announcement for lunch. 

[End of Meeting Minutes]WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
Traceback (most recent call last):
  File "/home/linux/meeting_whisper/whisper_console.py", line 18, in generate_file
    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址
AttributeError: 'NoneType' object has no attribute 'name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/queueing.py", line 541, in process_events
    response = await route_utils.call_process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/route_utils.py", line 276, in call_process_api
    output = await app.get_blocks().process_api(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1928, in process_api
    result = await self.call_function(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/blocks.py", line 1514, in call_function
    prediction = await anyio.to_thread.run_sync(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2177, in run_sync_in_worker_thread
    return await future
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 859, in run
    result = context.run(func, *args)
  File "/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/gradio/utils.py", line 833, in wrapper
    response = f(*args, **kwargs)
  File "/home/linux/meeting_whisper/whisper_console.py", line 46, in generate_file
    FileName=os.path.basename(file_obj.name)
AttributeError: 'NoneType' object has no attribute 'name'
Meeting Minutes

Date: [Insert Date]
Time: [Insert Time]
Location: Virtual Meeting via Video Conference
Chairperson: Gergud
Attendees: Jolt, Ferry, Matt, Matthias, Andy, Hector

Agenda Items:
1. Feature Requests for ModelArts on OTC
2. Comparison of Huawei Cloud with Competitors
3. Customization of Images and Frameworks
4. Compliance and Certification for European Market

Discussion Details:

1. Feature Requests for ModelArts on OTC: 
   - Gergud mentioned the opportunity to provide feedback on desired features for ModelArts.
   - The team agreed to list features available in other cloud platforms (Amazon, Google) that they would like to see in ModelArts.
   - The aim is to improve the feature set and have a comparable version on OTC.

2. Comparison of Huawei Cloud with Competitors:
   - Jolt, Ferry, and Matt volunteered to compare Huawei Cloud's services with GCP and Azure for one or two days.
   - Access to public Huawei cloud accounts was discussed to facilitate comparison.

3. Customization of Images and Frameworks:
   - Andy raised the idea of customization options for images and frameworks on OTC, requesting latest versions of CUDA, Python, TensorFlow, etc.
   - There was a discussion about providing pre-configured images like inference with Lamar free or training with Lamar free to ease customer deployment.

4. Compliance and Certification for European Market:
   - Matthias mentioned the need for a logo certifying compliance with European standards.
   - It was noted that obtaining an official stamp would be challenging but that AIC4 certification is being considered by Ernst and Jan at T-systems for future audits.

Decisions and Action Items:

1. Jolt, Ferry, and Matt will compare Huawei Cloud's services with competitors (GCP and Azure) during the next sprint.
   - Each member will spend one day comparing features.
   - Next meeting to discuss comparisons is scheduled a week later.

2. Gergud will provide accounts for Jolt, Perry, and Matt on public Huawei cloud to facilitate feature comparison.
   - Deadline: Before the start of the next sprint.

3. The team will compile a list of desired features from other cloud platforms to request for ModelArts on OTC.
   - Deadline: End of the week.

Other Matters:
- Matthias expressed anticipation for future audits that could lead to AIC4 certification, signaling improved compliance in the European market.
- Meeting concluded with thanks and an announcement for lunch. 

[End of Meeting Minutes]
./tmp9p3lew4x/20240510_121130.m4a
临时文件夹地址：./tmp9p3lew4x
临时文件夹地址：./tmp9p3lew4x
上传文件的地址：/tmp/gradio/406276c6c91843e9d7e647d308597ccbaca13be1/安全周例会717.mp4
base name 安全周例会717.mp4
 So next week Friday we do a webinar for the public where we introduce HSS and show the features and functionalities, give a live demo of ransomware and recovering and do you want to see it, to join? No, thank you. Okay. Okay, no problem. Either way it will be recorded and then uploaded also to our YouTube channel for interested customers. Based on what we have seen so far from HSS, I sent you an email for a few points where I just want to check with you the status and if that is possible and we can somehow address it to fix the things we mentioned. So basically if I share my screen, I just presented the service to our sales team internally and that is the feedback I received so far. For example for HSS it is not supporting the newest operating systems like Windows Server 2022 and so on. Joshua, you said we should give you a list and you forward this to Andy. Is this sufficient for you? Do you need to... Yes, it is too long. Can you please make it simple a little bit? Just say what do you need? And we already sent it to Andy, they are also kind of confused. So they tell me two things. The first thing is yes if the HSS is upgrading, it will have the same operating system supported with Huawei. Do we have a timeline for updating it on OTC? We already have the package, anytime can do the upgrade. Anytime? Ah, okay. I didn't know. First we are still waiting for him to do this upgrade. The second thing is if you have any other operating system you kind of like to have it supported, please leave it very clear. We want Windows 20, 24 or something. This list here, I share my screen and that is the list. This is the list, okay. I have a red X on the side so it kind of confused. We just make those supporting and it should be here, right? Yes, so it is in red X because it is currently not supported. Oh, okay. Then I think no need to let Andy to take a look and see how they can support it. Also, the upgrade is kind of critical because it can also solve the 0.5. I think you have the 0.1, 0.2, 0.3 and 0.5. You don't find mine well because the current version of HSS is weak. The scan function is kind of weak but the upgrade will have been improved. That will still be a good way to go. Okay. Do you have an estimation how long it would take to upgrade it? Because we have the webinar next week, Friday, and I don't know how quick it could be to upgrade it. Otherwise, we do the webinar with the current installed version if it is taking too long I think right now it is already Wednesday. I don't think it will happen next week. Okay, then we use the old version as a baseline for doing the... When you find the other customer, the next version will be done soon, which is also kind of true. Do you have release notes for the new version? Like an overview of what will be added and change that I can kind of announce what is coming next? I can maybe give you a release note but I don't think we should do that before we see it actually coming. What do you mean by see it actually coming? Well, what if the release note has some new feature and the coming package says no, we don't have this for OOTC? What will that be? Okay, so we don't know what is inside the package. So we need to see if it is matching the release notes. Yeah. Okay, good. Okay, then I will leave it out. Okay, so then we address point one and point five of the upgrade. So point two. So I said... No, I say point one, I say only align with the HSS so HCE will be supported and if the rest, if Huawei is not supporting then the upgrade won't help. I need to create a demand here. Yeah, and you can take this list. You leave out the first one because it is supported but for the other four you can add this list to Andi and create a demand that would be really appreciated. Okay. Okay, great. So second one is so if customers install or want to install an agent and they get a message that the software is not signed and not trusted. Can you take this one? Yeah, sure. The question is if you can sign it because we cannot really sign software which is not coming from OTC so we did not develop it. If we sign it then it is Huawei. Yes, yeah. Okay, sure. Would it be possible from your side? That is the message, publisher unknown and this is an app from an unknown publisher. If Huawei is signed then I will speak with Andi. I think it is possible from our side but I will get back to you. Okay. Okay, the third one is about updates, so regular updates of the vulnerabilities so we just implemented the package for July. Is it possible because you said it is coming once a month so can you provide an official statement or create a statement that it is coming once a month that we have it reliable like a promise we get it once a month in your vulnerability database? Because then we would also kind of promise it to our customers because if you cannot officially promise it then we cannot promise it to our customers. That is why I am asking. I think you should not promise this thing to customers because what if they have a month that no vulnerability is supported? I guess there will be no month. What if they have a month from July to August only very small or no critical vulnerabilities are supported? So if small vulnerabilities are supported I guess they should be put in the package, right? No, no, my point is that we cannot promise you that. Okay, it is fine. So it is not a problem because then we also say we aim so we have the goal to update it but we do not make any promises so you cannot. We aim, yes we aim. It is kind of true because if I remember correctly since we deployed this HSS and GA we kind of upgraded it like one or twice per month but because we can upgrade simply because we have the package we have the new support but on one side they say I think they are not sure I think they say something like the longest period for this upgrade is like a quarter. So I guess that happened before I am not sure but yeah so we aim to upgrade which is kind of reasonable frequency. Yeah, okay that is fine with me. The next thing is about also having that we can install the agents on premise or on another cloud so currently it is not possible? I do not get it what to mean but I know also I give you the link it says very clear how to do it step by step I am not sure. Yeah, this link here right? Yeah, we have the same documentation on our page but it is not possible because the agent cannot be so it is only communicating internally. So if you look at the agent configuration one second. I just take a quick look I think it says something about the proxy is no community with each other and I assume that is not the problem of our agent. Yeah, because for example if I want to download the agent I need to download it from this page so here is the host guard agent but this is not accessible from the internet so I cannot download the agent and this is also the configuration yeah HSS agent pot blah blah blah and so this is where the agent is communicating to but this is also not reachable from the internet so the agent cannot communicate outside of OTC so it is only possible by network internally. So we also have on our page if you go to our help center and HSS it is written yeah it is here for where is it here is third party cloud server and on premise servers yeah but how do you install the agent on the third party cloud server if it is not allowed to or the connection is only via OTC internally so it must change to internet. Do you understand what I mean? A little. Let me show you on Huawei's site. Oh it is there. Let me just quickly need to log in. So if I go to Huawei cloud and I want to set up the agent on HSS. It is loading. So if I want to install the agent I get two versions the cloud server and non cloud server. So cloud server that means these servers are protected by HSS they are on Huawei cloud and non cloud server is like on premise or on another cloud anywhere else but not on Huawei cloud. So somehow you are missing this page and you have problem to install the agent. Yes. If you find a way to install the agent you should have no problem. No because the agent has the configuration that to contact this system the master is kind of our dashboard. Sss agent pod lb otc systems.com this is not reachable via internet. So the agent cannot communicate. Hi Sebastian. No problem. Did you understand now Joshua? Kind of. So just install agent and I may connect to this pod. Yes but this pod is not you cannot connect to the pod when you are outside the otc. But you have to get it work. And that's why you have on Huawei cloud you have agent for cloud server and agent for non cloud server. I see. And I don't know if that is part of the upgrade for the new HSS version. Maybe. Maybe not. But I think this version support this function already. I just need to figure out. Because we have it on the documentation. The third party cloud server and on premise server. We have it at least documented here but it is currently not working. How can we move on with that one? Can you have a look at that one? Ok that's great. Sebastian just a summary while you were absent. So I just spoke about this email about the HSS let's say pain points from our side. So Joshua will address compatibility with these new operating systems at R&D for the first point. Great. For the second point TiBo said they can sign the agent with their certificates. So he is asking Andy. If so it would just be seen like Huawei is the publisher. Not it's unknown it's from Huawei the agent. Of course if you sign it you can see it's signed by Huawei. Yeah sure. Yeah. I see that right. For the third one they do not provide an official promise let's say. So for the regular upgrade we aim to have it once a month. So we will also say we aim to update it monthly. There is no promise to customers that they cannot kind of blame us or do any legal measures if we delay. For the first one we just spoke about and for the fifth one about not finding Maverick correctly Joshua said that will be improved with the new HSS version with the upgrade. We already have the upgrade package. We are just waiting for you to give the go to implement it. That was what I was told. Is it the one that is written there? BM 5299? No. Yeah so this is one bug. HSS not finding Maverick correctly. Can you send me the ticket number where I need to approve? Tiwa should have it right. But that's just one bug the bug calculated. But I don't know any I guess you need to approve any demand then for upgrading HSS? I think so but I don't know where you have it. Can you send me the ticket? I am not a lot of that ticket. Like who created this? I am sorry I didn't understand what did you say? I don't know about the ticket. Do you know who created it or what? Like is there a demand for this? Let me check my open. I don't know who would usually create the demand when the package is already there to be installed. I don't know maybe there is no demand to upgrade yet and we need to create it. Connected tickets. There is no demand. Who would usually create this demand? Just a second I just check all the tickets potentially but I don't see any ticket for that. Nothing assigned to me no demand with HSS in. The question would be who would create this ticket? Either it is the demand that we are giving to Huawei that we are creating it but also Huawei is creating these demands if they provided something and okay they just want to implement it. It is a bit nuts if we have the bug ticket and then on top of that we also create a demand. Usually we get the demand then from Huawei whenever they have provided the solution. Of course we need to have the demand ticket to have the changes triggered. Yes, yes, yes. I guess this new version will fix not only one bug hopefully a few more. So it is the new HSS version? Yes. But we haven't created the demand for the new version. But Joshua said we can install it, the package is available. I have no information from today. I just want to check. I mean that is what Joshua just said like 10 minutes ago. I heard it also for the first time. Do you imply that we do not have the new HSS package? That is a question do we have or do we have not? We do have I said it before so who is challenging? Tibor. Tibor do you know where we have the new... I am not challenging. I want to check it. You asked Yun Dan next to you and I think she knows about it. We are waiting for the HSS update. She definitely does not know. I do mention it last week I think. I would say HSS is quite important. We should upgrade from time to time. I think Sebastian you know this topic right? I will check it with Lily and that is the new version that I will create the demand change. Demand change, whatever. But keep it to the latest version and keep catching the latest version. I think it is the right way to go. Yes, yes I agree. I heard it today the first time that the new version is waiting to be installed. I have been waiting for a long time I think. I am waiting but I did not get the information it is available and we can do something. That is new for me today. But if you have it yes please Tibor create a ticket and form us. Sebastian approve and start with P-Port. Yes but I also need to have release notes for that one. Yes that is coming hopefully with the package. New documentation, new API, blah blah like we usually do. Because we will get the question by the customer can HSS do antivirus and malware detection? Currently I am not sure what to answer because if I say it can do it a bit poorly. That is not a good answer to give. And if we have the package and release notes we can say not yet but will come with the next version. That is a better answer we can give. I think the answer should be yes we can do it because it is its function. Yes but I sent you the email as of today if I use some malware they are not detected. Yes did you try the new real one? Yes, yes of course. No the one in the test set those are not real. No we have a different source. Ok then what is the do you have the virus fingerprint? If you do please send it to me and I will write which virus you have not spotted. But does it make sense with the old version when you say it is improved with the new version to wait until we have the new version? Yes the new version but the problem is you do not have the new version next week. Do you think you can upgrade the HSS in one week? Depends on the upgrade right? Depends on the amount of new functionalities will be added as you said before. You said before there will be quite a couple of new functionalities added then definitely not. Probably not. What we just do is... There is only a small upgrade and there is not much to test. It can be quick right? We have this ice fire thing you gave us so this is working. We will use this one in the demo. But it is also not detected as a malware by the way. Yes it is a ransomware. Yes but it is a virus right? It should be detected just because it is in there. The file itself should also be detected. So then what we can only do is kind of hide this antivirus stuff because it is not working 100% and hoping it will be improved in the next version. I do not know what you mean with signature so I sent you this email last Friday. I do not know how to extract it and what does it mean so what do you need? How do we get the fingerprint of a virus? I do not know what to do. If you have the virus then you are supposed to have the fingerprints. This is referring to what is this virus and what is the behavior. It is just like a human. You use this fingerprint you can identify this is me, this is T-Ball. I can give you the name and then you can google it and you know what it does. You mean kind of. Just example. I sent you this email on Friday. Here are three virus things, ransomware which are not identified. For example Win33CRELOC. That is a virus we have and it is detected by the Windows Defender as ransom. The below one but not identified by HSS. If you now say fingerprint what do you need? What is the fingerprint? I do not want to start from there. If I google it here is the behavior of this thing and here is the technical information. I do not know what you mean. Search the fingerprint. It should be a random hash number. I think I am not programmed. I do not get any search results. Sebastian can you help me? Yes I need to do that together afterwards. I can send you this for one example but I guess we have multiple examples. Check all the vulnerabilities we put in there and we can collect information. Then we do it and send it to you. The question is if that will be already fixed with the new version and we do the effort. We would not need to but we can provide it. That is what the bug ticket is used to. Then we can put more information in the bug tickets. I think we use this memory in Gigabit for... We will skip this part for the customer webinar next week because it is too soon. We just hide this antivirus functionality here. We do the ransomware with the ice fire example you gave us. Thank you for that one. Sebastian, do you have... For the ice fire, have you already talked about the inconsistent results? Not yet, we just talked about the five points I sent via email. For the ice fire ransomware, I tried it out. It is working well from time to time. It is also detected and so on and so forth. I also have the case that it is not detected and the ice fire stops running without being killed. Therefore, it is not being reported by HSS. I will further try it out but I might need your support next week. You do see my email, right? Yes, I have also seen the video. Did you install that and did everything exactly as you need? No. It has no set. You need to wait when you change the epoxy. You change the epoxy and the spreadsheet does not take effect. You run the virus and you will just go through because you think the epoxy is not changing. The epoxy is supposed to be reported without being killed. Which proxy do you mean? The ransomware virus has two poxies. The first poxy is report and kill. The other one is report and kill. You change the poxy. I used it with report and isolate. So report and kill. No, every time you change the poxy it will not affect immediately. Which proxy are you talking about? Policy, no poxy. Policy, sorry. Every time you change the poxy, you switch to report no kill and you change to report do kill. You need to wait until it takes effect. Yes, but I did not change the poxy. I changed the poxy. Let's say it was especially when I set up everything. I downloaded the virus. I extracted it. I changed the mission there. Let me just do it. Just a second, I just need to log into my environment. Here we go. Give me a minute. I just set up my environment because I rebooted before. And then you can also show your screen. Yes, just logging into my tenant. I will stop sharing my screen. All right, I have HSS. And some protection. I have here, let's take this one, HSS presentation 01. I can't do the mistake because I forgot. Erans change. All right, here we are. Switch to UD. Then I need to... See, it's there. See, it's there. The atherod. See, it's executable. Let me see the poxy. Policy. It's this one, right? I have here report, alarm and isolate. I have the page files, etc. and var log and home, linux, root and sys. All types. It's here. Click the... It's already there, right? It's already there. Let's see. Sorry. See, it's running. It's not killing, right? Yes. And if I refresh here, I also don't get the... I also don't get the event. You don't get the event is normal. Like when you need to wake up all the time. It's normal. It's normal. It's normal. It's normal. It's normal. It's normal. Like when you need to wake up all... You also see, right? So it's like, okay, it encrypt the zip file. It creates the readme text file. Do you see the bait? The bait for the ransom? Which root it is? Sorry? Is this under the proxy? Yes. Let me see. Okay. So sometimes it works, sometimes it doesn't. In what time... It seems to be random, right? It seems to be like... Sometimes it does not try to encrypt the bait files. But it stopped running, so the process stopped running before it encrypted the bait files. So it encrypted some files. See here also some of the files are encrypted, but not all at all. Okay. Okay. Wait, why your bait file have this... is culled by the code? I don't know. Can you go to the... your bait folder? What do you mean with bait folder? Go to the virtual machine. CD. This? No, the bait. Okay. Where is it? The bait... The SD something. Okay. That's where the... It's not attacking the bait file, that's why it's not working. Yes. For me, I think the main issue is that the process stops running, right? Because if it runs indefinitely, then it would eventually encrypt those files. But it does not, it just stops running. That's probably the issue. No, it's not encrypting the bait. I don't know why, but it's not encrypting the bait. Yes, but it's also not encrypting here. Yeah, because the hardware is safe. Oh, it's encrypted also. Everything else is encrypted but not the bait size. No, but the bait is not encrypted. Can you go to the SDEC Q0079? Sure. No, this one. No, this one. Yes. Q0079. Okay. Okay. Okay. Okay. Okay. Okay. I'll let Andy take a look. Okay, thanks. Also, try it with another operating system, right? With the IMR1. It's the same there. All right. Which version of the Linux was it? HCE2. Yeah. Okay. Thank you for the question. Okay. Okay. Thank you for showing us the photo. You're welcome. All right. That was basically the main thing from my side. I have an additional topic. It's about these energy cloud customer. So, I just received information about the priority of needed services and for the open ones, the highest priority for the customer is SAC master. Is it also possible to get some insight like we did for Cloud Bastion host to SAC master? Probably we have some difficulties about it because the SAC master is still not stable. How come it becomes to the higher priority? I don't know a way of that. It's not a high priority. It's the highest out of the left over. So, for generally it's medium. So, CBH is low priority. CBH is low priority? Yes. I just was informed yesterday by Daniel and Tao. I didn't know that until yesterday. Therefore, it's more important to have a look on SAC master. Medium means the highest priority things. It's HSS and Container Guard which we delivered. We have this ELB mode for WAF which we planned next quarter and also for DBSS supporting my SQL that is already planned and we do it next quarter. So, then the next one would be have a look at SAC master but that would be like medium pure priority means somewhere next year. Question would be about your you saying it's not stable. Do you have any WAF idea, timeline when it would be ready for use in partner Clouds like OTC? We will see about that but we currently we do not have as far as I know we do not have this. SAC master is not delivered in any of the HLV Clouds and it will probably have a lot of difficulties and a long long period. So, it's betting that. Okay, but it's strange because they left Orange and they say they need the service because they use it. They do not use this service. But why do they then say they need to continue? That's a different angle, a different view. So, then it will not be a blocker for the current business because they haven't used it. But I agree it's good to have this one I'm just saying please be ready for the long range long period delivery. Yeah, I mean but somehow it should be on our roadmap in the future even if it's taking a long time because it's integrated in so many things checking the whole platform. That's the main issue. You integrate a lot of things and the period getting longer, people start forgetting things and you will end up with a very difficult delivery. So, if we plan to do that, we tend to do it quick, shut the delivery, have enough resources and give it a certain period and get it done ASAP. But you said it's not stable. It's not stable. It means you have a lot of new features coming with this thing. You keep integrating stuff, you keep integrating AI stuff. But that's cool. New feature means new function and new function means long period test and probably have some of the features even experimental so you see what I'm saying here. So, I don't see a big issue in having, if we mention it's open beta test and so on, we still have beta features in HSS so I don't think it's a blocker to not do this service. I'm not saying it's a blocker or anything. I just say if you do it, I aim to do it quick. Yeah, okay. If it's possible to do it quick. Which would bring me back to the initial request, can we also have some session to get live demo of the service like we did from offerCBH? Maybe I will ask Zan-Yu. That would be great. My topic, I still have two more topics need to go through which is quite important. The first one is the EPSGA and the second one is the HSS image for ECS. Who is the response for the HSS image building and testing? Image squad, so Homan Schiller and Johannes Schischke. I'm in contact with them. They have any progress? They say they are going to finish it in this month, right? You only have two weeks. They said it will not be done before end of this month. So let me ask them for an update how well they are progressing. Because we don't have a regular meeting with them. You say it's not necessary. So every week I aim to have some at least update. I don't want to ending up like at the end of this month I don't want to hear they say we just finished creating the folder. To... HSS. It's no plan, no schedule, no in the roadmap. Nothing. They planned. I also agreed with them if they have issues and do not progress in time as a plan they will let me know. Nevertheless of course I can ask them regularly every week. I can ask them every day if you want for an update. But the more I ask the less they progress. Do they have any progress? It being at least two or three weeks since they said it. I will check it. Okay, still no progress. Then what about EPS? For EPS I told you, right? So we are waiting for reply from what's your name? We don't get any reply there. We cannot move on. Let me move on. If we have the APIs in UNL then we can test it there shortly and then I think we are if it's available in UNL as well we are also fine to go to GA with it according to what we had in the software. So we need functional testing. But if we don't have it yet in UNL then there is no way to test it. The test case would include creating overarching region projects and if we only have it in one region we cannot test functionality. Just a question Joshua. So is also this energy cloud customer requesting it or why do you want to push it? Because I didn't see any customer request for general availability. For EPS? Yes. How should I answer this? No, no customer demanded. But that's not the reason we put it in GA forever. Right? It's just to complete it after 100 years. First thing is it's been there for years. It's not for months. I kind of accept for that. But it's there for years. It's not just one year, two years. I think it's like three or four years. Longer, longer, longer. Even before I joined. Somewhere, someone decided to make it white list only for one customer and we didn't touch it since then. Yes, and this nonsense should end up right here. We spend time, we spend money, we spend people to evolve, to get this deliver done and it function just fine because you never hear our speaker complain EPS is not working, right? I know it's not complaining. Because I also use it every day. It function is good. Yeah, I agree. So, what's your reason to not GA it? That's the question. It's only just a priority thing. So, it's not important. But surely we should do it when we have time left. I think we should put some priority on it because you already see if we don't put any priority on it for the last four years. Yeah, because it was not important for any customer. So, we would rather have HSS and Cloud Firewall instead of EPS. But if we have resources, yeah, we can. It's not that difficult, right? It's publishing APIs from all sides. It's not too much effort publishing. We will need to have some effort testing it. Question, of course, Joshua, is there any service upgrade of EPS that we want to implement before we go GA with it? I think you already checked it and you said, okay, there is no real upgrade of it available. So, that's also fine for me then. We don't need to upgrade it. Publishing APIs in UNL, testing it, okay, is it working as intended? Also, the CCross Region functionality there. And then let's go GA. It's okay. Yeah, what we just need to include is then testing and open bugs like service integrations. Yeah, so if you cannot authorize ECS and CCE, for example, as basic services, the service is basically useless for customers. And I have the fear a lot of services will not be integrated automatically if you deploy it on Netherlands and we need to trigger other squads to do some work. But I'm open for surprises. But yeah, you are right. The priority is adjustable, but the text is still important. Yep. And I see the image for HSS is quite important and hopefully next week we can get some update like they already finished this image, that image and waiting for test or something like that. Is it also needed to update any console UI? Yes. It's already done. The console part is already done in the testbed and we are waiting for, but it doesn't do anything because we don't have the image at the back end. So I do hope we can have some update of what they are actually doing. Now I'm checking maybe they are already even finished with you. I trust you, but I just don't trust them. I mean, it also comes from the bad experience because I think last year or sometime I was joined the squad. People said they are going to finish this day, that day and when we ask them what's the progress after three months, they say, oh, we just finished our vacation. So no progress. Alright. I have one other topic not related to HSS and stuff. Maybe T-Boy you can help me out there regarding the P-Wave or the platform-wave. Tino, that's probably not the thing for you because we don't run money with that. In the end, we repaired the manager nodes, that's fine. But T-Boy we talked about in the past about upgrading it eventually. Step by step. I'd like to plan with you, maybe not in this call, but we can do it offline because I think it's also not a topic for Yoshua. I can just quickly say that I have cleared the division ticket and it's being evaluated by R&D currently. So I'm tracking the progress. I will get back to you. I have new information. I uploaded, I commented all the requirements. I spoke with Ference about it. What are the exact requirements and I put it in the ticket. So yeah, when I have feedback from R&D I will get back to you. Okay, good. You cannot estimate some timeline. When we get... Usually deadlines for each. By step or like how do you say? Like each... You can say step. It's currently in the analyze state. So I can also ping the guy who is analyzing it. Residence time one day. So it's currently on him for one day. I think that's progressing quite fast. Let's keep in touch there about this topic. The freedom to not lose focus on it because it's back end security, right? It's platform security, of course, violence on occasion. So I need to take over his part with annoying people about it. But we need to get it done, right? From what I've got from my colleagues it's fairly manageable currently to maintain it. So we need to see how we can improve the situation there. And without risking the availability of CPVAS and the function of CPVAS. Okay, that's it. Any other topics you need to talk about today? Send me the email to dedicate the priority change for the energy cloud because I think none of us noticed that priority change. It's kind of a surprise for me though. So there was no email. There's an Excel list I received from Daniel. No, not from you Sebastian, right? And you received it from Daniel. Yes. I can forward you this Excel list and there's a priority inside. I didn't notice it before. That's the Excel list I already showed you, Joshua. So it's the same actually. We talked about this one already. But wasn't that because... I know we have these two servers is on demand. But my question is since when the priority change? Because I think before the CBH is median. The second master is low. That's what... I just received this file. I was absent when this file was created and prior to the last. So it was where I was absent. So I cannot answer this question. I sent you the screenshot from the list in our group. There you see the priority. And basically that is the list I received from Sebastian and you received it from Daniel. I don't know when. A few weeks ago already. Months ago. So there you see the priority. High things. We have delivered the cipher suits. We will deliver the support for ERB mode. So these are the high things. HSS we already delivered. And then next is medium is DBS. S supports RDS for MySQL. That's what we have planned. And then next thing would be SACMASTER for medium priority. If you see the list which I just put a screenshot in the chat. That is what I received and I just identified the priority yesterday. Because I talked about CBH with Daniel. He said why do you care about CBH? It's low priority. Have a look at SACMASTER. It has a higher priority for the customer. That's basically the information I have. Any comments from your side Joshua? Sorry I was not listening. Oh. Okay I sent you a screenshot of the priority. And this list is a few months old. And I just received it. While I returned and there you can see the priority. So it didn't change. It was this way all the time. Okay. So SACMASTER has higher priority than CBH. That's why it would be nice to get also an overview by the new view. That we can have a look into it from our perspective. Or implementation plans. Okay. That would be really cool. Okay. Unfortunately I have to leave. I have a private appointment. Yeah we will talk to each other next week latest. We will stay in contact via chat. Alright. Okay. Have a good day. Alright. Bye. Bye. Bye. Bye. Hello. Hello. Hello. Um. Um. Um. Um. Um. Um. Um. Oh. Oh. Xianlining. understanding how. We have a meeting with Alker, the head of TSC, about how to bring OTC Force to the next level, and how to do Go To Marketing. And in this meeting... Wait a minute. Let me put my headphones on. Hello, can you hear me? Yes, yes. In this meeting, there are several parts of the meeting. One of them is that the OTC team has summarized the progress of all sales charts and key activities over the past century. And when they summarized it, they also raised two points about the product. The first point is the old-fashioned GTO. I think that's based on the pace we're moving forward now. Including the July verification, which is the process of the procurement after the verification is completed. That's the current solution. The second point is what Alker mentioned in the photo. The old-fashioned GTO on the platform. But it didn't say which service it was. Because he mentioned this before. So I think that's the first point. The past-century version of the GTO. It's a bit old-fashioned. And the second point is the GTO in the Model S. It's the second point. Because there are many sales in the meeting, we can't clarify it with him. So we sent it back. That's the background. I think we should discuss our strategy and give answers to him. If the strategy works, it's fine. If it doesn't work, can we optimize it? If it doesn't work, we can't do anything about it. We have to try our best. So we should discuss the strategy again. Because last time when Yu Xin came, she mentioned that the source will be distributed to Europe. The source will not be strengthened, not be verified, not be double-closed. After the release of the community, we will throw out the image. But this is the plan of the leader. If we do this, I think at least in the release stage, the GTO can't say anything. Because it can't keep up with the upgrade. If it's behind again after the upgrade, it's his business. We can force him to change it. So we should discuss our strategy here and the progress of each strategy. We should discuss it.
________________________________________split transcription____________________________
Meeting Minutes

**Date:** [Insert Date]
**Time:** [Insert Time]
**Location:** [Insert Location]
**Attendees:** Sebastian, Joshua, TiBo, Andy, Yun Dan, Lily, Tibor
**Chairperson:** [Insert Chairperson's Name]

---

## Agenda Items
1. Review of HSS Pain Points and Upcoming Updates
2. Update on Compatibility with New Operating Systems
3. Agent Certificate Signing by Huawei
4. Regular Upgrade Schedule for HSS
5. Improvements in Maverick Detection with the New HSS Version

---

## Discussion Details

### 1\. HSS Pain Points & Upcoming Updates
- Sebastian summarized pain points regarding the Host Security System (HSS) and discussed potential solutions.
- Joshua will address compatibility issues with new operating systems at R&D.
- TiBo mentioned Huawei can sign the agent with their certificates, which Andy confirmed would show that it's published by Huawei.

### 2\. Compatibility Update for New Operating Systems
- Joshua will work on ensuring HSS is compatible with newer operating systems.

### 3\. Agent Certificate Signing by Huawei
- TiBo informed that signing the agent with Huawei's certificate will make its origin clear, but Andy confirmed this needs to be verified in practice.

### 4\. Regular Upgrade Schedule for HSS
- The team aims for a monthly upgrade schedule for regular updates.
- No official promise is given regarding the update frequency, allowing flexibility without legal implications if delays occur.

### 5\. Improvements in Maverick Detection with New HSS Version
- Joshua confirmed that the upcoming HSS version will improve detection capabilities for Maverick malware.
- The team has access to the upgrade package and awaits approval from Sebastian to proceed with implementation on P-Port.

---

## Decisions & Action Items

1. **Compatibility Update:** Joshua to ensure HSS compatibility with new operating systems at R&D (Deadline: [Insert Date]).
2. **Certificate Signing:** TiBo to sign the agent with Huawei certificates as discussed, and Andy will verify if it's correctly identified by users.
3. **Monthly Upgrade Schedule:** The team will aim for monthly upgrades without providing a binding promise to customers.
4. **Maverick Detection Update:** Tibor to create a demand ticket for upgrading HSS to the latest version (Deadline: [Insert Date]). Sebastian to approve the upgrade, focusing on P-Port as a test environment.

---

## Other Matters

- Discussion about whether malware detection capabilities can be improved before the new version is deployed.
- Sebastian requested virus fingerprints that were not detected by the current system for analysis and improvement.
- The team acknowledges the need for clear communication regarding HSS's capabilities, especially in malware detection, to provide realistic expectations to users.

---

Please note: Actual dates, times, locations, chairperson details, and deadlines should be filled in as per the actual meeting details.Meeting Minutes

**1. Meeting Overview**
- Date: [Insert Date]
- Time: [Insert Time]
- Location: [Virtual / Physical Location]
- Chairperson: Not Mentioned
- Attendees: Joshua, Homan Schiller, Johannes Schischke, Zan-Yu, and Others (names not specified)

**2. Agenda Items**
1. SAC Master Services Update
2. EPSGA and HSS Image for ECS Progress

**3. Discussion Details**

### a) SAC Master Services Update:
- The highest priority request from Energy Cloud customers is for the SAC master service.
- Concerns were raised about the stability of SAC master, but it was clarified that its medium priority ranking is based on remaining services.
- CBH (Cloud Bastion Host) service is considered low priority in comparison.
- There are uncertainties regarding SAC master’s readiness and timeline for use in partner Clouds like OTC.

### b) EPSGA and HSS Image for ECS Progress:
- The EPS (Enterprise Project Service) has been whitelist-only for a long time, with no clear customer demand or request for General Availability (GA).
- Joshua advocated for moving EPS to GA status due to its functionality and the lack of complaints about it.
- It was noted that EPS should be prioritized since it has been in development for years without reaching full availability.

**4. Decisions and Action Items**

#### SAC Master Services Update:
- **Action Item**: Regular updates on SAC master’s progress are requested by attendees to avoid last-minute delays or surprises.
- **Responsible Person**: Not specified
- **Deadline**: Ongoing

#### EPSGA and HSS Image for ECS Progress:
- **Action Item 1**: Joshua will follow up on the progress of creating an HSS image for ECS every week, ensuring regular communication with the team responsible.
- **Responsible Person**: Joshua
- **Deadline**: Weekly updates until completion

**5. Other Matters**
- There was no additional discussion recorded beyond the agenda items.

*Note: The minutes have been drafted based on a summarized conversion record where specific dates, times, and physical locations were not mentioned.*Meeting Minutes

**1. Meeting Overview**
- Date & Time: Not specified in the transcript.
- Location: Virtual meeting via teleconference or video call.
- Attendees: The attendees' names are not fully clear, but it includes "T-Boy," "Tino," and others who discuss HSS, P-Wave/platform-wave upgrades, CBH priority changes, and OTC Force strategy.
- Chairperson: Not mentioned in the transcript.

**2. Agenda Items**
- Project Progress Update (HSS)
- P-Wave/Platform-Wave Upgrade Planning
- Change of Priorities for Energy Cloud Projects
- Strategy Discussion for OTC Force's Next Level

**3. Discussion Details**

#### HSS Project:
- The team had a bad experience with the squad last year due to lack of progress and miscommunication about project completion dates.
- Current status: People are back from vacation, but no significant update was shared.

#### P-Wave/Platform-Wave Upgrade Planning:
- T-Boy mentioned an ongoing discussion about upgrading this system step by step. It is not related to HSS or money management.
- A ticket for the division has been cleared and is being evaluated by R&D; it involves platform security enhancements without risking CPVAS availability.

#### Change of Priorities for Energy Cloud Projects:
- The team discussed a surprise change in project priorities, as CBH moved from median to low priority while SACMASTER rose to medium.
- Daniel shared this list months ago with no clear explanation on when the priority changed; it was only noticed recently during discussions about CBH's new status.

#### Strategy Discussion for OTC Force's Next Level:
- The team summarized sales charts and key activities' progress, raising concerns over GTO (Go To Market) being old-fashioned.
- Two points raised: 
   - Old GTO process needs modernization.
   - Unclear reference to GTO in Model S by Alker; clarification needed from him since many sales representatives were present but could not clarify.
- Discussion on strategy to address the issues and possibly optimize it if current plans fail.

**4. Decisions and Action Items**
- No specific decisions or action items mentioned except for the need to discuss strategies further and give answers back regarding GTO modernization needs.
- The team will re-strategize considering Yu Xin's previous suggestion about source distribution focusing on Europe without double-closing after community release, potentially impacting GTO's ability to keep up with upgrades.

**5. Other Matters**
- Additional points of note are not mentioned in the provided transcript; further details might be included in other sections of the meeting minutes if they were discussed during this call.
- The team will follow-up on these discussion points and action items, potentially scheduling another meeting or communicating via email/other platforms for updates.

Note: The actual decisions made and specific action items are not clearly outlined within the given transcript. It's suggested to have a clearer summary from participants involved in each agenda item for accurate record-keeping purposes.Meeting Minutes

**Date & Time:** [Insert Date] | [Insert Time]
**Location:** Virtual / Physical Location (as per respective parts)
**Attendees:** Sebastian, Joshua, TiBo, Andy, Yun Dan, Lily, Tibor, Homan Schiller, Johannes Schischke, Zan-Yu, T-Boy, Tino and others.
**Chairperson:** Not specified

---

## Agenda Items
1. Review of HSS Pain Points & Upcoming Updates 
2. SAC Master Services Update
3. Compatibility with New Operating Systems
4. Agent Certificate Signing by Huawei
5. Regular Upgrade Schedule for HSS
6. Improvements in Maverick Detection with the New HSS Version
7. EPSGA and HSS Image for ECS Progress
8. Change of Priorities for Energy Cloud Projects
9. Strategy Discussion for OTC Force's Next Level

---

## Discussion Details & Decisions

### 1\. Review of HSS Pain Points & Upcoming Updates
- Sebastian outlined the pain points concerning the Host Security System (HSS), and potential solutions were discussed.
- TiBo noted that signing the agent with Huawei certificates will clarify its origin, which Andy confirmed would show it's published by Huawei.

**Decision:**
- TiBo to sign the HSS agent with Huawei certificates; Andy will verify this action.
  
### 2\. SAC Master Services Update
- The team discussed a priority change where SACMASTER rose from median to medium importance, affecting project planning and resource allocation.

### 3\. Compatibility with New Operating Systems
- Joshua addressed compatibility issues of the system with new operating systems.

**Decision:**
- R&D department will be tasked with ensuring seamless integration between HSS and new OS versions.

### 4\. Agent Certificate Signing by Huawei
- Confirmed as an action item from the first discussion point.

### 5\. Regular Upgrade Schedule for HSS
- The team agreed on a regular upgrade schedule for HSS to enhance system stability and security.
  
**Decision:**
- A formalized upgrade plan will be developed, focusing on systematic improvements without affecting CPVAS availability.

### 6\. Improvements in Maverick Detection with the New HSS Version
- Details about enhancements in threat detection were discussed regarding the new version of HSS.

**Decision:**
- R&D to implement advanced maverick detection features as part of the upcoming release.

### 7\. EPSGA and HSS Image for ECS Progress
- Updates on the progress of integrating HSS with the Energy Cloud System (ECS) were provided, focusing on the EPSGA module.
  
**Decision:**
- A ticket has been cleared to evaluate platform security enhancements without risking CPVAS availability. R&D evaluation in progress.

### 8\. Change of Priorities for Energy Cloud Projects
- Daniel's list from months ago was revisited, noting the surprising change in project priorities. CBH moved to low priority.
  
**Decision:**
- The team will reassess the prioritization criteria and update project roadmaps accordingly.

### 9\. Strategy Discussion for OTC Force's Next Level
- Concerns were raised over the outdated Go To Market (GTO) process, requiring modernization.

**Decision:**
- A strategy to address GTO issues and potentially optimize it will be developed. Answers regarding GTO modernization needs will be gathered from relevant personnel like Alker.

---

## Additional Points & Action Items
- The team encountered miscommunications about project completion dates last year but aims for better coordination this time around.
- P-Wave/Platform-Wave upgrade planning is ongoing, focusing on step-by-step enhancements unrelated to HSS or financial management aspects.
  
**Action Item:**
- T-Boy and the team will provide regular updates on platform security enhancements and risk management strategies.

---

## Follow-Up
- Specific decisions were made regarding SACMASTER priority adjustments, GTO modernization needs, and HSS agent signing by Huawei certificates.
- The team will schedule follow-up meetings for detailed discussions on strategy implementation and project progress. 

Note: This document merges all the meeting parts into one coherent narrative while addressing all unique points discussed during each segment. All attendees contributed to various topics as needed throughout the meetings.

---WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
Meeting Minutes

**Date & Time:** [Insert Date] | [Insert Time]
**Location:** Virtual / Physical Location (as per respective parts)
**Attendees:** Sebastian, Joshua, TiBo, Andy, Yun Dan, Lily, Tibor, Homan Schiller, Johannes Schischke, Zan-Yu, T-Boy, Tino and others.
**Chairperson:** Not specified

---

## Agenda Items
1. Review of HSS Pain Points & Upcoming Updates 
2. SAC Master Services Update
3. Compatibility with New Operating Systems
4. Agent Certificate Signing by Huawei
5. Regular Upgrade Schedule for HSS
6. Improvements in Maverick Detection with the New HSS Version
7. EPSGA and HSS Image for ECS Progress
8. Change of Priorities for Energy Cloud Projects
9. Strategy Discussion for OTC Force's Next Level

---

## Discussion Details & Decisions

### 1\. Review of HSS Pain Points & Upcoming Updates
- Sebastian outlined the pain points concerning the Host Security System (HSS), and potential solutions were discussed.
- TiBo noted that signing the agent with Huawei certificates will clarify its origin, which Andy confirmed would show it's published by Huawei.

**Decision:**
- TiBo to sign the HSS agent with Huawei certificates; Andy will verify this action.
  
### 2\. SAC Master Services Update
- The team discussed a priority change where SACMASTER rose from median to medium importance, affecting project planning and resource allocation.

### 3\. Compatibility with New Operating Systems
- Joshua addressed compatibility issues of the system with new operating systems.

**Decision:**
- R&D department will be tasked with ensuring seamless integration between HSS and new OS versions.

### 4\. Agent Certificate Signing by Huawei
- Confirmed as an action item from the first discussion point.

### 5\. Regular Upgrade Schedule for HSS
- The team agreed on a regular upgrade schedule for HSS to enhance system stability and security.
  
**Decision:**
- A formalized upgrade plan will be developed, focusing on systematic improvements without affecting CPVAS availability.

### 6\. Improvements in Maverick Detection with the New HSS Version
- Details about enhancements in threat detection were discussed regarding the new version of HSS.

**Decision:**
- R&D to implement advanced maverick detection features as part of the upcoming release.

### 7\. EPSGA and HSS Image for ECS Progress
- Updates on the progress of integrating HSS with the Energy Cloud System (ECS) were provided, focusing on the EPSGA module.
  
**Decision:**
- A ticket has been cleared to evaluate platform security enhancements without risking CPVAS availability. R&D evaluation in progress.

### 8\. Change of Priorities for Energy Cloud Projects
- Daniel's list from months ago was revisited, noting the surprising change in project priorities. CBH moved to low priority.
  
**Decision:**
- The team will reassess the prioritization criteria and update project roadmaps accordingly.

### 9\. Strategy Discussion for OTC Force's Next Level
- Concerns were raised over the outdated Go To Market (GTO) process, requiring modernization.

**Decision:**
- A strategy to address GTO issues and potentially optimize it will be developed. Answers regarding GTO modernization needs will be gathered from relevant personnel like Alker.

---

## Additional Points & Action Items
- The team encountered miscommunications about project completion dates last year but aims for better coordination this time around.
- P-Wave/Platform-Wave upgrade planning is ongoing, focusing on step-by-step enhancements unrelated to HSS or financial management aspects.
  
**Action Item:**
- T-Boy and the team will provide regular updates on platform security enhancements and risk management strategies.

---

## Follow-Up
- Specific decisions were made regarding SACMASTER priority adjustments, GTO modernization needs, and HSS agent signing by Huawei certificates.
- The team will schedule follow-up meetings for detailed discussions on strategy implementation and project progress. 

Note: This document merges all the meeting parts into one coherent narrative while addressing all unique points discussed during each segment. All attendees contributed to various topics as needed throughout the meetings.

---
./tmp9p3lew4x/安全周例会717.mp4
临时文件夹地址：./tmp9p3lew4x
上传文件的地址：/tmp/gradio/8b2695ae0d526a0d4a681dcd9bb493c59434cf63/20240715_103838.m4a
base name 20240715_103838.m4a
 in German citizens and well this service is running in Yumi it will be shut down in July 2025 and this is why the Kastmann-Aumod wants to move into a new infrastructure and they will prepare a private club so that's the background and yeah so as you can see we will have kind of the set the setup which we envision is that we will have a kind of a z-structure within Frankfurt and then in the year a disaster recovery and yeah everything else maybe you can take a look later at the picture again I would not know all into detail on the specifics but this is what has been aligned from the start I would say so just but for everyone who's not in the picture or was not in the picture and then I brought this overview with me this is now kind of a little bit also an extension of of this scope and the scope overview this is a lap of scope and also the deliverables so this is what has been thoroughly discussed in the last couple of weeks so the configuration for example of the different sites the services this is also for example you can find all of this information even more in the conference we have a conference site so anyone doesn't know it yet just give me send me a message and I will provide it to you because they only saw kind of all the information this has been pretty stable although I think last week it was it they were in some additional requirements which were mentioned from Ryan's skip site with our solution designer and this is what is being shown here in this magenta bubble so except from option this the second point so this option and those are kind of mandatory requirements which have to be incorporated into the configuration and so this was raised last week and from what I understood from you christian you commented in the conference that this is already now incorporated into the configuration from your side as well is this correct yes um that is however um try and put in a required capacity to be obstacles kind of you know we are kind of bound by the increments of a server so we need to you guys need to make sure that or make confirm basically just that's acceptable okay yes uh or if we need to because there is also an alternative let's say but then it will be not meet the 155 it would be less you know if If 155 is the minimum, we need to go to 172. It's all in my head. But that's maybe something we can discuss later on in the configuration. And otherwise, it's not for our big, big audience here. But based on if that's confirmed, we can actually make a price, build material, and you can start with these. Yeah. As he's in the room. Actually, it would be great if we could discuss this. Now, we're in a new session because this is, you will see this later in the game chart. Our current timeline is we have all kinds of things currently going on, like the back-to-back agreements, which we are working on, things like that. But one of the major steps that we are on the critical path is the configuration. So only if we have this available, we are even able to order anything. So this means if we would, for example, get the signature unexpectedly shortly, let's say next week, we could not order anything if we didn't then have already done all the ordering steps. It would be kind of a very important topic to discuss today. Then Ryan, question to you. It's on confidence. We put in the, let's say, new proposed configuration. Because this is, in the end, of course, a matter of budget and money, right? So I mean, more is always good from a capacity perspective, but if you then say, OK, but it's killing our business case, then we have a different situation. But as I said, it's either 150 or it's 172. You ask 155. So we put in 172. Is the 155 a minimum requirement, Ryan, or is that a, let's say, indication? No, it was a requirement. What is on this slide is the minimum requirement that the customer has demanded. So the customer has demanded for production, 465 terabytes, and for DR, 215 terabytes. That is the minimum. And they've reminded us by ignoring the updates as well. No, good. But then we stick with what we put in. And then I would appreciate, from Henrik or from Sasha, confirmation, yeah, this is the configuration. And then we prepare our quote based on that. What you can see is that I've added 12, 15 terabyte racks to bring it, storage shelves to bring it up to the 465 in production, spread equally over the three availability zones. And I've added eight 15 terabyte shelves in DR to bring that up to the 215 terabytes that they require. OK, yeah, yeah, yeah, I think I saw that. You can see it on this slide as well. And I made comment in Confluence. Yeah. Good, we will, as I said, tomorrow morning, or let's say, so end of the day, but probably tomorrow, you will have then the final quote. We will have also the bill of material for third-party hardware based on that. So Jochen can at least get a, you know, he can ask for a budgetary quote, right? Even if it's only for him to start the, as he mentioned it, the shopping cart and the internal process. So would that be included in the back-to-back agreement, then, in a sort that this is relevant and necessary? So Jochen, is this actually something you are working on right now? Yes, yeah, I would say it needs to be in there. So it's always that we have the configuration in there, including everything, business plan and everything. Business plan, configuration, and what I discussed this morning in the preparation meeting we had is that I want in this back-to-back agreement also the usable capacity. Because technical capacity, yeah, I don't want to have that discussion again. So we want to make sure that that's clear. And also double check that with Ryan. Because often the technical capacity that we put in is not necessarily what you can ultimately use. And we had some experience in parts of discussions around that, yeah. What do we, so we provide service, this is what you can use. So that's sellable capacity or something. Yeah. That is at the end. Usable capacity, yes. Yeah, no, good. And we might, as said, we will do an internal review. If there is now a huge discrepancy between, let's say, what we configured and what you requested, we will have to put in some additional, let's say, capacity to make sure that you can actually deliver what you promised. Yeah, so and furthermore, to connect to this back-to-back, does it make sense to have also a sort of, let's say, roadmap planning in there? So this means if we start with a, let's say, specified core component, and then say optional packets for that would be CCE, hopefully, in some point in time, or let's say, feature one, two, or feature three, which then be also able to be deployed at the platform. Yeah, up to you. I mean, you can put in all optional services, but I mean, that is basically what is already in the, I mean, CCE, for example, right? They start with OpenShift now. I don't see them migrate to CCE in two years, do you? So I mean, we can put it in, but we will, I don't think we're gonna agree a price now for service that we will deploy, so that would always be an upgrade to OpenShift. I mean, I do have only the endless stories about this negotiation and internal calculation, in my mind, where we discussed, for example, this container services, Langsley and had debates on that one. So therefore, it probably makes sense to have that as a building block available, sitting at the bench, and once it is relevant, then we can also. Yeah, but I don't think we will be able to put in a price or a kind of, so the question is, I mean, we can, how do you say it? We can put in that this platform can be extended later or something. With services, yeah. Okay. Because we always did it like that, so also. Yes, so you have best practices, and I'm trusting this. Are you written that as the advantages into the proposal already, that we can bring across RDS services, that we can bring across CCE and others, but for the initial ramp up, and they want to go one-to-one on the Kubernetes versions that they have, and all the node versions that they have with full managed service for the existing environment. Future scalability, though, is what we've illustrated by means of the option for the extra six servers that are listed on this slide, and that is where those options could come in relevant. Okay, understood. So from my understanding, Sasha, you're working on that, on, let's say, the specific project agreement? Yeah. What you refer to as the back-to-back? Yeah. Okay, good, now that was another question I had, but it's good to know. Good, okay. Okay. Good, so, this was, although it was weird, those points, I think, and there's also an additional requirement. Maybe we jump just to this side here. Sorry for interruption, but, as Klaus Lieber was speaking, the key assumptions, they are still up to date, right? They are still valid, or is there any major change? We know that you see your own slides, so this is all still valid. It should be the same. The spoiler I took from your last slides, Ryan, so. Yeah, those are up to date. That's one I provided into the proposal as well. Okay. Good. Okay. Good, then. Maybe you should have jumped to this slide, but. Yeah. Yeah, okay. Sorry, I see we have a SRE agreement about 99.95, right? Yeah, actually. Actually, this 99, or technically it's based on the three EU-based. Yes. So from our single EU-based, this is in some cases kind of a two-edged edge. Exactly, so I already told Ryan, so in the offer towards DHL, we took it out. So we said that it's a one AZ OBS with maximum 99.9. Okay. Okay. Sure, sure, nothing else. So Ryan corrected that. So we're on the safe side. Okay, so this, let's see, it's not shown in the. Yeah, let's see, Henrik has the older version of the slides. Oh. Okay. That's. No worries. Read it to you, exactly how it is if you like. OBS is 99.9% based on single AZ, and this reflects to the DR site as single AZ, also 99.9. Okay. Yeah. Yeah, I think that. You don't need to correct it now. I will update the slides after this meeting. So, and then I will share it, of course, everyone here. Invited. Yeah. Yeah. Okay. Then I think there's another topic. Let's just take a quick look at it, and then maybe discuss it a little bit. So what I've understood is there was a meeting, Sasha, you were a part of this meeting, as well as Norbert Ruth from our site, who's dealing with. He's an SDM. SDM. SDM, and there was, it was mentioned or realized that the power DMZ firewalls at max capacity. So we don't have. That was from Sebastian Benner, actually. Sebastian Benner, okay. But maybe you can explain this topic a little bit, because I'm not really experienced with the DMZ firewall. So the DMZ firewall on public OTC site, basically, the market will be, this seems to be full. And if we want to have an additional connection from our backends to the new platforms, we need to, let's say, use the DMZ firewall, and there are no ports available anymore. And this needs to be considered, so that we also expand that one. So that was Sebastian's statement. And is that a question to Huawei, to more specific? Yeah. I don't know how this can be solved, should be solved, if it's just extending it, or having a new model, I don't know. Actually, since last week, Sebastian Benner mentioned about it. Zheng Wei and the SRE team already deployed monitoring of the firewall. I don't know whether we have some data now about the CPU workload, and also logs or memory, all those kinds of things. Yeah, they are under monitoring phase, I suppose. True, yeah. But then monitoring is- As Alex was speaking, I can't even update that. I got the update before I called. That was also the reason why I was a little bit late. So they are still working on this issue with DMZ firewall. It seems to be, if we have data proposed by Huawei to deploy to newer things, it should be solved. So this is the last information which I got. So they are working on it, and it seems to be solved. Okay. That's good. Then I at least put this to the other side. Okay. So, okay. I will give you an update as far as I get the final information that we have enough capacity on that. Okay? Okay. Okay. Okay. Is there, maybe let's jump back to the slide. Is there anything in addition which we have to discuss? I mean the- What I understood is also with regards to our general SLA and redundancy agreement, we see it also in the key assumptions that they will manage their backup and replication processes manually themselves. I understood from the accounting at that time that they are going to manage this based on their ownership documentation. And they have manual processes for that. I understood this is also something that T-Systems is offering to them as a service, right? Yes. So this is nothing that customer doesn't say. No, the customer is here as a managed services organization of T-Systems actually. Exactly. And in that case, I just would like to have some kind of feeling from your side. Is it like they know what they are doing and the service- Sorry, I have never talked to them, and this is not a simple process, right? And if you want to give a high value service and something on that level fails, you know it will be OTC finally. That is- It's always OTC. Exactly. You know how it goes. You remember Thomas Weber in the past, all this topic. Yeah, I don't know. Do you have a feeling about that? Yes, so at least the statement that we got is from was Micke Martini providing the container service and he stated that they're doing it now, let's say in a similar way on the existing platform. So there's nothing automated that is manual backups. And he knows OTC and he stated that he's able to do the same thing on OTC. So that was the statement. I think this we can trust. Yeah, thank you. Good. Thank you. Any other topics regarding the root problems? Because as I said, it's kind of the most important topic. We will have later, by the way, for everyone not aware of that, a network deep dive at, I think it is two or three for one hour. So all the networks topic we can discuss there. So this is mainly, I'm mainly asking for the other resources, right? If there's any other topics anyone wants to mention or if everything is okay, because we need to have this configuration finalized as a kind of from our side. We have some internal stakeholders which will go on vacation and we would really like to have this done as a priority one kind of from our side right now. So there's this call this afternoon and then we have an optional slot tomorrow or is that a security deep dive, right? Tomorrow is a security deep dive, yes. Yeah. I'm looking at my two, my colleagues here. Does everybody have this on his radar and in his calendar? To this afternoon, two o'clock. You are nodding no, but that means in your case that you are not in the invite because it's not like if she, okay. Can you maybe double check to make sure that Thomas Weber is in? Right now, yeah. Yeah. I can forward it. Yeah. The meeting afternoon is not on my calendar. That's interesting. Did you update it with all the people? I didn't saw any people that you sent. No, you invited me first and then I accepted and then no. Oh, okay. The idea is that you would edit, that you would add all the people that I, and for all future meetings, the people that are in the list, in the Excel that I sent you, please add them. Okay, always. Always everyone. Yeah, and people that are, that don't think they are necessary will opt out. I'll just put everybody in and people can decide themselves whether they attend. But typically- Maybe we can review the table of contact. Yeah. If you want, I mean. We have this here. Okay. Here in this. Ah, okay. Yeah. You can put it also to conference, I think. Yeah. Everybody is- This will be put into the conference, of course. I think that I currently have it also still open here so I could just send it to everyone. The question is, is it suitable for everyone then at this time? Excuse me for not- For everything immediately that was, I had- You assumed that I would have done it. Different, yes, exactly. Excuse me for that. So the question is now if this would be still suitable or not. Anybody, any urgent meeting conflicts at two o'clock? Not for me. Good. You know, most people actually in our internal chat set, you can do it two o'clock. So that's why I came back to you. Okay. So just send it out. That's good. Except you, I guess then. Yeah, you and I are both in the same meeting, another meeting, but. The alternative was Friday eight o'clock or tomorrow eight o'clock. No problem. Just for future communication purposes, I think it should be like consistent. Yeah. Absolutely. No, but that's why I said so. Okay. I think this should be everyone except you. You're already invited. So, okay. I will just send it out to everyone. Go forward. And tomorrow this will be at, sorry, 2.30. Since would this be okay? Otherwise we have to postpone. Afternoon, right? Tomorrow. Security. 2.30 and then. So. I don't hear no, so assume yes. Okay, fine. No one's saying no. I'll accept. There we go. Mm-hmm. Okay. Okay. But next time as discussed, I will just always. Yeah. Yeah. Invite everyone and you can decline or accept based on your own judgment. Okay. Easier. Yeah. Good. Then if there's nothing else we have to discuss, regarding the requirements because I didn't hear anyone disagreeing. I think this I will update just after the call, the storage requirements would be discussed as the first item. Then we could proceed to the next point. So. Last chance. Okay. Then we will proceed. So. Project. Kind of important of course. So. From what I understood and we have Alex here in the call with us. Alex, you explain presented this project and this deployment, the deployment stages to us on Friday. So this is a new, not a proposal. It's not finished yet. New process, which is now also adhering to the new tools and the new procedures. And Alexander, we didn't talk about this beforehand, but maybe because you were mainly involved from our side into the alignment of this, maybe you would like to present it? I mean we can. Sadly you have not the latest version. Okay. I just, this is the first I have. You all have the latest version. I just, this is. You all have everything. Starts the beginning in running in the running game mode. Yeah. No, definitely not the last version. So let me share that for you. So then you get the last version. I can do the presentation and this is not coming out only out of my pencils and my brain. This is coming out from you, from Uruguay as well from Ritter-Schweinbäuer, which is also here in the call. So don't. We need to be on the side. So most likely you will come from there. Let me do this quick before. Let me do this quick share. Check, check, check where we are. So here I have the latest version and then I need a confirmation from you if you can see it. If I have shared it. Let's check. So. Let's see. Is everybody able to see the screen? Yeah. Which I'm sharing? Yes. Which one do you see? The wrong one. It's the old model deployments. Yeah. Good now. Now you have the right one, right? Yeah. There you can see this is a 16 step overarching description of how we should deliver in general HCS host stack. So it's very hard to say here how long does every of these part takes due to the fact by his nature, it's a different if we have a deployment of a cloud which contains three availability zones or maybe more than three availability zones with thousands of server compared to that with a single A-set implementation, which may be a handful. So thereby the nature and as well, we also need to consider which kind of services are selected by the customer. So there is a standard way of employment for sure, but there is no standard timeframe. This up front for you as an information. Starting on the top left with the collection of information that you see the first color coding, magenta means it's done by magenta. So by TSI, then you have the second color, which is the SCD design. This is a combine of TSI and Huawei. It's not a must, it's an optional thing. So SCD is tool which comes from Huawei and Huawei is so kind and open to share this with us, not in personal, so they share their access to the tool. So if we can design with them together, then it's a shared approach. And there are also the color coding for completely in blue. Completely in blue means this is the responsibility by Huawei. Here we are closely out or only slightly affected by that. So these are the three color codings and then you see on the bottom right, the green color which should reflect and define a confirmation by having the acceptance by the customer. I accept this, I will not go in every detail to that. I guess you can read it by yourself. First of all, we need to do the collection. So we need to have the information which one of these which later in the location the customer wants to have. So all this needs to come from TSI so we are on first contact. Then we do out of this information, the SCD designs which is alongside the standard sizes which we want to offer the customers XS and X and L and M and so on. So here we are going into detail. We are also having, thanks to Leo again, the information that Huawei is able to provide to the tool which makes the configuration for all of these processes much more easier which also checks all the dependencies if a customer for example selects CCE that you need to collect all the necessary information and so on. So it's pretty pretty awesome tool and I'm curious to learn more of that. It's really cool and thank you again for this kindness role and share this information and please access to that. Out of this SCD design, we are getting our high-level solution design which should then reflect all the technical prerequisites which we need to fulfill as well as the summary of all the information which we have collected within the customer so then we should at least have here then the final validation of the solution within the customer is really that what is in scope and what not. Then the third point is the site survey which means for us these are the information which needed and later on by Urvay for doing the cloud alpha kind of fill up like DC power capacity which we have that DC space, how the rest needs to be organized and so on. Where the location is to have the interconnection there are also information for us they're pretty important because we need to collect here which kind of how many DWDM lines we need, do we need the line encryption and so on so on to connect these data centers so location for each other, these root connections needs to be in place and so on naming by sets all this is close to point three. Then we have final with this third point the contract negotiation phase. After the negotiation phase and customer have decided once have it and we start with the PO, it's the ordering of the hardware. We need to do on our side the complex negotiation how this is look like and the purchase order needs to be filed and then the service by Xfusion needs to be ordered and the switches by Urvay. So this is Urvay, I guess in future we may also need to consider here the third party environment or third party hardware. If the customer for example wants to have dedicated products which are coming with Nvidia graphic cards or something else which is special which is not able to deliver by Xfusion or by Urvay so then we need to integrate it at point four. At the last point, after that we retrieve I guess this will run simultaneously the LED design by Urvay. So this is still in that one. We took more than here, sorry about that. LED design comes from Urvay. We need to be in close connection. I would have a future stage that we are able to do this LED design. Together you have line out really in detail how the LED design and what they need to do for the LED design that's not so easy to achieve to be really honest. This is a huge hassle with a lot of manual labor to establish all of these information and to correct all of these information to combine and validate all of these information. I guess this is also a huge part of it. Then point six is up to us. So this is the hardware installation which is most likely it runs in the data centers of TSI then it's easy for us to steer. If not then we need to steer the third render from the data center location then we need to have a data center administration for the cabinets and so on. Alex? Yeah. Sorry, Christian here. I have a question and that's related to the installation or hardware delivery and ordering part because we need to provide a bit of material for you for the particularly third party hardware. Are you planning to have this hardware shipped to one location and then distributed by your third party that's gonna do the installation, unboxing and the wrecking, et cetera? Or do you plan to have it shipped to each individual location separately because then you would have to have from us a bill of material split into locations if you know what I mean, right? It's a kind of a, it's a very practical logistic thing but if we give you one list and Jochen orders one list then you will have it delivered to one location and you need to sort it yourself, right? Usually we need to have a bill of material which defines the location for arrival. Otherwise it makes no sense due to the fact we need to do the logistics by ourselves which is an additional hurdle to be honest. I would prefer to have a bill of material for each little center location. So yeah, the implementation is a bit unfair. For third party it looks a little bit different because just to mention, if we do need to assemble by ourselves like it's huge service including NDA protocols, then we need to have the shipment to a third party on our side which takes care of this assembly. Then it needs to be shipped to a location like a lab where we can ensure this is working. And after we have ensured this is working, after we have to find a group, then it gets shipped into this center location where it finally needs to settle. No, good, but that's not applicable. I think in this case, but what is, I'm looking at Henrik here, what we need to have also for the Huawei hardware, that we have these three locations with exact address details and four actually, indeed you're right, four locations. And that we have that we use the naming. We had already some, in a previous call we noticed that AZ1 and AZ2, that we have that correct. And that we, yeah, I'm not sure if there's gonna be a kind of contact person that's gonna kind of receive the orders and then kind of check it against what should be delivered, but that is something we need to. And if there is a difference between the things that Huawei is delivering and what Exclusion is delivering, because for Exclusion, I guess, no one will be handling that as much. Who's handling that for the Huawei part, right? Yeah, no, true. Now, yeah, to check what exactly is, because we had it in Switzerland too, sometimes, right, things get either lost or they are not sent. Then the question is where did it get lost, right? So, but good, I think normally your own data center, but also the third parties have a procedure for that to receive incoming goods and to check against what should be delivered and kind of a freight bill to double check that really everything is delivered that was supposed to be delivered. That is a very practical thing, but it's always a pity that we find out that something's missing after, you know, when we're actually unboxing. But the address details, et cetera, need to be clear, also for our team here to make sure that we ship the right stuff to the right location, right? So that's to be done, the coming, or let's make a mark that it's a... It's a valid request, and I guess we should also make it down here in that kickoff, that we definitely need to have a problem for each of the data center location, otherwise we got lost there. Yeah. And you can predict this, this is pretty simple. And you have to know when you have to have this information, right? So for example, Jochen, if he gives the PO to Excusion, he already has to give them that information. Exactly. You can write this after Excusion. Yeah, no. As a matter of fact, it might actually even impact his quote. So I'm really right, we should in any case give Jochen the heads up if he's not here in the call, that he needs to make sure that Excusion understands that we need to deliver to four different locations. So our bill of material also needs to be already split. I'm looking at you, Bchen, we need to make a bill of material in the end from the pricing configuration for every location, you know what I mean? But good, we'll manage that from our side, but good, you need to make sure that we get the correct address details, et cetera. And it's always like there isn't a detail stand for transceivers, for cables. Yeah, yeah. All of that. Yeah. I think that- It's not only the boxes, indeed. The difference for this project is there are two new data centers, right? Because OTC people are very good at managing that in Beer and Magdeburg. This is actually even third party. Yeah, even third party, but they are very good practiced. Yeah. Yeah, so these two new data centers gonna generate challenges, of course. I know each one of them have very well procedure and management people, but is the integration between OTC team and the new team, right? Yeah, I think for that hardware delivery squad gonna be a challenge, and also us. So Jochen is in the building, actually, but still not in another meeting. No, but we will update him. We will update him, that's okay. Good. Thanks, Alex. Sorry to interrupt you, pretty easy. Oh, good, very good. So we were stopped at LED, right? So then next is hardware installation. I was explaining the DC administration, the cabinet and cabling and so on, which needs to be fed out by ourselves. Most likely, all of you know these cables which we need to have, the front cables need to be also upfront ordered because it's not so easy to get them into place. For that here, we are hopefully utilizing this time SkyRoad, SkyStudio and SkyRoad. If you are folks, I guess you know your own solution for the TSI guys, I guess for most of them, are kind of you. So SkyRoad is software which helps us by the deployment of the network devices for the initials, and SkyStudio is for running out the hardware devices, for getting the first things deployed on the nodes that we can invest this multiple times. If we have done this, then there is a huge thing for us which we need to align. This is the SVN remote connection. So SVN remote connection allows who we already need to make access to that environment which also has a standard and a combined approach to the implementation together. Usually, it should be in standard process because we definitely need to define, so there are actually no standard description for that, how the SVN should be implemented as well, how the SVN should be hand-overed because there are kind of, yeah, secure relevant information needs to be shared and so on to have this access to that. If these remote interfaces are already connected so then who we can make use of the environment as we are, we need to ensure that the public network setup is done and the PMC, which is the foundation of all public communication, is established network configuration for standard services and the configuration of the home network needs to be in the setup. Then we are moving ahead to the phase eight or to the step eight. This we can also do together. This is the Huawei pre-operational steps which includes then the hardware alarm checking so if every hardware piece which we got implemented is working sufficiently and we face the issues or something like that, or there are never been fully a collaborative concern, and clearly check needs to be done. Most likely, we will not have that situation in reality what you plan to have. For sure. Then firmware upgrades and so on, you can read that by yourself. I guess it's not so complicated. Then we have the IEAS deployment. There we have learnt in the last week and again, we have here a new tool which is the EDK tool which helps us a little bit make use of mobile automation in that space that we can do the first initial deployment for the standard services on that environment which belongs to IEAS. Then there's the tool. So it should help us and to gain a little bit more speed, a little bit more quick interaction to that. There was we need to set up the pre-storage pools and so on as I've mentioned. And then there's final dot. This is the TSI of rule for the firewall configuration which worries me most because no one has a upfront communication in place here how the communication model should then look like in the end. So this will be definitely a bit into a huge concern because Huawei is usually setting something up which is completely different in expectation than expectation would be half. So therefore it's a huge back and forth, I guess to reach then the point where we accept in the final security concept. So maybe this we also can improve if we set up there a get together between the relevant stakeholders of having the security in mind and the Huawei folks who are setting up the initial firewall configuration. Should you to be done upfront, in our case it's most likely not the case. So therefore this is usually proven. There is on that picture, there are no more yellow stripes in it which means at that point of time we need to cut the SBN connection for Huawei works due to the fact we are here at the point where we in the next step interconnect our back end services like the CloudScope suite which integrates then all the services which we need for operate and maintain. In that case there we have only one CloudScope which is a high-end principle which should be known by everybody. So therefore we are not allowed to have Huawei agents longer in the environment so we can't segregate between these two environments. So if you have access to CloudScope then you can reach everything. Therefore we need to cut this line for SBN sadly. But it's a case. In the step 10 we as I've mentioned, we interconnect the CloudScope suite with all the services coming up on the standard services like CAC or automation and the STR also, CMDB so that we collect all of this information and so on and so on. I guess this is a huge part of our work which we need to adopt. Let's see if we can figure out a solution where people of the SI and Huawei can really work closely together with remote desktop sessions or something like that so that they are able to share all this information because it's then also for the later support within SRE. Highly important that these information are known by these folks which needs to have that. Within the next layer there we have the past deployment. So if you can ensure CloudScope's sufficiently running we have an overview of all the methods which we have implemented. We can reach all the assets. We can address all the methods with stars within the CAC and we also see these by monitoring and we can collect logs that dissolve the CMC and CMNCLS. Then we can start with the past deployment which are the other layer services on the environment like the software which we need to do the implementation. This should be done usually by the squats but we get to know this is kind of difficult because then the upfront plannings and alignments are kind of hard to achieve because squats are running in their daily work. We are trying to establish there something new. We have a concept in mind which belongs to champions like people who are educated for doing the deployment on an HCSO stack which comes out of the squats and if they have to do the implementation of an HCSO then we address them and then they do that by themselves and they do that in the name of the squats. So we try to get their dedicated people announced for all these past services to strengthen a little bit the back and forth communication and alignment procedure which we need to have to place otherwise we would run into the issue that we only able to deploy HCSO stacks alongside our web cycles which is maybe not in the interest for our customers because customer wants to have it. It's the customer wants to have it. If we plan it in the paper. So therefore we also have here new services like EDKAN which is updated sufficiently to the existing version which contains a lot of services to do the deployment with it's also automation approach on MoRe. As well the HCC turnkey solution which I only have seen in a demo. I have never seen that in live to make that also as a statement here. I hope we can get our fingers on the HCC turnkey solution because they are some really, really, really promising that it is of our life for doing this implementation and also including later on the treatment for the services. It's pretty cool tool. I'm really eager to see that in life. If we pass that we have the security deployment or the NDR and RAAF services and so on needs also to do the implementation to that. This is step 12 and also I guess this is one three parts here close together. Then we come to the last part in the implementation. This is the SRE acceptance which we done by Huawei. So the SRE team of Huawei needs to collect all the information and get all the information for us and by the team of deployment which kind of services are deployed, how the network looks like and so on. They need to do some platform checks on their side to ensure the environment is valid. We also need to do that. This is point 14 and the acceptance from our side is the quality assurance UA TV and so on which we need to check from our side. We definitely need to improve here to make sure our robot tests can be handled that fully automated. So we definitely need to heavily invest in that if we want to achieve here deployment cycles which are really on short term. So we are pushing harder that if we get more environments which we need to deploy we definitely need to improve here. On step 15 which is new for most of you, this is security hardening described which includes the deployment of our magenta layer. Magenta layer includes our LWAP configuration means for our agents and consultants that they are able to reach these nodes and logical and physical nodes. They can have an access on that including they can go around themselves higher level privileges like root and if they go around themselves higher level privileges this needs to be locked sufficiently. All this includes the magenta layer and for that we have already automatized process. This needs to be checked. This is valid. All the statuses need to come up. It's in green light that they all reach. If we have that we also need to do the security approvals if we have met there all the security prerequisites which we need to make and then we also need to ensure the final password checks and some passwords I guess also needs to be changed before we handle this for the customer usage. And then we have the final delivery and the alpha testing by the customer and the customer needs to be onboarded. So this is the last step on 16. I hope I do not confuse you too much. I know this was kind of early here. If you have any kind of questions feel free to reach me out there. Thank you Alex for the great overview. Some general thoughts from my side that I have in my mind. I guess if I understand you correctly it's foreseen that how I will not access any kind of physical location. Everything that we basically do in this process is only remotely, right? Exactly, yeah. Okay. And I mean why I'm asking that specifically is that on the way to deliver this project we are also developing kind of like the new HCSO delivery standard for OTC, for OTC private as a product, right? And I think we will have a lot of learnings on the way no doubt and afterwards we can make kind of a review. Okay, does this apply? Is this something that we can in future replicate efficiently, yes or no? Or what do we maybe have to change? I think everybody has that in mind. I just want to make it clear again here. And that's also with regards to the, yeah, let's say end to end process then a matter of time most likely, right? So as you stated, right now we don't have an end to end projection where we say, okay, we are 100% sure we can deliver this in that time. This will be one of the results that we find on the way. Excellent. Yeah. And for those findings, I said we will make a review afterwards. Okay. No more excess. Physically, okay. Yeah, automation tool set is new. You also mentioned that already, that there will be a lot of learning on the way as well. I think that's also clear. Yeah, okay, understood. Thank you, Alex. Leo. There we go. Okay, I have one question to my own colleagues here, Chris Selm here. In previous project, we used this mini cloud scope set up and now we have this automation tool, right? Is there, do you expect, and I'm looking at Leo, Richard, but basically all my colleagues too, is there any other, let's say, development on its way that is not available yet, but that we expect will make our lives even, or not even, a little bit easier. In terms of, I know, look, most of the steps, right, Alex just presented involves, how do you say it, is manual work to the extent that you cannot automate the collection of information, the site survey, and those kinds of things, right? I mean, that will take what it takes. But is there, as far as you know, anything with regards to HCSL as a product that will make it even, let's say, faster and easier to deploy or to maintain that you are aware of? Yes, actually, from two years we delivered this cloud, actually this is almost the same procedure of three clouds, but in three clouds we used mini scope, a depotting in the on-premise, and we do the physical service delivery. From this two years development, RD already, RD actually implemented the mini scope cloud function. In two years before we used EDK software from closed scope, currently we use offline EDK tool. You can see in the Svn remote last, as it deployed, we used offline EDK tools. Actually, these tools can automatically deliver a big, a physical platform, include 3AZ deployment and active transformation. Also work to be done. But actually, from this point, we are delivering efficiency is almost the same as with cloud. Yeah, yeah. We may have a intensive mode progress for delivery efficiency is like Huawei to for remote connection for more long time. For example, currently our Svn remote is stopped before to connect to closed scope. I think we can have some space that Huawei still can connect to the regions, but not closed scope for a long time, like until the security delivery or Huawei acceptance. At that time, for remote closed scope, still owner by TSI side. Huawei R&D can still log in remote from the regions. Region level, region is on delivery status. Yeah. We have some bugs or some defects need to resolve. If R&D can directly connect to the regions, we can have higher efficiency to solve the issues. Okay. The delivery will be more. Which is obviously probably from security a challenge, but it's good to know, right? That we may think in the future or discuss it at all. Yeah, we have the security data actually, so we can bring it up there. Yeah. We also have Alexander Simmons from security here right now. So I don't know if you can. Yeah. It's probably a topic which we have to discuss in lots of detail, right? I would suggest to do that. But furthermore, Leo, from a product perspective, there is nothing currently in China being, let's say developed that. Because Thomas said, right? We are trying to kind of make a standard delivery process from this based on this. But if we then know, for example, something else is coming in six months, that will change again our reality, then we better know now, then we can take that into consideration. That's why I'm asking. Right? If you're saying, okay, now this is what it is from a software and tooling perspective, then this is what it is. And there's obviously in every step, probably room for optimization. That's good to know. Let's see where we can get that. But not in terms of tooling or methodology. We're not gonna ship this in a box with software, for example, already pre-installed. Compared to two years before, actually already do many improvements on the automated tools. That's not what I'm asking. It's more that we, but I think you answered the question. It's more that we should know if there's something on its way then we better know. But if not, then we work, this is our base assumption. We can see that in midterm, it will be like this. But of course the function of each tool will keep improving. For example, EDK, EDK, yeah. But the methodology will maintain like this in a short or midterm, long term, we cannot see. Yeah. And also one thing, one comment from my side is you can see that we have like three test period. Yeah. So we need to, from this project to discuss and learn how we either we do that in parallel or we can standardize what we did there. And to make sure these three test phases will not delay our project. And most important, more important is make it doable in the future for more deals, right? Yeah. May I ask a question more in a general sense? So comparing what Alex outlined as sort of master plan, where are the main differences when we look at the retrospective of Swiss OTC in the setup phase? Is it in principle more or less the same philosophy we are tackling or is it, are there some significant changes to how we roll out that service? That's what Leo just outlined. Yeah. The physical differences from is a step number. In Swiss Cloud Step 9, we build a mini-cloud scope to deploy the S service, IAS service. From currently, we have a automatic tool, offline, DK2 can deploy it. So we don't need a mini-cloud scope anymore. That's a... But we did that already in Swiss OTC. No, we build on a separate cloud scope. Swiss OTC is a very big tool. Basically, and that was a kind of a bit of an overkill basically to build a tool that we needed to do the installation and then we took it down again, if you know what I mean. And now there is a simpler tool so that makes it, that part of it is a bit more efficient. Deploying your laptop. So from your laptop, you can deploy the ISE platform now. So that is only essentially reducing Step 9? That is a tremendous improvement, right? Sorry. The others like EDKM is also improvement for the tool. Yeah, in the Swiss OTC phase, the deployment was done by cloud scope with manually deploy activities. EDKM can orchestrate some of the jobs. Yeah. And then another thing... And then another solution for OTC in principle, right? Yeah, and also one thing I would like to point out is with Swiss OTC, we have... We can see that we already have a baseline in the software point of view, right? So our new delivery will be based on Swiss OTC version or one version ahead of that, right? So it's not a brand new thing to post TSI. Maybe also to comment that, guys, don't get me said, it's not a comparable situation which we have with Swiss OTC. It's completely different, yeah? So OTC was not in that shape to deliver the right baseline configuration for that. We do not have a dedicated tool for that. We have no pre-checkups and so on and so on. So it's not comparable at all. But the questions which you are asking are totally valid. The question is how we can improve from a standard perspective, yeah, from the general approach to get things simpler, faster, and efficient deploy. There you are looking, out of my perspective, to the wrong positions. This PRS deployment for step nine, it's not that what takes so much time and where you can squeeze out so many, oh, sorry. Do you see this again? Yeah, yeah, yeah. There you will not make, if you improve here, you will not squeeze out weeks or months or something. Where you really can't squeeze is here, 11. If you have this delivery really sufficient, there you can achieve a huge improvement. And then everything which comes later on, like here, the UAT testing, there you can squeeze out really, yeah, 30 and 40. There you can generate a lot of time. This 15 is close to, yeah, I don't know. This is fully automatized, yeah? There you can't achieve anything more. If we are not moving away from our standards, I guess it can be deployed completely automatized, yeah? And then the checks also run completely automatized. If you have not so many common cases, it's running really smooth. So it maybe takes a couple of days. I don't expect too much things like that. So here on 13 and 14, you can squeeze and 11, yeah? This, these are the points where you really can generate improvements. Nine, eight, hardware alarms. You need to check all the environment, right? If the hardware is not running as you expected, if the memory is not showing up in the right amount, then you have an issue with hardware. You need to run the data center, you need to check. It will take time. There you can't squeeze. This depends on the cases which you need to handle. Yeah. Yeah? There you will not squeeze anything out, yeah? If you are lucky, then all the hardware shows up as you want to have it. As not, if you're not lucky, that can add a lot of balance on. It's the case, and then it takes time. So here you can't really improve. If this is really running so smooth as we have designed it here, you will see a huge improvement. Yeah, absolutely. And this one, I think this one you correct, like the hardware, because that's why we also put the Skylo, Sky Studio tool, and what hardware issue, like that. This one, if the tool, because it's ongoing POC, so that's why we will rush to do the tool tool tool tools. Okay? What? This one? Yeah, but we need the coordination. I asked Xiao Du, they told the guy in charge of the project is on leave. He will probably come back this week, so I will continue with the guy. The Skylo, Sky Studio, for the POC. Also one question, for the year of I, mid to moon, this span is three months. It's hard to understand. Mid to moon, three months, hardware viewing. In English. So does it mean if I start, we have hardware to be all known, the hardware will be on October, mid to October? Why? His question is about the hardware delivery. I think it's not, I mean, it's not a real case now. It's an estimation, yeah. It's estimation, it's a general approach here. And this is made for that, sorry, this is not made for that special dedicated project. This is a general overview how HCSO models should be delivered. This is the reason why I don't have. This is some P3 imported land, so it's not for that project. By the way, this guy is our PM from Huawei side. So, Zhang Songlin, yeah. He will be. And what is important to know, Songlin, is that this three months estimation includes the internal processes and approvals that are needed in order to get an order out. So it's not after, let's say the order is placed with the vendor, but this includes, let's say, the internal process that we need, particularly on the third party hardware. There's some additional steps that we need to take. And even in Huawei, I know we also need approvals. So that's why we assume the three months. We hope that both hardware, Huawei hardware, sorry, and the third party hardware, deliver faster than three months, but we know that we need some weeks to get the approvals out. How does this comply into the whole project planning? So if you're doing a forward and a backward calculation, do we meet somewhere in between or how would that happen? Yeah, is it June next year or is it December or something in between? Huh, we need to think about it. I mean, we could take a look, if I can share my screen. I'll show you a good slide. Sure. Sorry, this is also what I want to show you. So I wrote down all the steps. I did not put any time into the steps. They are all one day. So you can see like if I open up this here, it's all one day because we don't have, as it was already mentioned a couple of times, yet no estimation for that. But even then you can see we got done in the beginning of December probably. So this is everything here is linked. This also includes currently the discussions so the back-to-back agreements and the dependencies of all the tasks, right, to each other. And this is what I want to use also now in the next couple of weeks. I would appreciate if we can maybe forecast more and more steps in terms of time duration because this will be during especially this project, kind of critical because we have, as you have seen this requirement, okay, the middle of next year, the entire data center will be shut down. We have to be, it's not finally aligned internally with the account and everything, but we will have a very tight timeline. This is why it will be very important to get to know all the steps, discuss them, and forecasts will be extremely important in this project in specific. I'm not, it's of course always a little bit difficult, but we should do our best to come to a kind of realistic outlook on how long this timeline will take. But as you can see, the steps at least here for the hardware purchase order, I think this up until here, it's kind of already a little bit realistic timeline. We don't know how, of course, how long this will take to deliver, but this is based on all the price steps. So you can see, we kind of expect right now, this can always change, it's all subject to change, but we expect the DHI contract to be signed on end of this month. So from what I've heard, this latest data, we will see what actually happens, right? And all the other steps also includes what we are currently doing, the technical scoping, we will have the security appointment tomorrow, right? We will have to do the back-to-back agreement. This is mandatory to even order anything, right? And in here, you can see internally, I wrote down all the steps. So this is not too interesting for you, of course, but also, for example, this step here, which we just discussed during the meeting, we have to provide details on where everything will be delivered to you, right? So this included in here, so that everything is being taken care of. I think this has incorrect predecessor. Okay, correct. Good. I know in some other projects, we actually consider to give your internal customer access before, let's say, the platform needs to be, let's say, ready 90%, right? Of the testing cases and bug fixing, et cetera. But there is a point where you can say, okay, internal managed services colleagues, you can maybe start deploying your, right? Get yourself ready and stuff like that. Now, yeah, okay, give them access without this lay, for example, for one or two months, while we are still fixing the last things, right? But that they can, for example, really start building up there. Or as such, we discussed, for example, right, that they would use public OTC to set up their environment and then to, let's say, copy and move it onto the public OTC so that they can win some time in the overall planning. So maybe you can integrate into your planning some milestones, which, let's say, incorporates then some external touch points in the sense of, okay, this is a milestone where you have first access to prepare yourself. Like Christian mentioned, this is a milestone where we, for example, need also your support and your feedback, and that is a milestone where acceptance of UAT starts, and that is an acceptance where we then have also SLA on board and stuff like that. So maybe we have this sort of decision points also transparently to be shown up in the overarching project to give the others the confidence and to align on the project plannings there because the managed service on top will also take additional time, right? Yes. Exactly. You're right, but this is a dangerous move which we then make because imagine, you have something on the platform which is the final check, right? And then this squad maybe needs to work on, you know, to get that in the chain which is acceptable for the customer. Exactly, if you read the customer already play with the service, most likely, yeah? The customer may create an incident and a ticket to the site. I will not, I am not talking about the customer. I'm talking about our internal managed service groups, Alex, because they need also to ship their service then towards the customer, and I would strongly vote against. Yeah, I would strongly vote against the customer. Let me put the explanation why it's dangerous. I don't say you can't do it, yeah? But it's really dangerous. Imagine the following situation. You have implemented everything but you're still facing issues. Then you let the managed service folks run to that environment and let's test them. Then they are trying to do implementation on their services. Then they stumble across exactly to that issue which you need to handle by yourself. There you are not ready. Then they will create a ticket. Then they will ask for help. Then they try to reach out and approach these squads. And then you address the same people, which are responsible for the update on the service within the issue which got created by the managed service guys. No, I fully see the risk, and I'm not saying we should do this before we have fixed the critical issues. But I remember from, for example, the case with Switzerland, we had at some point, we had the platform, let's say, it was not made available because there were some pending issues with documentation, for example, where there was actually, it was not like there was no documentation. But then there were some questions about certain things that need to be changed in documentation. I mean, those things, right? The platform is technically stable and approved by you guys, right? So we cannot make any call on that. I'm only looking for where can we optimize, right, in the overall planning if the hard deadline is summer next year when Munich closes down, that we optimize, right, that we consider this as an option. And again, right, up to you. When you think, you know, it should definitely be technically stable, right? You don't want them to have the first experience with the platform with all kinds of issues. That will not give them confidence either. So, but it's good. That's for later. I think that's the event of my side, which would mean you should not ship the software without the proper documentation, okay? This is the official version. Yeah, and the inofficial version, you're right, yeah? You will not be running deployments on that environment by having not the right documentation on that, yeah? Yeah. This is. And I think it's important to reality, the OpenShift people specifically do ask to be able to start to create their image from which they will create the rest of the Kubernetes environments, you know, following on. So they would like as much lead time as possible to create. Because the demanded date was already 1st of November. We know that's not achievable, but they are under supreme pressure to be prepared to bring the customer applications across once they have the Kubernetes environments stable. Yeah, they need to have a dedicated radar, right? And they need to have proper software packaging for reaching out their satellites to do the implementation of OpenShift. I know it's a lot of work, because especially foundation work for OpenShift is kind of, yeah, complex and hard to achieve. But try to make that possible as soon as possible, yeah? So what should I say? For sure. As far as they can have an environment which they can deal with, they will get it. Internally, I'm not afraid here to risk here the customer satisfaction, so therefore. Yeah. All right, good. We will keep it in the back of our mind, right? And discuss it, maybe you guys can take it to your internal customer. Yeah, right. That's what I'm doing, kind of. Yeah. I know. This is giving me a little bit of a headache, because yeah, there's a lot of steps after we are finished. Yeah. So we have to really, yeah, trim it down as much as possible, get it done as fast as possible. When do you want to go? Do you want to go through these steps now to see what days or what do you need in terms of input from Google? Yeah. So, oh, did you just want to say something? No, okay. So I think since we have 40 minutes, I think, right, if I'm not mistaken, we have 40 minutes, yeah, 40 minutes left to discuss. So I honestly, looking at the topics we want to discuss, there's only the organization and way forward left, so we could actually take the time now. This is the core of the... Exactly. And I think this would be a good thing to do right now. Yeah, let's do it. Let's just go through the steps and see how we will organize ourselves. Maybe also, and this is one of my questions, which I want to raise, what we should do during the time where we wait for the hardware, right? What do we have to prepare? Who has to align with whom? Who has to get to know what? So that we actually can a little bit also pre-plan so that we are able to do all the steps as soon as the hardware arrives fast and with high efficiency effectiveness, yeah. Okay. Then... Step one. Yeah, let's go through the topics. So I think the top and most topics, so design, turn alignments is nothing really interesting. This is just internal processes, nothing which impacts us. Technical scoping and delivery planning is really just the workshops. Like we had in the AZ selection, it's a sort of discussion, right? Because the naming scheme is kind of a little bit strange. Reversed, we have the security details. So this is just what we are currently doing, right? It's just put in a timeline. And we have some dependencies like the network deep dive, which we need before we can even do any network ordering. We have to first discuss with Martin Schenk. Alexander, this is what you said, right? You will organize an appointment. I think I wrote this down. Alexander, now let's hear it. So organize with Martin Schenk. This is really important to do because the customer wants to have a reduced network concept. He wants to interconnect his firewalls directly to our outer routers, which I didn't want to have because I want to have our standard approach implemented. The customer, I guess, believes it simplifies the ways of communication, which is definitely not the case. Yeah, so we need to align that with us and the customer. It just needs to be done by Martin and me. And sorry, I have yet no standing for him for this topic. It is the case. But is this a call with Martin and us already set up for the 22nd? This is what you took with your safe addicts. If I understood you last time correctly, this is why I wrote it down here. So you want to take care of that? Or should I take care of that? Should I organize something? I have not set out the appointment. If you can, it would be nice. Otherwise, I definitely would forget this. If I mess it up. So, okay, cool. Okay. Yeah, and with... Alex? You need to define before with the customer, before we go to worldwide to negotiate or to design, right? So if the customer's not accepting our approach, then it makes no sense to run with you in circles. In the end of the day, the customer decides. Right, so... But that means that you need to have a conversation with the customer on the 22nd first? Yes. Yes. Okay, let's write this down. Exchange with DHL. As soon as possible, we need to get to the customer and to their dedicated network folks, and we need them to explain why we have this additional layer between these endpoints, because it makes sense. And if they understand the concept, if they are really networking guys, I guess they will love the reason why we want to have them. If you look only to the paper, if you only look to the network for policy, you think that's the good misleading. You think this is an additional layer which you can get rid of, because it's complicated. It's not the case. It's not a complicated thing, it's simplified things. But you need to understand the concept, and it's not easy to understand. I have my approaches to reach them out. Alex, how would this impact... Would this only impact the Huawei equipment? So... Okay, not the third party. How many impacts the Huawei equipment? These are four switches. What are the differences? And are they foreseen? I'm asking probably the wrong person. I'm looking at Leo. So they are in the current configuration, they are included. So... No. Net... They are not included. So they need to be added, is your statement. Okay. So in the first run, we had that in, and the customer wants to get rid of them. And then we had the second version, which is not including them. So, and by this decision, I was not aware of that, that we really need to make sure that they are there. And then Martin reminds us that, hey Alex, if we get rid of this, and he explains why they are so important, and said, okay, this would be good if we can discuss this with the customer, but he's still on vacation for this week. And next week, if he's back, then we all immediately go to the customer and try to convince them to get them back. Yeah. And then we... Let's go back to our original... So, but if I understand you correct, you basically, your aim will be to convince the customer to accept these four additional devices. And so we shall assume in our design for the platform, these four additional devices. Is this four additional devices for... That is for each AZ, right? One device, correct? Exactly. Okay. And then I should just, we gonna add it to our configuration, and we assume it included. And then we... I mean, we will probably not put out the hardware order ourselves before the final goal anyway, but that we do this, let's say in parallel, and that we assume it included, because the chances are, it's more likely that you will convince them, than that they will convince you to leave them out. If I... And I have spoken, honestly, because I never have spoken to these guys and left it for the customer. I do not know if they are convincing at all. No, but I know, Alexander, you will be hard to convince to leave them out, right? So... So I'm counting on you to convince them. Can't be better, yeah? I'm always the best object. No, I tried to do my best, because I want to have the customer experience and the best change, if I'm able to deliver, right? So if I have really good documents, I guess I'm able to convince them. Yeah. Could be the case that these network folks are staying with their approach, but they are also highly satisfied by that. And then, honestly said, you only can help people who are willing to let you help, right? And if this is the case, then we have this now. So I mean, we are able to deal with, but it would be much more comfortable for us, if we can, if we can. Hold on please, then. Bichan wants to say something. Sorry, what four device was missing? Which device? Can you mention or name the devices that you refer to here? I have not these devices by me, but how I can figure it out. I have it somewhere in my conversations with him, not him. No, yeah, it's maybe, sorry, let's discuss it. You can, let's discuss it this afternoon on this network deep dive, to make sure, because Bichan is actually in our team responsible for, let's say, he's doing the configuration of, and in the configuration tool and the hardware bill of material. So we need to make sure, Bichan, that you this afternoon know which devices we are talking about here, and that they are then included in our, and double check whether they were not maybe already in, because I don't know what Alex has in terms of last version of the configuration, but double check that and make sure that they're in, so that we base our bill of material and also the pricing on that. Right? Thanks. Maybe just one question. I think I have a misunderstanding. The exchange with DHL, with the network guys from DHL, we want to do this together with Martin Schenk, already before Martin Schenk returns from vacation. But this idea to have the support by Martin Schenk, yeah. Okay, okay. Then this is... But maybe you can organize to reach out to the DPDHL team already before you have an appointment with these people in all the daytime. Absolutely. Just want to clarify. We're the only one with a five minute break, can we do that also maybe for the people there? Yeah. Okay, then. This afternoon, Martin, we're joining, right? No. Alex will be there. Okay. Okay, so Christian just proposed a five minute break. I would say let's do this, if everyone's found that, and then we can continue with the following topics, okay? Yeah. All right. You're back at five past 12. Yeah. Five past 12. Okay. Okay. Yeah, I know you missed the part but you were the one... Thanks. I know that I can't even touch with this... Yeah, that was too short. I don't know, happy to tell you about these kind of things. Actually, it's a rotten jar and it's in copy box. I like the fluffiness. This one is a little bit more elastic. It's a little bit more fluffy. I like the fluffiness. We're just passing it out. It's a bit tough to process. It's a bit tough to put it in. I just put it in. I'm not sure if it's going to work. It's just a little bit less. I'm not sure if it's going to work. It's just a little bit more elastic. You guys, you can see it. I tried it yesterday. I had it a couple weeks ago. But it's more secure. It is more of the same. It has different textures. Maybe for each item, maybe we can do more things. I mean, based on yours, maybe you can do more things. I mean, based on yours, maybe you can do more things. I mean, I would have to share the time we spent because we from the outside. We just wanted to say that. I would have to watch what we were doing. So, I'm going to try this again. That's exactly what I'm going to try. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. I'm going to try this again. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. So, we're using the same language as before. You're a station manager. You're a station manager. Yeah, the first time being here. I'm very proud. I mean, they... I'm very proud. They're very happy. They're very happy. I'm proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. I'm very proud. Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Do you actually want to... Are those status quo events already? We kind of.. We kind of... We kind of... We kind of... I think double check fair buddy. Now another day's sure wasted. And they start behaving like I should do something. I'm not sure if it's the same thing as the other one. It's not the same. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. It's the same thing. Yeah, he's occupying all the seats. Sorry, let me... No, no, at least you have been in the big cities. One of the cities. Listen. What was it like? Yeah, well, we just debated. It's a matter to the last program. I'm happy and I was expected. And I was happy that Spain won yesterday. And all the big guys, they did deserve it. Yeah, yeah. Spain was actually the best thing, so I think... Yeah, I think it is. I think it's like the Germans hit the floor. Yeah. And overall, I think... I think we did a good job. It was too much to the Germans. And that was a good program for Europe. The Germans hit, but also the Dutch... The Germans were really pressing in Europe. Yeah, yeah. For a successful... Yeah, yeah, it was. I thought it was a joke. I thought it was a joke. I'm sorry. It was a joke. It's nice that you made it. It was very nice. We're in the room, right? Yeah. And now, so now next we have... Sorry, we'll go continue. Then we have everybody? Okay. All right. Then we can continue. Okay, a little bit more break. I can give you an update if you want. I want to... What has changed? Okay. We already have an update. Good. Perfect. We already have an update. We are from Delivery. You're always fast, right? Yeah. So first, why do you want to have that? I'll give you one example for that. Usually the customer wants to direct, connect his firewalls to our call switches. Usually you have a break out of these firewalls, which is no bigger than 10G, which is usually the case. This would mean for us in our calls we have hard limitings these interfaces because 10G is nothing for us. So therefore, we are recommending that. Then all the traffic, to give a second... I have a couple of points. I will discuss this with the network folks. The recommended switch and how much we want to have. The recommended switch is CE6850-48S6U... Do you recognize this? Max. I can also type in chat if you need. Yeah, please chat. I don't need to type in chat. Okay, and of these we need one per ASET, which means in total six, not three. It's not a very cheap model, right? We usually use very good hardware. Always. Because it's much more cheaper to use the right hardware instead of having cheap hardware. And an incident. Yeah. And deal with issues. But Thomas, I guess, he will hire this product, right? As always. Thomas is not paying this anyway, so... He doesn't care. I have very deep pockets, and I don't want other people's money. So I type now, and it should be okay from there. Good. I see that. And this one page. And this one ASET. We should, well, we... Sasha will then also include this back to back, right? If we assume that it's in the config. Okay. Okay. So... Yeah. Okay. Good. Thanks, Alex, for digging this up. And... Yeah. I think this will... Any remarks on that? Any additional? I put in, I don't know when we will have this point, but absolutely when... So Martin will return on the second of July, so I plan to, yeah, schedule a meeting during this week, however the availability is, right? But the working assumption will be, right, that we include them, Alex. You know, we can always take them out, if you know what I mean. Could you repeat that I have a really hard connection today? I don't know why. The working assumption will be that we include them, and we can always take them out. So that we... If we are lucky, then we can convince the customer, then we have that expert. Yeah, there is... So, Alex, I know that you are not having a commercial discussion with the customer, but there might be, and I will share that with Sasha, so there might be, obviously, right, for the overall project, a cost impact, right? So I know there has been communication with the customer, let's say, on an overall, let's say, project price, and the service, right? In the original conversation where we aligned on prices with Jinju and Olof Veins was involved as well, I need to check whether they were included, if not. If they were not included, I will have to add them, like the additional storage, so we will have a revised price. So that's something to consider. But that's... I will ask Sasha to discuss that with the project team from DHL then. But just so you know, there is, obviously, right? I mean, maybe it's only in my mind, but this is like two serious cost blocks, right? The switches and the storage part, they will add up significantly, I assume. Yeah, good, but I will just... you'll have that tomorrow. Okay. Any other remarks? Okay. So I will organize with the DHL team so that we can then have this deep dive. Good. Okay, next, I mean, technical scoping, we don't work on it, we already had this. Security, we have tomorrow. I already mentioned that before. Then back-to-back agreement, this is a topic we actually planned today to talk about the browser, but me and my other side have to currently discuss it a little bit more internally. I suggested to have it on Wednesday. Yeah, if... So the back-to-back agreement is going to be what we call project-specific agreement, whatever, right? For two, three, whatever pages, we need to outline everything that is either extra or deviating from what we have already agreed. As we did before, also, for the other projects. Yeah, it's interesting because I looked... Yeah, no, but also in terms of form, because for Ö-MEDSAP, there was never a project-specific agreement that was done based on an email exchange, interesting, about conditions. And in Switzerland, we had a contract of adherence. And that I think is a little bit more extended, right? Here we are contracting Germany to Germany, which makes it a little bit simpler. But good. I don't think we need to reorganize a separate stream for that. I will do that, and Jiang Yuan will help me during my absence to kind of streamline that on our side. But I think, you know, initially, it's mainly agreeing on the content, what needs to be, right? Building the blogs that need to be in there. And then the T's and C's, basically. But... Yeah. Is that on the critical path? Yeah, I mean, of course, we would like to have something signed, or at least agreed. Yeah, I hope that we can also for you, I guess, right? So, I'm going to have first drafts or suggestions from outside this week. So, you can also have a look at it. Hopefully. And then, yeah, we can see what's missing or what needs to be. That would include also the business plan, right? Yes. That's obviously for us one of the most important things that we have a kind of a foundation for the revenue share enforcing. So... Yeah, I think, Sascha, I mean, Wednesday we have a call that is Raaki. Yes. Or let's say, sorry, we have a call that is our weekly call, which I think we discussed in our group, but it's quite a wide audience. I would suggest not to discuss the document there. But I would prefer to have a conversation with you, even if it's only what you have now on Wednesday or something, because I will be leaving on Thursday. I will take my laptop with me on holiday, but I prefer not to work too much on this agreement there. Okay. Yeah. No, and I also think, you know, it's not that I don't want to hand off things, but for Jaayuan it will be quite difficult to judge the content, right, and whether this makes sense or not. Yeah. I would say... It's the process, but not... Yeah, please. Thanks. Good. And I will loop him in then, so that he can actually listen along and understand it. So we will set up a meeting with him, and then it would be nice if we could do that somewhere on Wednesday morning, because he is trying not to. Yeah. What would you expect when the RASI, the back-to-back agreement... Do you think end of next week is realistic, or do we need even longer? Because on this depends the hardware or the ring. Yeah. And the other way around, you need to have a signed agreement with your customer, because... Yes, always needs to happen. Yeah, this is a nice... Yeah, from my side it's fine. The question is always, right, at some point we will need all of the hints in this conversation. We will need our legal guys to review, and they sometimes take one or two days more than we do. But I think we should strive to have that finished before... Yeah, that's way... Before it all starts, let me put it that way. That's okay. Okay, I'll leave it at very first at latest. Good. Then we have this, yeah, collection of information, SCT design site survey, right? I don't know when this has to be done. I don't know if it's pre-req... What is this called? Pre-requisite? Pre-deces... Pre-decesive, whoops. Pre-requisite of the requirements, or something like that. Pre-requisite of the requirements, then the SCT design is based on that to give you the final bill here. So this all has already happened? No. Your previous activity B2B agreement, based on that, you're going to have all the B2B material things, right? So that means this one should be included in the B2B agreement phase. The SCT design, at least. This at least. Because this is the step that to output the B2B material. So I put it to the back of the B2B agreement. Yeah, should be there. And this is, but this is not already done, right? So it's a task open. That should be finished this week. Yeah, depending on the requirement, right? Only if there is a requirement, then that one can be done. However, then I assume that there will be no surprise anymore from the contract conversations with DPDHL, but that's... We don't know. Excuse me, what about the agreement which you asked for at the acceptance? You need to discuss this one. Acceptance of whom? The acceptance criteria. Criteria. You mean? You mean the acceptance criteria, right? Yeah, correct. Otherwise, how big is the acceptance criteria? That's a good point, but, Holger, maybe also from your side, right? So there is, of course, the back-to-back agreement could have acceptance criteria, but we never did... We, for Swiss OTC, we actually tried to avoid a customer acceptance. But that's the end customer acceptance, right? That was SBB or T-System Switzerland, actually, that had to... Right? Because we deliver a service, and the service, that's the concept, at least, the thinking. So that a service is ready when it's ready. We say it's ready, this is the service, and it meets these criteria, and then, yeah, is there an acceptance? But I think from a project management perspective, I understand you want to round off at some point, right? Say, okay, this is end of the project, and now it goes over to SRE, and it's operational. But this is... I think we have that in the end. So what Alex presented in the last exciting point, there was the Ro-Ve acceptance with SRE and the T-Systems acceptance. And then we move over to operations. There is no additional acceptance by DHA. No. Exactly. So it must also not be the reason that there is a dedicated acceptance for the cloud platform, because what we are selling towards the customer is a higher level service, so, and therefore, for sure, there must be an acceptance there. However, the underlying infrastructure, that's fully to us. Yes. So we should include a milestone on that one, as a sort of, let's say, internal acceptance, but not reaching out towards customer. You have multiple milestones, Volker. You can open these this way, which I have presented. For example, you have here pre-operational hardware alarms. It's eight. This is a milestone, because there you ensure that you have no longer hardware failures. This is a huge milestone. Yes, so I'm talking about more the acceptance towards the usage of the platform itself. So maybe it's a good idea to connect that more or less to UAT or something like that, or QA. Yeah, then it would be, yeah, you're right. Then it's point 13 and 14. It's like SOP acceptance and TSI acceptance. Then we have security hardening, which is also ending with the acceptance. Okay, so just to make this a little bit more visual, where would we put this? So if I now let me hide those. So where would we put the milestone? Just so that I understand it correctly. Where would this be after? Is this correct now or not? Yes. Okay. And after security hardening, there's also a milestone, because without the security hardening, we can't handle this to the customer. Not possible. Okay. So we would call this milestone after security hardening. How would we call this? It's not the same name probably, right? No, security. Security milestone is a spin. Security milestone or something like this. Maybe Alexander, you have a good idea from security. How usually you call it if security says the final yes, you're allowed to make use of this. Maybe in other words, just the improvement, security improvement. Improvement, sorry. Security improvement. Okay. Okay. Good. I added this one. Okay. Sorry, Ritesh. Yeah, we don't get your Ritesh. It's hard to understand. Okay. And I'm very Okay, I'll try to read the text. Now it's better. Now it's better. Now it's better? Okay. Yeah, now it's perfect. Yeah, so we wrote SRD acceptance and acceptance and SRD and TSI acceptance. So the first SRD acceptance is Huawei. So maybe you should read it not to confuse it. And the second acceptance is from TSI. And this includes our SRE, our quality, our UAD and UASR. Okay, okay, okay. Yeah, I think we have to detail all those steps now further and further, sorry. You only need to cut the end symbol. This is TSI or TSI SRE acceptance. This includes the quality assurance UAD. So like that? Is this correct? Yes. Okay. Yes. Alright. This was what you meant, right? Yeah, but we generally don't have a SRE. No, we don't have a SRE. We have a SRE that will be enough for a group of staff. Okay, excuse me. It's a little bit too much at the same time. You are not who she's asking. You basically asked you to remove the SRE again because T-Systems doesn't have SRE. SRE is a Huawei organization. Right, Ritesh? Good. Alright. I think we understand all what we mean here. Okay, so that's the right, but indeed the B2B agreement should have deliverables, which is, we will do our best to describe it properly. So I think we should from either... You should also give the milestones some sort of numbers, basically, to reference to that one, that helps later on in communication. That's correct. I will put this in, but maybe not right now because I cannot, I would have to create a specific column for that, which automatically then numbers them, so I will just set up a task. This has to be done by me, okay. Good. So also, by the way, what I would propose just overall, before we even go further now in the discussion, with the discussion, that we on both sides try to I will share this with you from worldwide, of course, in our conference, that we from both sides try to assure that all the steps, the necessary steps, are included in this plan, because we don't want to miss any kind of steps. Yes. No, but good. Let's use our Wednesday calls to go through this every week at least, and if needed, we need to get to the organization point later. Exactly. Okay, the column resources here means the responsible party, right? And do you think it's necessary we add another column with the names of the responsible persons? So we can either add a new column entirely, which will be called personnel resource, or we just one by one replace it actually with names. So here's this resource chart, right? This is how it's structured, and we can just add new resources here, like people, and I would actually think it would make more sense to have Huawei as a resource, like to just describe overall the steps, and then we can just also additionally always add new, additionally specified people, right? So they can show you if I go to resource from anything, I can select, and I can also, for example, I already put myself in, select myself. We can just add people. Yeah, because Henrik can only share a kind of screenshot from this in Confluence. You can not give us access, let's say, to the MS project. Oh, I can. Why not? Confluence, I think you will not then you will have to go to and we hardly actually use. I can't put the file here. I think it's just to make sure that we don't work at the same time. Exactly. I suggest you keep it, and we provide people, yeah. Then we have one source of truth. That's okay. Yes, at the end must be only one, maintained by Henrik, and I think this chart will be used weekly or daily by you and our PM. You will check item by item and you know who is the responsible person for each item. You get the feedback, right? Exactly. Exactly. Yeah, let's do it like this so then it will remain with me. I will always update the screenshots if there are any changes and comment on the changes. Yeah. And yeah, integrate everything you have to be like you put there. I will I think create a sub page on the Confluence just for this. Yeah, okay. So that we can track also the changes. I will arrange that. Okay. Now we only have half an hour left. We have, I think we need roughly 15 minutes to discuss the way forward and what to do next, what we take out, take with us from this meeting. Yeah. But I think one, since we have now Joachim with us, I think one step I want to highlight just for Joachim because Joachim is handling on our side the ordering and we talked about it before he joined us. So I just would like to mention this point again and then I think we should just go over to the way forward so we didn't couldn't go through all of it. But I think we have made the first two steps. Yeah, we can continue on Wednesday. I just want to highlight for you Joachim. So we talked about this configuration topic in the beginning and we realized that it's like mostly stable and that's and from your side you said that by tomorrow we should have this configuration finalized. Is this correct? Yeah. Okay. So Joachim, this would be now the timeline. At least for the resources excluding the network. The network as you can see here we will have... What do you mean the network component? The network components, yes. Which are not relevant for you for your third party. Yes. Yes. May I assume? So I'm talking only about for example the servers right? So this means for you end of tomorrow, end of business, we should have this and then we can provide this to Xfusion to receive this You can start to release your shopping cart. Create the shopping cart for Stefanie Kuhlmann and so on and so forth. And you will have and that's another part we discussed prior to you joining. You need to clarify with Xfusion that they deliver it let's say to the four different locations so you get the total list and they break down per site but that's more the logistics. I mean the delivery, they don't care. I mean anyway goes through this this is and they ship it wherever you deploy it. The thing is we need to issue three different POs with three different per AC? Do you do that per availability zone, the different orders? Yeah I mean the delivery address. Yeah exactly. It will be four actually four locations. No, no, no. I mean Biele has two availability zones. No, no. Biele has only one. There's a Singer and ACs. And then Frankfurt. And they have two data centers. Usually with three bases in total. Yeah okay but it's one data center which holds two. Yes. Yeah. It's one location. It's one delivery address. So you consider one address, one point of handover. Yeah. But then we have still three addresses. Yeah. Three addresses but three availability zones. Which the guys inside the DC have. On which level you will have to separate them? Do you give three orders then to the exclusion or you just give three addresses to ALSO? Because ALSO usually does something like shipping, selling, shipping. This is electronic because we haven't got the contract yet because of legal reasons. With exclusion. So the shopping cart that comes to the PO that the electronic will be sent to ALSO. In parallel I forward the PDF like PO to the exclusion. Because ALSO is doing the importation, customs and everything clearly. So distribution. Exclusion cannot do this because they don't have a contract to get the papers and you know all this shit. Yeah. But this is ALSO is also paid for so that's not the issue. I would just like to ask who needs the addresses? Where is the point of handover? It's in there on the PO. The PO goes first electronically to if they need to still equip something like for example the GPU servers then I don't know I mean it depends how they ship it for example. Finally I said it before since you are here then the Douglas which cable is packaged into which box? There is no cable. If cables or transceivers or whatever or power cables I guess every single one. It's a separate branch to do the ordering. Normally I would expect that I don't know who is doing it. I'm only talking about exclusion boxes with servers. And whatever is included. But what comes outside I don't care. But you will also just take care about the experience stuff, nothing with power. So about separating the tools. I mean let's say so finally it arrives at the cardina so Peter Weir's desk so they do all the handling with the data centers. So I ask them whether they, because that was also a question whether they have the responsibility or the authority to handle also not these systems like data centers like Iqvilix or the other one NPP. Because normally they look at Amsterdam these two sites Magdeburg and Wiel. They don't even look at Swiss. They don't have anything to do with Swiss. That is also I was new to me. They don't have a record about what is installed at Swiss. So from this point of view it should be straightforward. We will get three quotes in the age of September and then on PO. But that's exactly the point, right? We have to understand the differentiation between AZ and address. How easy is it? As long as AZ is in one data center, they don't care. But for us it's necessary so we can put the people, the raw materials, right? We just have a table with three big items. Data center one, data center two, data center three. For data center one maybe we have AZ one and AZ three. Then the bill of materials for data center two we have AZ two, right? BOM. Data center three the redundancy region, right? So we just list everything like this. Then you should be able to send the right view. Let's say if you name it AZ one and servers then you see AZ one servers, AZ two for one side and servers. We'll mention. We'll deliver it and then you need to double check. But tomorrow end of business you should have it. As long as AZ for one supplier is at one address, I hope it is always one storage where they receive goods. Good. Sorry. I have a question. Andrew you said that the devices which come from Huawei and the servers which come from Edusen. But there is one more server type called management servers which OTC has not so far ordered from neither of them. So in this case the management server will come from Exusion or from Huawei? Maybe Shobi you know it? It's all Exusion, Ritesh. Kristian here. Leo correct me if I'm wrong. Management servers are also coming from Exusion. Correct. All servers. Okay. And do we have the final number of the servers? It's on conference and we will update it. I think even today we still have some customer demand. New demand. We updated that's why we give the final number tomorrow. Tomorrow. So these four additional switches we include for and the additional storage might also have impact on the server. So we make the final configuration today. Tomorrow morning we discuss it. We bind pricing to it and then we have the build. We can provide the numbers. Please write the vendor also for Huawei or Exusion on those configurations. We split. And it will be Ritesh just for you. Also it will be on the conference page that Henrik referred to. All the materials as well. So if you are interested. Split into third party and Huawei. Okay. Okay but thank you. Thank you for the good questions. Good. Governance. Then. An organization. Yeah. Governance and organization. We can look at that but before I want to do that I just have one last question. For this topic. Will we be taking I know we have not yet forecast for each step. But will we be roughly like most taking the same time for all of this. Excuse me. Let me rephrase. Will all those steps probably take the same time which it took to deploy the Swiss Odyssey. Because internally this will take probably two to three weeks until we have a roughly stable view. Realistic view on all the steps and how long they take. Right? But the thing is internally we as OTC here we are part of a bigger project. Right? They are more on board of units. And they of course want to know hey OTC how long do you need. So what would we tell them? I think we should be a little bit more generous except for us a time frame where we feel comfortable with when we say okay we can maybe squeeze out now during discussions and make it shorter. But this is what we need at most. So that because this will be then locked in probably. And this is a little bit of a challenge right now for me. Very important topic because everyone will be like afterwards will depend on us. You refer to Swiss Odyssey and then probably to the run book that I sent you. Right? For example yes. I don't know how we would come to a kind of rough estimate. The thing is there we had this cloud scope installation etc. which we don't need anymore. So. But it was as complex as it was in the YR. Yeah. In a way it was. Yes. I'm thinking if we can use our call on Wednesday for that to go through these steps. And worst case you expand the call at the end a little bit. Make it a little longer. One and a half hour or two hours. Sorry to interrupt. My suggestion is maybe Henrik and Song Lin or Leo and Zheng Wei you small team. First of all to list all the WBS to make sure at most you can lock or freeze the WBS. Yes. Based on this WBS you should collect the relevant time from each team. Maybe only after that it's safer to tear a date to external. That's the rational way to do it. Yeah. But internally they are a little bit pushing. Yeah I know. As Hager mentioned there are two ways. Forward way and backward way. We must at the end find a... If we meet in the middle that would be good. Exactly. Let's see what I can do. I will talk today. Our support. To see what the expectations are. But our resource is available for Henrik. Not 20 by 7 but if you want to have a call this afternoon. You can also sit 24 by 7. You can talk to him. I think it can help you at least. Some of the parts you will have to ask Alex or Richesh to make a statement on. So that's a little bit... It's difficult to say I would not use the Swiss plan because it already includes steps that you don't have here anymore. Right. I will see what's internally I cannot predict yet what they will... No. If you need help with also communication because I know we sometimes we talk about calendar days. And calendar days is a correct statement. But you need to make sure that we assume working days. Right. As calendar days because we assume actually number of shifts of 8 hour shifts. Those should be the units. And we need to make sure that we are not assuming 6 days a week if Hungary is not able to work 6 days a week. Right. For example. The plan is always based on work days. Then the thing that we can do is during the delivery use the calendar day methodology to catch up with the lost part. But also for example what we did in Switzerland we had double to shift today. At some point during tests and exceptions. To make up time that we lost. But that is depending then on people being available for WebEx in the operations team in Squats. Okay for now I will not make any statement regarding any time. No. We will have to discuss. This is just otherwise not possible. Alright. That was good. Then I would say let's go through the last three points. So this would just be organization. Doesn't look too fancy yet I know. But I will revise the slides. I so received the information a little bit on short notes. So I could make it super fancy. No. But it's just that people understand who is what the contact is. Yes. I can just say from our side we will have kind of a dedicated project team. This is what at least was I think supported by most colleagues from our side. For example you Alexander you mentioned this I think initially you said we need a dedicated team to really push this project. And so this will all come together. So it's not a finalist picture. We have of course on our side the Squats which will support all the steps. We have a steer core already on our side as you can see here. For the people and the business owner of course. And they are spiked up. So this is roughly the picture right now. This would be updated. I will also put this all in the confluence. So and update it day by day. From your side I see here the list of all the work I can do. It doesn't fit your structure yet but maybe you and I can have a separate alignment on that. That's fine. To make sure that you can map it in the same way. What I find more important than this org chart is actually the cadence kind of you know conversations that we have. And that's where we come to this. Perfect. So what I propose right now is at least two thirty minute weekly course with a dedicated team. Then we have of course on Wednesday, this call always right. Where we can also talk about the project. And then we will propose as soon as we are coming to this to prepare all the phases after the ordering after the delivery has happened that we then have on demand sessions in this three months. Which of ordering so that we can prepare all the topics and so that we can start right away after it's delivered. So we should do this on demand. And then I propose that we have daily calls as soon as the hardware is installed. Because then we are just on the critical path the entire time. So this would be our proposal. What do you think? What about the synchronized meeting with the business owners and sponsors? This happens every Friday on our side. I have since two weeks already a steering board. You mean it will be split right? I mean your people talk to your executives and we do within our right? And we will on management level I think you know if we do a joint update we do it in operational steering board. Unless we need something in between we can always set it up at home. Otherwise I think it should be a kind of recurring topic there. I think you have an internal update. You do that on your accounts or in your whatever call. Line we set up a dedicated meeting. You can always pull us in there if you want for that topic. Let's see for yourself. But it's mostly that they just have some general what I understand generally is there any problem on your side? They leave it to you and they should have a cover. And the report? We're going to be a weekly report? Or something that's sent to both parties? Yeah that's what I want to discuss. How do we do this ideally? I asked Matthias Mütens how he did it. If he had like Jira we put in the task. If he wrote it down each week he said he did not do that at all. And that was fine. So I know because this always creates a lot of overhead if you have to update slides every day and just like information which everyone already has in their head. The question is is this necessary? Yeah. Maybe with your project plan. Then we update the plan and you put just on the headline one sentence like what's achieved based on the plan? What didn't achieve based on plan? That's a good idea. What areas we need right? In case that you need management to attention for something. Absolutely. This is what I'm already doing for the steering also. I will just share this also in the confluence and always so that everyone can take a look at it and we can see where we are maybe behind, where we are already maybe done. If they expected I will do this. This will also be on the sub page where I will try to put a documentation of what has changed and maybe where we have a problem and this got already resolved and stuff like that. I will take care of that. But I don't think we need what I meant I understand initially is that you want the reporting call where we then at the end of the week summarize everything. I think this would not be sufficient. Yeah don't do this. Exactly. No, this is fine. This will take care of that and make it so basically from the structure. Okay and then I wrote just down, it's not communication this is rather like to do this. So the to do which we now to do this. So we have said configuration tomorrow during security deep dive we want to discuss the region access after step nine. This was one point which was mentioned then aligned with EHL network team to schedule the call after schedule the call after Martin Schenk spec from vacation. Okay any what else B2B call Wednesday morning Wednesday this week such a Finalize the review and finalize the project plan. Projects plan three, two to three weeks. Your serve Your serve, Sony How's this S O N G R I N R L L L I N So is this correct? N LIN Yes, correct. And I think Leo and Zheng Wei Okay it's fine, you too but they will join as well. So Leo and then Your English name? H E R V E A H E R V E A H E R V E N The Chinese name is easier. I will get used to that. I'm really not doing that on purpose. Please excuse me for that. No, you're not easily offended. I can send you out my god. I will get used to the names and make sure that I have Okay What else? Okay and whoever else wants to join? No, Harvin. Harvin. Har... Choose a name that's easier. Like Richard. Like Richard. Like Leo. Eric. I think I have to I will take care of that. Apologies, I need to leave. I'm expected in five minutes in another meeting room together with Thomas with your boss of Germany. So continue. Don't give me any action items that I don't want. Thanks for your time and attention and organizing everything. Okay. I just put it away here. I think that's kind of all, right? Yeah. Okay. Do you think that you can be in the D.H.O. or maybe one? Oh, excuse me. I think we are meeting later to discuss that. Yeah, the A.C. naming we should discuss later during the network call. Yeah. Sorry. During today's appointment at two I think it is. Yeah. Does this answer your question? No, I didn't get it. So you are planning to discuss it today at two with D.H.? Yes. No, in turn. The first and with D.H. probably next week. No, sorry. Yeah, not yet next week. Yes, exactly. Correct. Okay. Can you write it as a to do here because these are the networks. It is already written down as to do three. Which point? Three. Under the to do. No, three. Yeah. The three points regarding the network isolation and network topics one. Yeah, but this is also, I thought we should also discuss the A.C. naming also separate then if it is from outside in internal discussion only then we can have this today. Okay. Okay. Okay. Good. Just one last question because Christian mentioned me with all the switches but I understood from Alex that there were six switches in the other. How many were there in the other? We can just, Alex, here is the question. There was the discussion about the switches. How many are needed? Is it three or six? What is the number? Six. Six. Okay. Six. Thank you. Yeah, good to know because we need to have the quotation number tomorrow, right? Exactly. Okay. And the naming question which was opened from Ritesh is still valid question. Okay. Now, that's the main thing because this is pretty important that the customer accepts our proposal because this is really a point which I do not want to discuss with the customer because this follows our standard. And our standard needs to be clicked here also in that way. So, I tried to push as hard against this possible. Anyhow, we need to discuss this with the customer. Right. Exactly. Next week. So, I will take care of that, yes. Okay. Yeah. Okay. Good. Any comments? Any open topics? Otherwise, we would be in two minutes. Finish this call right on time, actually. Which is pretty good. The meeting is this afternoon going to happen here or remotely? Yeah. The room is reserved? Yes. Until five. Okay. So, maybe it's the same room? Yeah, maybe discuss here. Communication will be better. And there will also be WebEx for Webjoins remotely. Okay. Yeah, sure. Okay. Alex speaking. Do you need the afternoon for today because the network topic is already discussed from my side? Well, I thought there were open points to discuss regarding the network still. So, this was at least my impression last time because we had to cut the discussion short. In the last technical scoping, I guess, we wanted to discuss it. So, Ryan, you were discussing the topic and then we said, well, okay, we have so many points. Maybe let's do a deep dive on that. So, if it's not... So, from whom from the network do you have invited to that call? No, there is no one from DHF. No one. From our side. I invited, so we, when we discussed this during the meeting, in the technical scoping, we said that we invite, we can just take a look here. This is, everyone invited. This is what was mentioned to me during the meeting. I asked who I shall invite and this is what was the result. Okay. What do you think, because there's no one from the network, right? From the network. I think the main reason was that Martin is on vacation.
________________________________________split transcription____________________________
Meeting Minutes

**Meeting Overview**

* Date & Time: Not specified in transcription (to be filled based on context)
* Location: Virtual meeting (assumed due to reference to calendar invites and virtual attendance)
* Chairperson: Not explicitly mentioned; assumed to be the individual initiating discussion points
* Attendees:
  * Henrik, possibly the chairperson or note-taker
  * Ryan (mentioned in context regarding slide updates and OBS agreement details)
  * Sasha (part of the meeting discussing DMZ firewall capacity issues)
  * Norbert Ruth (SDM involved in DMZ firewall discussion)
  * Micke Martini (provider of container service, discussed manual backup processes)
  * Thomas Weber (notified to be added to network deep dive invite)

**Agenda Items**

1. Review and Finalization of OBS Agreement Details
2. Network Deep Dive Session Scheduling
3. Security Deep Dive Session Reminder
4. Resource Allocation Update
5. Manual Backup Processes and Reliability Discussion

**Discussion Details**

* **OBS Agreement Review**: Henrik noted the importance of finalizing details due to impending vacations among internal stakeholders, emphasizing priority status.
* **Network Deep Dive Session**: Scheduled for later that day at 2 or 3 PM (precise time not clear). It was agreed that network-related topics could be discussed there.
* **Security Deep Dive Reminder**: Set for the following day; Thomas Weber's inclusion in the invite list was to be confirmed.
* **Resource Allocation**: No additional resource concerns were raised, and the current allocation appeared satisfactory.
* **Manual Backup Processes**: Micke Martini confirmed manual backup processes used on existing platforms could be replicated on OTC (One Technology Center) with similar efficiency.

**Decisions and Action Items**

1. Henrik to update OBS agreement details based on feedback from Ryan and others present at the meeting, aiming for finalization before vacations commence.
2. Sasha will double-check Thomas Weber's inclusion in the network deep dive session invite list and ensure all relevant parties are notified.
3. The responsible person (likely Henrik) shall confirm that everyone listed in the Excel sheet is added to future meeting invites, allowing individuals to opt out if they deem themselves unnecessary for specific meetings.

**Other Matters**

* A reminder was given about reviewing the table of contacts, indicating a possible need for an updated list or distribution of roles among meeting participants.
* It was acknowledged that some attendees might not have received updates promptly; thus, Henrik offered to resend relevant information to ensure everyone's inclusion in ongoing communications.Meeting Minutes

**1\. Meeting Overview**
- **Date & Time**: Not specified
- **Location**: Virtual meeting (assumed)
- **Attendees**: Alex, Christian, Henrik, Jochen, Bchen
- **Chairperson**: Not explicitly mentioned; possibly Henrik due to guiding the discussion flow.

**2\. Agenda Items**
- Contract negotiation phase and hardware ordering
- LED design by Urvay
- Hardware installation
- Logistics for third-party hardware delivery and assembly

**3\. Discussion Details**

*Contract Negotiation & Hardware Ordering*
- The team discussed the negotiation phase with customers, followed by POs for hardware orders.
- Xfusion services and Urvay switches were mentioned as part of the procurement process.
- Integration of third-party environments or hardware was acknowledged for special customer requests.

*LED Design by Urvay*
- It was noted that LED design is a complex task requiring detailed information gathering, validation, and manual labor from Urvay.
- The team aims to develop their own LED design capability in the future.

*Hardware Installation*
- Hardware installation will primarily occur within TSI data centers but may involve third-party administration for non-TSI locations.
- Close collaboration with data center operators is essential.

*Third-Party Logistics*
- Discussion revolved around whether hardware should be shipped to a central location or directly to individual sites, with preference for the latter to simplify logistics.
- For third-party assemblies requiring NDA protocols, components must first ship to an assembly location before final delivery.

**4\. Decisions and Action Items**
- **Action Item**: Jochen needs to ensure that Excusion understands separate deliveries to four different locations when providing quotes.
- **Action Item**: Address details for each data center are required promptly to avoid logistical issues.
- **Action Item**: The team must split the bill of material per location based on pricing configuration, with Bchen responsible for this task.

**5\. Other Matters**
- Challenges were anticipated for two new third-party data centers due to less established management practices compared to Beer and Magdeburg locations.**Meeting Minutes**

---

**Date:** Not specified

**Time:** Not specified

**Location:** Virtual Meeting (No physical location mentioned)

**Attendees:** Alex, Chris Selm, Leo, Richard and others not individually named.

**Chairperson:** Not mentioned explicitly; Alex led the discussion on HCSO deployment process.

---

**Agenda Items:**

1. Overview of HCSO Deployment Process
2. Development and Automation Tool Updates
3. Project Deliverables and Standardization for OTC Private Cloud Product

---

**Discussion Details:**

- **HCSO Deployment Process:** Alex presented a comprehensive overview of the Huawei Cloud Stack Operations (HCSO) deployment process, detailing steps from initial planning to final delivery. The process emphasizes automation with tools like EDKAN and HCC turnkey solutions for implementation efficiency.
  
- **Automation Tool Set Innovations:** Chris Selm discussed ongoing developments in automation tools, particularly advancements that have made physical service delivery akin to cloud-based processes through the mini scope cloud function. Offline EDK tools now automate large-scale physical platform deployments with significant efficiency gains.

- **Project Deliverables & Standardization:** The team aims to establish a new HCSO delivery standard for OTC Private Cloud as a product outcome of this project. A review will be conducted post-project completion to assess the end-to-end process, identifying areas for optimization and potential changes necessary for future replications.

---

**Decisions and Action Items:**

- **Process Automation Enhancement:** The team needs to heavily invest in automating quality assurance checks (UA TV) for robot tests to enable faster deployment cycles. (Responsible: QA Team; Deadline: Not specified)

- **Security Hardening Implementation:** A security hardening procedure including the deployment of the Magenta layer will be enforced, ensuring secure access and locking higher-level privileges appropriately. This process requires automation check validation and security approval. (Responsible: Security Team; Deadline: Not specified)

- **Mini Cloud Scope Function Integration:** The integration of mini cloud scope functionalities into current processes should be explored for further deployment efficiency gains. (Responsible: Development & Automation Tools Team; Deadline: Not specified)

---

**Other Matters:**

- No additional points were explicitly mentioned in the provided transcript.
  
  Note: Specific deadlines and responsible persons for action items are not clearly defined within the provided text. These details need to be finalized post-meeting or through follow-up communications.

---Meeting Overview:
Date & Time: [Insert Date], [Insert Time]
Location: [Insert Location]
Chairperson: [Insert Chairperson Name]
Attendees: [List Attendees]

Agenda Items:
1. Hardware and Delivery Estimations
2. Project Planning Updates

Discussion Details:

Hardware and Delivery Estimations:
- The current estimation for hardware delivery is approximately three months from order approval to delivery, including internal processes and approvals.
- It's noted that this timeline is an estimation and may vary based on the specific requirements and vendor conditions.

Project Planning Updates:
- A detailed project plan was reviewed with all steps mapped out as one day placeholders due to a lack of exact time estimations for each task.
- The current expectation, based on estimated timelines, points towards completion in early December. However, this timeline is subject to change based on the real-time data and progress updates.
- The DHI contract signing is anticipated by the end of this month.
- Technical scoping, security appointments, and back-to-back agreement preparations are ongoing tasks that are being factored into the project planning.
- Suggestions were made to create decision points for milestone achievements, such as initial access for internal managed service colleagues before full platform readiness (90% completion) and feedback incorporation opportunities from external stakeholders.

Decisions and Action Items:
1. The team will review and adjust the hardware delivery estimation based on real-time data and vendor conditions.
2. Detailed project planning needs to be updated with more accurate time estimations for each task to ensure a realistic timeline is maintained.
3. Create decision points within the project plan that allow external touchpoints, such as initial access and feedback incorporation stages, ensuring alignment and confidence in the project's progress.

Other Matters:
- It was discussed that allowing early access under certain conditions might pose risks but could also provide opportunities for managed service colleagues to start preparations earlier.
- Concerns were raised about potential incidents or tickets being created prematurely if customers are granted access before full platform readiness. 
- The meeting concluded with a note on the importance of ongoing communication and alignment between all stakeholders involved in project planning and execution.

[Insert any further notes or updates that may be relevant to the meeting]Meeting Overview:
Date: [Insert Date]
Time: [Insert Time] - [Insert Time]
Location: [Insert Location]
Attendees: [List Attendees]
Chairperson: [Insert Chairperson]

Agenda Items:

1. Review of Customer's Decision Regarding Additional Devices
2. Exchange with DHL and Customer Engagement Strategy
3. Network Deep Dive Session Update

Discussion Details:

1. The team discussed the customer's decision to initially remove four additional devices (Huawei switches) from the first design phase, which were later deemed necessary by Martin Schenk for network architecture simplification.
2. Alexander acknowledged that these devices are crucial and proposed a discussion with the customer to clarify their importance before proceeding with worldwide negotiations or designs.
3. The team agreed to schedule an exchange meeting with DHL's network experts as soon as possible to explain why the additional layer between endpoints is necessary and beneficial for the project.

4. Bichan, responsible for configuration and hardware bill of materials, will join a network deep dive session in the afternoon to ensure that the devices are included accurately.
5. Christian suggested organizing an outreach to DPDHL's team before Martin Schenk returns from vacation, aiming to have his support during the meeting with the customer.

Decisions and Action Items:

1. Alexander will organize a meeting with DHL's network experts upon return from lunch break at 12:05 PM.
2. Bichan will join the afternoon session for network deep dive to update device inclusion status in configuration tool and hardware bill of materials.
3. The team agreed on having Martin Schenk involved post-vacation, but Alexander will initiate contact with DPDHL's network experts before that.

Other Matters:

1. Christian proposed a five-minute break, which was unanimously approved by the attendees.
2. A discussion about different textures of an item (possibly unrelated to meeting agenda) was briefly mentioned, indicating informal conversation amongst team members during or after the official meeting minutes were taken.

[Note: Specific details like date, time, location, and attendees should be filled in according to the actual meeting information.]Meeting Minutes

**1. Meeting Overview**
- **Date:** Not specified in the transcript
- **Time:** Not specified in the transcript
- **Location:** Not specified in the transcript, but assumed to be virtual given references to calls and being on holiday
- **Attendees:** Mentioned attendees include Raaki (Sasha), Jiang Yuan, representatives from DHL, and other project team members. Full list not provided.
- **Chairperson:** Not explicitly mentioned; discussion is led by a speaker who coordinates actions but does not claim the chairperson role.

**2. Agenda Items**
1. Cost Impact Analysis for Project Revisions
2. Technical Scoping Update (discussed previously)
3. Security Discussion Scheduled for Tomorrow
4. Back-to-Back Agreement Drafting and Review

**3. Discussion Details**
1. **Cost Impact Analysis:**
   - The speaker acknowledges potential cost impacts due to project revisions, specifically mentioning additional storage requirements.
   - Plans to review original price agreements with Jinju and discuss changes with the DHL team, particularly regarding added costs for switches and extra storage which could be substantial.
2. **Technical Scoping:** (Previously discussed)
3. **Security Discussion:**
   - Scheduled for tomorrow; no further details provided in this segment of the transcript.
4. **Back-to-Back Agreement Drafting:**
   - Speaker suggests discussing the agreement on Wednesday, focusing initially on content rather than legal specifics.
   - Emphasizes the importance of aligning revenue share enforcement within a business plan as part of the agreement.
   - Proposes avoiding detailed discussion during the broader group call and instead scheduling a separate meeting for focused review.

**4. Decisions and Action Items**
- **Sasha:** To discuss cost impact revisions with DHL project team and provide updates on additional storage requirements.
- **Speaker (project coordinator):** Will organize a deep dive session with the DHL team to address project modifications.
- **Jiang Yuan:** Will assist in streamlining back-to-back agreement processes during the speaker's absence.
- **Speaker (project coordinator) & Sasha:** To schedule and hold a separate meeting for discussing the initial draft of the back-to-back agreement on Wednesday or as soon thereafter. The speaker suggests avoiding detailed discussion during the broader group call scheduled for Wednesday.

**5. Other Matters**
- Speaker intends to loop Jiang Yuan into relevant discussions regarding the back-to-back agreement, enabling him to understand and contribute to the process.
- A note about personal holiday plans is mentioned, indicating intent not to work on critical documents while away but still taking a laptop for possible limited access.
- There's an emphasis on the importance of internal discussion before finalizing details with external parties regarding project-specific agreements.Meeting Minutes

**1. Meeting Overview**
- **Date & Time:** [Insert Date] at [Insert Time]
- **Location:** [Insert Location or Online Platform used for the meeting]
- **Attendees:** Henrik, Joachim, Ritesh, Stefanie Kuhlmann, Peter Weir (and other relevant team members)
- **Chairperson:** [Name of the Chairperson]

**2. Agenda Items**
- Review and discuss configuration details for resources excluding network components
- Clarify delivery logistics with third-party vendors
- Address procurement process through Xfusion and ALSO

**3. Discussion Details**

a) **Configuration Timeline**
   - By end of business tomorrow, a finalized resource list (excluding the network component) is to be provided to Xfusion.
   - Clarity was sought on delivering resources to four different locations.

b) **Logistics and Delivery**
   - It was confirmed that deliveries are made per site, with three main delivery addresses identified.
   - The team discussed separating orders based on availability zones within data centers for clarity in logistics.

c) **Procurement Process**
   - It's noted that ordering will be executed through Xfusion, with electronic purchase orders sent to ALSO for handling importation, customs, and distribution.
   - Paperwork issues were flagged due to the lack of a contract; workarounds were discussed involving PDF POs forwarded directly.

**4. Decisions and Action Items**
- **Action Item 1:** Henrik will finalize and provide the resource list excluding network components by end of business tomorrow.
    - Responsible Person: Henrik
    - Deadline: End of business tomorrow
- **Action Item 2:** Joachim to clarify with Xfusion about delivering resources to four different locations.
    - Responsible Person: Joachim
    - Deadline: ASAP, before the order is placed
- **Action Item 3:** Stefanie Kuhlmann and Peter Weir will coordinate to ensure that ALSO receives clear delivery instructions for each address.
    - Responsible Person: Stefanie Kuhlmann & Peter Weir
    - Deadline: Before electronic PO submission

**5. Other Matters**
- A question was raised about who needs specific addresses and where the point of handover is, indicating a need for clearer communication between procurement and logistics teams.
- The team agreed to separate orders based on availability zones when dealing with Xfusion and ALSO, ensuring each location receives its designated equipment.
- It was noted that handling cables, power supplies, and other components outside the server boxes will be handled separately by another team.### Meeting Minutes

#### Date & Time:
- [Date not specified]
- Time unspecified

#### Location:
- Unspecified location

#### Attendees:
- Alexander
- Thomas (briefly attended)
- Leo (expected to attend a later segment)
- Herve / Harvin (actual name pronunciation unclear, Chinese name possibly easier; expected to join)
- Zheng Wei (expected to attend)

#### Chairperson:
- Not explicitly mentioned

---

### Agenda Items

1. **WebEx Availability for Operations Team**
2. **Project Organization & Updates**
3. **Communication Cadence and Alignment**
4. **Synchronized Meetings with Business Owners & Sponsors**
5. **Weekly Reporting Mechanism**

---

### Discussion Details

#### WebEx Availability
- No specific statement regarding timing made due to the dependency on availability of operations team in Squats for WebEx sessions.

#### Project Organization & Updates
- A dedicated project team will be established from our side, as initially proposed by Alexander.
- The Squats team will support all phases of the project.
- An operational steering board has already been set up and runs every Friday with updates on this topic.
- Alignment needed for mapping organizational structures between parties.

#### Communication Cadence
- Proposed at least two 30-minute weekly calls with a dedicated team.
- Regular Wednesday meetings to discuss project progress will continue.
- On-demand sessions post-ordering/delivery, especially in the critical three-month period before installation.
- Daily calls once hardware is installed due to high activity and critical path.

#### Synchronized Meetings
- Separate internal updates with business owners/sponsors on both sides. Recurring topic at operational steering board level for inter-party update if necessary.

#### Weekly Reporting Mechanism
- General agreement that extensive overhead in reporting can be minimized.
- Proposal: Update project plan weekly with achievements, non-achievements, and areas needing attention.
- Avoid summarizing the week's activities at the end; focus on action items and status updates throughout the week.

---

### Decisions & Action Items

1. **Configuration Discussion**
   - Configuration details to be discussed during security deep dive tomorrow (related to region access post-step nine).
2. **Network Team Call Schedule**
   - Align with EHL network team post-Martin Schenk's return from vacation.
3. **B2B Call**
   - Finalize and hold a B2B call on Wednesday morning this week, involving Leo and Herve/Harvin.

4. **Project Plan Review & Finalization**
   - Review and finalize the project plan within two to three weeks (no specific person assigned).
5. **Easy Pronunciation Names**
   - Request for participants to choose names that are easier to pronounce (e.g., Richard, Eric) if their given name is difficult.
6. **Meeting Continuation**
   - Thomas has to leave early due to another meeting and requested no action items be assigned in his absence.

---

### Other Matters
- Alexander will take care of the action item regarding names and apologies for any difficulties encountered with pronunciations. 
- No further specific matters were discussed before the end of the transcription.
  
--- 

#### Note: Specific details such as exact dates, time slots, and meeting locations are not provided in the transcript, thus they are omitted from these minutes.Meeting Minutes

**1. Meeting Overview**
- Date: Not specified in transcription (must refer to calendar or previous records)
- Time: Not explicitly mentioned; meeting was called to a close "right on time"
- Location: Room reserved until 5 PM, suggesting an onsite location with potential remote participation via WebEx
- Attendees: Alex, Ryan, Thomas (boss of Germany), Christian, Leo (alias Hervean), Zheng Wei, Martin Schenk (on vacation), Ritesh, and possibly others not mentioned by name.
- Chairperson: Not explicitly named; Alex seems to have taken a leading role in discussion.

**2. Agenda Items**
1. Management attention for certain aspects of the project
2. Project update documentation on Confluence page
3. Configuration discussion during security deep dive
4. Region access after step nine clarification
5. Alignment with EHL network team scheduling post-vacation period
6. B2B call to finalize review and project plan in 2-3 weeks

**3. Discussion Details**
1. **Management Attention**: The need for management's attention on specific project aspects was acknowledged, and the current steering process will be shared more transparently through a Confluence page.
2. **Project Updates Documentation**: Updates will be regularly posted to reflect progress and any issues encountered, with solutions noted upon resolution.
3. **Configuration Discussion**: Configuration details are set to be discussed in tomorrow's security deep dive meeting. The region access post-step nine was highlighted for discussion during the session.
4. **Scheduling with EHL Network Team**: Call scheduling will occur after Martin Schenk returns from vacation, ensuring his availability for critical input on network topics.
5. **B2B Call Update**: A Wednesday B2B call is scheduled to finalize a review and project plan within 2-3 weeks' time frame, aiming for a smooth rollout of services or solutions.
6. **Names and Communication**: Challenges with remembering names were discussed; simpler aliases (Richard, Leo) were suggested for easier communication among the team.

**4. Decisions and Action Items**
1. Alex will document project updates on Confluence to track progress transparently.
2. Configuration details and region access will be discussed tomorrow during a security deep dive meeting.
3. EHL network team scheduling will occur post-vacation period; exact date not specified.
4. Finalization of review and project plan within 2-3 weeks, with Wednesday's B2B call marking the next key discussion point.
5. Alex will confirm if additional network personnel need to be involved in afternoon discussions.

**5. Other Matters**
1. **Meeting Follow-up**: This afternoon’s meeting was reserved for onsite attendance until 5 PM; WebEx availability ensured remote participation could also occur.
2. **Network Topic Clarification**: There's uncertainty about whether further network discussion is needed since Martin Schenk, a critical team member, is currently on vacation.

**Note:** The lack of specific dates and times in the provided transcription requires referencing additional documentation or prior meeting records for a complete schedule.### Consolidated Meeting Minutes

**Date:** Not specified in transcription (refer to calendar or previous records)
**Time:** Meetings were called to a close "right on time"
**Location:** Room reserved until 5 PM, indicating an onsite location with potential remote participation via WebEx for various segments of the meeting.
**Attendees:**
- Alexander
- Thomas (boss of Germany; briefly attended)
- Christian
- Leo (alias Hervean)
- Zheng Wei
- Martin Schenk (on vacation)
- Ritesh
- Henrik
- Joachim
- Stefanie Kuhlmann
- Peter Weir
- Xfusion representatives
- ALSO representatives

**Chairperson:** Alex took a leading role in the discussion.

---

### Agenda Items and Discussions

#### 1. **Project Planning and Coordination**
   - Alexander stressed the importance of maintaining a clear line of communication.
   - Thomas and Henrik discussed the need for regular updates on the project's progress, emphasizing the value of visual aids like PowerPoint presentations to ensure understanding across teams.

#### 2. **Procurement Process**
   - Ordering will be executed through Xfusion with electronic purchase orders sent to ALSO for handling importation, customs, and distribution.
   - Paperwork issues were noted due to a lack of contract; workarounds involving PDF POs were discussed as an interim solution until the formal agreement is in place.

#### 3. **Project Update Documentation**
   - Updates will be regularly posted on Confluence to reflect progress and any issues encountered, with solutions noted upon resolution for transparency.

#### 4. **Network and Configuration Details**
   - Configuration details are set to be discussed during a security deep dive meeting tomorrow.
   - The region access post-step nine was highlighted for discussion during the session.
   - Scheduling will occur after Martin Schenk returns from vacation, ensuring his availability for critical input on network topics.

#### 5. **B2B Call and Project Plan Finalization**
   - A Wednesday B2B call is scheduled to finalize a review and project plan within 2-3 weeks' time frame.
   - The objective is to ensure a smooth rollout of services or solutions, with Alex confirming if additional network personnel need to be involved in afternoon discussions.

#### 6. **Deliverables and Timelines**
   - Alexander underlined the importance of meeting deadlines and delivering on promises.
   - Joachim was asked about his availability for further meetings regarding the project's progress.

#### 7. **Delivery and Logistics**
   - There are concerns regarding delivery times from Xfusion, which could potentially delay the project if not resolved promptly.

#### 8. **Management Attention**
   - The need for management's attention on specific project aspects was acknowledged.
   - The current steering process will be shared more transparently through a Confluence page to ensure alignment and accountability.

---

### Decisions and Action Items
1. Alex will document project updates on the Confluence page to track progress transparently.
2. Configuration details, region access post-step nine clarification, and further network discussions are scheduled for tomorrow's security deep dive meeting and upon Martin Schenk's return from vacation.
3. Finalization of review and project plan is set within 2-3 weeks with Wednesday's B2B call as a key discussion point.
4. Joachim will confirm his availability for additional meetings to monitor the project's progress.

### Other Matters
1. **Meeting Follow-up**: The afternoon meeting was reserved until 5 PM, allowing for onsite attendance and ensuring WebEx availability for remote participation.
2. **Network Topic Clarification**: Uncertainty exists about whether further network discussion is needed due to Martin Schenk’s absence on vacation.

**Note:** Specific dates and times require referencing additional documentation or prior meeting records for a complete schedule. This document merges multiple parts of the meeting minutes into a single, coherent summary without duplications./root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing OpenSearchVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import OpenSearchVectorSearch

with new imports of:

>> from langchain_community.vectorstores import OpenSearchVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing ElasticsearchStore from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import ElasticsearchStore

with new imports of:

>> from langchain_community.vectorstores import ElasticsearchStore
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/v0.2/docs/versions/v0_2/>
  warn_deprecated(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/chat_models/__init__.py:32: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.chat_models import ChatOllama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/__init__.py:29: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.
  warnings.warn(
/root/miniconda3/envs/whisperx/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import Ollama`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Running on local URL:  http://0.0.0.0:7859

To create a public link, set `share=True` in `launch()`.
Deleted folder: /home/linux/meeting_whisper/tmp9p3lew4x
Deleted folder: /home/linux/meeting_whisper/tmpzrfbl43s
Deleted folder: /home/linux/meeting_whisper/tmp3k89dq_5
临时文件夹地址：./tmpj3ff20mx
上传文件的地址：/tmp/gradio/406276c6c91843e9d7e647d308597ccbaca13be1/安全周例会717.mp4
base name 安全周例会717.mp4
 So next week Friday we do a webinar for the public where we introduce HSS and show the features and functionalities, give a live demo of ransomware and recovering and do you want to see it, to join? No, thank you. Okay. Okay, no problem. Either way it will be recorded and then uploaded also to our YouTube channel for interested customers. Based on what we have seen so far from HSS, I sent you an email for a few points where I just want to check with you the status and if that is possible and we can somehow address it to fix the things we mentioned. So basically if I share my screen, I just presented the service to our sales team internally and that is the feedback I received so far. For example for HSS it is not supporting the newest operating systems like Windows Server 2022 and so on. Joshua, you said we should give you a list and you forward this to Andy. Is this sufficient for you? Do you need to... Yes, it is too long. Can you please make it simple a little bit? Just say what do you need? And we already sent it to Andy, they are also kind of confused. So they tell me two things. The first thing is yes if the HSS is upgrading, it will have the same operating system supported with Huawei. Do we have a timeline for updating it on OTC? We already have the package, anytime can do the upgrade. Anytime? Ah, okay. I didn't know. First we are still waiting for him to do this upgrade. The second thing is if you have any other operating system you kind of like to have it supported, please leave it very clear. We want Windows 20, 24 or something. This list here, I share my screen and that is the list. This is the list, okay. I have a red X on the side so it kind of confused. We just make those supporting and it should be here, right? Yes, so it is in red X because it is currently not supported. Oh, okay. Then I think no need to let Andy to take a look and see how they can support it. Also, the upgrade is kind of critical because it can also solve the 0.5. I think you have the 0.1, 0.2, 0.3 and 0.5. You don't find mine well because the current version of HSS is weak. The scan function is kind of weak but the upgrade will have been improved. That will still be a good way to go. Okay. Do you have an estimation how long it would take to upgrade it? Because we have the webinar next week, Friday, and I don't know how quick it could be to upgrade it. Otherwise, we do the webinar with the current installed version if it is taking too long I think right now it is already Wednesday. I don't think it will happen next week. Okay, then we use the old version as a baseline for doing the... When you find the other customer, the next version will be done soon, which is also kind of true. Do you have release notes for the new version? Like an overview of what will be added and change that I can kind of announce what is coming next? I can maybe give you a release note but I don't think we should do that before we see it actually coming. What do you mean by see it actually coming? Well, what if the release note has some new feature and the coming package says no, we don't have this for OOTC? What will that be? Okay, so we don't know what is inside the package. So we need to see if it is matching the release notes. Yeah. Okay, good. Okay, then I will leave it out. Okay, so then we address point one and point five of the upgrade. So point two. So I said... No, I say point one, I say only align with the HSS so HCE will be supported and if the rest, if Huawei is not supporting then the upgrade won't help. I need to create a demand here. Yeah, and you can take this list. You leave out the first one because it is supported but for the other four you can add this list to Andi and create a demand that would be really appreciated. Okay. Okay, great. So second one is so if customers install or want to install an agent and they get a message that the software is not signed and not trusted. Can you take this one? Yeah, sure. The question is if you can sign it because we cannot really sign software which is not coming from OTC so we did not develop it. If we sign it then it is Huawei. Yes, yeah. Okay, sure. Would it be possible from your side? That is the message, publisher unknown and this is an app from an unknown publisher. If Huawei is signed then I will speak with Andi. I think it is possible from our side but I will get back to you. Okay. Okay, the third one is about updates, so regular updates of the vulnerabilities so we just implemented the package for July. Is it possible because you said it is coming once a month so can you provide an official statement or create a statement that it is coming once a month that we have it reliable like a promise we get it once a month in your vulnerability database? Because then we would also kind of promise it to our customers because if you cannot officially promise it, we cannot also promise it to our customers. That is why I am asking. I think you should not promise this thing to customers because what if they have a month that no vulnerability is supported? I guess there will be no month. What if they have a month from July to August only very small or no critical vulnerabilities are supported? So if small vulnerabilities are supported I guess they should be put in the package, right? No, my point is that we cannot promise you that. Okay, it is fine. So it is not a problem because then we also say we aim so we have the goal to update it but we do not make any promises so you cannot. We aim, yes we aim. It is kind of true because if I remember correctly since we deployed this HSS and GA we kind of upgraded it like one or twice per month but because we can upgrade simply because we have the package, we have the new support but on one side they say I think they are not sure. I think they say something like the longest period for this upgrade is like a quarter or three months. So I guess that happened before, I am not sure but we aim to upgrade which is kind of reasonable frequency. Okay, that is fine with me. The next thing is about also having that we can install the agents on premise or on another cloud. So currently it is not possible. I do not get what you mean but I know also I give you the link, it says very clear how to do it step by step. I am not sure. Yes, this link here right? Yes, we have the same documentation on our page but it is not possible because the agent cannot be so it is only communicating internally. So if you look at the agent configuration, one second. I just take a quick look, I think it says something about the proxy, it is not communicating with each other and I assume that is not the problem of our agent. Yes, because for example if I want to download the agent, I need to download it from this page, so here is the host guard agent. This is not accessible from the internet so I cannot download the agent and this is also the configuration, HSS agent pot blah blah blah and so this is where the agent is communicating to but this is also not reachable from the internet so the agent cannot communicate outside of OTC so it is only possible by network internally. So we also have on our page, if you go to our help center and HSS, it is written, yes here for, where is it, here is third party cloud server and on premise servers. Yes, but how do you install the agent on the third party cloud server if it is not allowed to or the connection is only via OTC internally so it must change to internet. Do you understand what I mean? A little. Okay, let me show you on Huawei's side, how it is there. Let me just quickly need to log in. So if I go to Huawei cloud and I want to set up the agent on HSS, now it is loading. Not by server install agents from other cloud. So if I want to install the agent, I get two versions, the cloud server and non-cloud server. So cloud server that means these servers are protected by HSS, they are on Huawei cloud and non-cloud server is like on premise or in another cloud, anywhere else but not on Huawei cloud. So somehow you are missing this page and you have problem to install the agent. Yes. If you find a way to install the agent, you should have no problem. No, because the agent has the configuration that to contact this system, the master is kind of our dashboard. Sss agent pod lb otc systems.com, this is not reachable via internet. So the agent cannot communicate. Hi Sebastian. Sorry for being late. No problem. Did you understand now Joshua? Kind of. So just install agent and I may connect to this pod. Yes, but this pod is not, you cannot connect to the pod when you are outside the OTC. But you have to get it work. And that's why you have on Huawei cloud, you have agent for cloud server and agent for non-cloud server. I see. And I don't know if that is part of the upgrade for the new HSS version. Maybe. Maybe not. But I think this version supports this function already. I just need to figure out how to... Yes, because we have it on the documentation. The third party cloud server and on-premise server. We have it at least documented here, but it is currently not working. How can we move on with that one? Can you have a look at that one? Okay, that's great. Sebastian, just a summary while you were absent. So I just spoke about this email about the HSS pain points from our side. So Joshua will address compatibility with these new operating systems at R&D for the first point. Great. For the second point, TiBo said they can sign the agent with their certificates. So he is asking Andy. If so, it would just be seen like Huawei is the publisher, not it's unknown, it's from Huawei, the agent. Of course, if you sign it, you can see it's signed by Huawei. Yeah, sure. Yeah. For the third one, they do not provide an official promise, let's say. So for the regular upgrade, we aim to have it once a month. So we will also say we aim to update it monthly. There is no promise to customers that they cannot kind of blame us or do any legal measures if we delay. For the first one, we just spoke about. And for the fifth one about not finding Maverick correctly, Joshua said that will be improved with the new HSS version, with the upgrade. We already have the upgrade package. We are just waiting for you to give the goal to implement it. That was what I was towards. It's the one that is written there, BM 5299. No. Yeah, so this is one bug, HSS not finding Maverick correctly. Can you send me the ticket number where I need to approve? Tiwa should have it, right? But that's just one bug, the bug calculated. But I don't know any, I guess you need to approve any demand then for upgrading HSS? I think so, but I don't know where you have it. I don't know where you have it. Can you send me the ticket? I'm not a lot of that ticket. Like who created it? I'm sorry, I didn't understand what did you say? I don't know about the ticket. Do you know who created it or what? Like is there a demand for this? I'll check my open. I don't know who would usually create the demand when the package is already there to be installed. I don't know, maybe there is no demand to upgrade yet and we need to create it. Connected tickets. Click, click, click, click, click, click. There is no... Who would usually create this demand? Just a second, I'll just check all the tickets potentially, but I don't see any... Same for me. Ticket, nothing assigned to me, no demand with HSS in. The question would be who would create this ticket? Either it is the demand that we are giving to Huawei, that we are creating it, but also Huawei is creating these demands if they provided something and okay they just want to implement it. So... It is a bit nuts if we have the bug ticket and then on top of that we also create a demand. So for those, usually we get the demand then from Huawei whenever they have provided the solution. Of course we need to have the demand ticket to have the changes triggered. Yes, yes, yes. But I guess this new version will fix not only one bug, hopefully a few more. So it is the new HSS version? Yes. But we haven't created the demand for the new version. No, I don't know if we can get it. Since it is not available yet. But Joshua said we can install it, the package is available. I have no information from today. I mean that is what Joshua just said like 10 minutes ago. I heard it also for the first time. Do you imply that we do not have the new HSS package? That is a question, do we have or do we have not? We do have, I said it before, so who is challenging? The challenge is the new HSS package. We do have, I said it before, so who is challenging? Tibor. Tibor, do you know where we are? I want to check it. You asked Yun Dan next to you and I think she knows about it. We are waiting for the HSS update. She does not know. I do mention it last week, I think. HSS is quite important, we should upgrade from time to time. I think Sebastian, you know this topic, right? It is fine, I will check it with Lily. There is a new version that I will create, the demand change. Demand change, whatever. But keep it to the latest version. Keep catching the latest version, I think it is the right way to go. Yes, I agree. I heard it yesterday, the first time that the new version is waiting to be installed. I have been waiting for a long time, I think. I am waiting, but I did not get the information that it is available. We can do something. That is new for me today. But if you have it, yes. Please Tibor, create a ticket in Forma, Sebastian, approve and start with PPort. Yes, but I also need to have a release note for that one. Yes, that is coming hopefully with the package. New documentation, new API, blah blah, like we usually do. Because we will get the question by the customer, Can HSS do antivirus and malware detection? Currently I am not sure what to answer, because if I say it can do it a bit poorly, then that is not a good answer to give. If we have the package and release notes, we can say, not yet, but it will come with the next version. That is a better answer we can give. I think the answer should be yes, we can do it, because it is its function. Yes, but I sent you the email as of today, if I use some malware, they are not detected. Yes, did you try the real one? Yes, yes, of course. No, the one in the test set, those are not real. No, we have a different source. Okay, then what is the, do you have the virus fingerprint? If you do, please send it to me, and I will let you know which virus you have not spotted. But does it make sense with the old version, when you say it is improved with the new version, to wait until we have the new version? Yes, the new version, but the problem is you don't have the new version next week. Right? You can ask Sebastian, do you think you can upgrade HSS in one week? It depends on the upgrade, right? It depends on the amount of new functionalities will be added, as you said before. You said before, okay, there will be quite a couple of new functionalities added, then definitely not. Probably not. What we just do is... If there is only a small upgrade and there is not much to test, it can be quick, right? We have this ice fire thing you gave us, so this is working. We will use this one in the demo. But it is also not detected as a nowhere, by the way. Yes, it is a ransomware. Yes, but it is a virus, right? So, it is also part of a ransomware. It should be detected just because it is in there. The size of the search should also be detected. So, then what we can only do is kind of hide this antivirus stuff, because it is not working 100% and hoping it will be improved in the next version. So, I do not know what you mean with signature. So, I sent you this email last Friday. Fingerprint. I said fingerprint, I did not say signature. Fingerprint, yes. I do not know how to extract it and what does it mean. So, what do you need? How do we get the fingerprint of a virus? I do not know what to do. If you have the virus, then you are supposed to have the fingerprint. This is referring to what is this virus and what is the behavior. So, I think if you... It is just like a human. You use this fingerprint, you can identify this is me, this is T-Ball. I can give you the name, and then you can Google it and you know what it does. You mean kind of some... So, just example. So, I sent you this email on Friday. Here are three virus things, ransomwares, which are not identified. For example, Win33 CRELOC. That is a virus we have and it is detected by the Windows Defender as ransom, the below one, but not identified by HSS. And if you now say fingerprint, what do you need? What is the fingerprint? Okay, I do not want to start from there. If I Google it, here is the behavior of this thing and here is the technical information, but I do not know what you need. Search the fingerprint. It should be a random, like a hash number. I do not get any search results. Sebastian, can you help me? Yes, I need to... Let's do that together afterwards. Okay. I can send you this for one example, but I guess we have multiple examples. Check all the vulnerabilities, all the vulnerabilities. We can collect information. Okay, then we do it and send it to you. Question is if that will be already fixed with the new version and we do the effort, and we would not need to, but we can provide it. Yes, that is then what the back ticket is used to. And then we can send it to you. Okay, I will send it to you. I think we used this memory in 16 Gb for... But we will skip this part for the customer webinar next week because it is too soon. And we just hide this antivirus functionality here. But we do the ransomware with the ice fire example. Okay. I will send it to you. But we do the ransomware with the ice fire example you gave us. Thank you for that one. Okay. Sebastian, do you have... For the ice fire, have you already talked about the inconsistent results, I guess? Not yet. We just talked about the five points I sent via email. Because for the ice fire ransomware, I tried it out. It is working well from time to time. It is also detected and so on and so forth. But I also have the case that it is not detected and the ice fire stops running, but without being killed and therefore also not being reported by HSS. I will further try it out, but Joshua, I might need your support next week. You do see my email, right? Yes, I have also seen the video. I saw that and did everything exactly as you need. No. You have notes that you need to wait when you change the epoxy. You change the epoxy and the spreadsheet doesn't take effect. You run the virus and you will just go through because you think the epoxy is no change. The epoxy is supposed to be reported, no kill. Which proxy do you mean? The ransomware virus has two poxies. The first proxy is reported, no kill. The other one is reported, no kill. Yes. You change the proxy. I used it with report and isolate. So report and kill. No, every time you change the proxy it will not affect immediately. Which proxy are you talking about? Policy, no proxy. Policy, sorry. Policy. Every time you change the policy, Yes. You switch to report, no kill. You change to report, do kill. You need to wait until it takes effect. Yes, but I did not change the policy. Let's say it was especially when I set up everything. I downloaded the virus, I extracted it, I changed the mission there. Let me just do it. Just a second, just need to look into my environment. Here we go. Giving me a minute. I just set up my environment because I rebooted before. And then you can also show your screen and we can see what you're going to do. Yes, just logging into my tenant. All right, I have HSS. And some protection. I have here, let's take this one, HSS presentation 01. I can't do the mistake because I forgot. You rinse, change. All right, here we are. I just do root, then I need to. Let's see. See, it's there. It's the path road. See, it's executable. Let me see the policy. Policy, it's this one. I have here report, alarm and isolate. I have the page files, etc. and var log and home, Linux, root and sys. All right, for all types. It's already there. Let's see. See, it's running. It's not killing. And if I refresh here, I also don't get the event. It's like, it's encrypted as a file, it's created as a readme text file. Do you see the bait for the ransom? Which root it is? It's in the home image. Let's see, is this under the proxy? Let me see. So sometimes it works, sometimes it doesn't. It seems to be random, right? It seems to be like sometimes it does not try to encrypt the bait files, but it stopped running. So the process stopped running before it encrypted the bait files. So it encrypted some files. Let's see here also some of the files are encrypted, but not all at all. Why your bait file is called by the code? I don't know. Can you go to the bait folder? What do you mean by bait folder? Go to the virtual machine. CD? No, the bait. Okay, where is it? The bait, the SD something. Okay. That's where it's not attacking the bait file. That's why it's not working. For me, I think the main issue is that the process stops running, right? Because if it runs indefinitely, then it would eventually encrypt those files. But it does not, it just stops running. That's probably the issue. No, it's not encrypting the bait. I don't know why, but it's not encrypting the bait. Yes, but it's also not encrypting here. Oh, it's encrypted also. Everything else is encrypted. No, but the bait is not encrypted. Can you go to the SDEC Q0079? Sure. No, not this one. Not this one. Yes, Q0079. Ryan, let Andy take a look. Okay, thanks. Also, try it with another operating system, right? With the IMAW one. It's the same there. All right. Which version of the Linux is it? HCE2. Thank you for showing us that photo. You're welcome. All right. That was basically the main thing from my side. I have an additional topic. It's about these energy cloud customers. I just received information about the priority of needed services. For the open ones, the highest priority for the customer is SAC Master. Is it also possible to get some insight like we did for Cloud Bastion Host to SAC Master? Probably we have some difficulties about it because the SAC Master is still not stable. How come it becomes to the high priority? I do not aware of that. It's not a high priority. It's the highest out of the leftovers. Generally, it's medium. CBH is low priority. Yes, I just was informed yesterday by Daniel and Tao. I didn't know that until yesterday. Therefore, it's more important to have a look on SAC Master. Medium means the highest priority things. It's HSS and Container Guard, which we delivered. We have this ELB mode for WAF, which we planned next quarter and also for DBSS supporting my SQL. That is already planned and we do it next quarter. Then the next one would be have a look at SAC Master. Medium pure priority means somewhere next year. The question would be about your... you're saying it's not stable. Do you have any rough idea, timeline when it would be ready for use in partner clouds like OTC? We will see about that. We currently do not have... as far as I know, we do not have this. SAC Master is not delivered in any of the HALV cloud. It will probably have a lot of difficulties and a long, long period. So it's betting that. Okay, but it's strange because they left Orange and they say they need the service because they use it. In the Orange, they do not use this service. But why do they then say they need to continue? That's a different angle, a different view. Then it will not be a blocker for their current business because they haven't used that. But I agree it's good to have this one. But I'm just saying it's ready for the long range, long period delivery. Yeah, I mean, yeah. But somehow it should be on our roadmap in the future, even if it's taking a long time. Because it's integrated in so many things, checking the whole platform. That's the main issue. You integrate a lot of things and the period gets longer. People start forgetting things and you end up with a very difficult delivery. Yeah. So if we plan to do that, we tend to do it quick, shut the delivery, have enough resources, and give it a certain period and get it done ASAP. But you said it's not stable. No, it's not stable. It means you have a lot of new features coming with this thing. You keep integrating stuff, you keep integrating AI stuff. But that's cool. Yeah, it is cool. But the new feature means new function and the new function means long period test and probably have some. Some of the features are even experimental. So you see what I'm saying here. So I don't see a big issue in having, if we mention it's like open beta test and so on, we still have beta features in HSS. So I don't think it's a blocker to not do this service. I'm not saying it's a blocker or anything. I just say if you do it, I am to do it quick. Yeah, okay. If it's possible to do it quick. Which would bring me back to the initial request, can we also have some session to get a live demo of the service like we did for CbH? Maybe I will ask Daniel. That would be great. And my topic, I still have like two more topics need to go through, which is quite important. The first one is the EPSGA and the second one is the HSS image for ECS. Yeah. Who is the response for the HSS image building and testing? That's Image Squad. So Homan Schiller and Johannes Zischke. I'm in contact with them. Do they have any progress? They say they're going to finish it in this month, right? You only have two weeks. They said it will not be done before the end of this month. So let me ask them for an update how well they are progressing. Because we don't have a regular meeting with them and you say it's not necessary. So every week I aim to have some at least update. I don't want to ending up like at the end of this month. I don't want to hear they say, oh, we just finished creating the folder. I will ask them for that. It's no plan, no schedule, no in the roadmap, nothing. They planned and I also agreed with them if they have issues or base issues and do not progress in time as a plan. They will let me know. Nevertheless, of course, I can ask them regularly every week. You can ask them every day if you want for an update. But the more I ask, the less they progress. Do they have any progress? It's been at least two or three weeks since they said it. I will check it. Okay, still no progress. What about EPS? For EPS, I told you, right? So we are waiting for reply from what's your name? Yeah, I know. We don't get any reply there. We cannot move on. If we have the APIs in UNL, then we can test it there shortly. Then, you know, I think we are, if it's available in UNL as well, we are also fine to go to GA with it, according to what we have. At least we need to do some minor functional testing. Yeah, that's of course. But if we don't have it yet in UNL, then there is no way to test it. The test case would include creating overarching region projects. If we only have it in one region, we cannot test functionality. Just a question, Joshua. So is also this Energy Cloud customer requesting it or why do you want to push it? Because I didn't see any customer request for general availability. For EPS? Yes. How should I answer this? No, no customer demanded. But that's not the reason we put it in GA forever, right? It's just to complete it after hundreds of years. First thing, it's been there for years. It's not for months. I kind of accept for that. But it's there for years. It's not just one year, two years. I think it's like three or four years. Longer, longer, longer, even before I joined. Somewhere, somebody decided to make it a white list only for one customer. And we didn't touch it since then. Yes, and this nonsense should end up right here. So we spent time, we spent money, we spent people to evolve, to get this delivered done. And it functioned just fine because you never hear a speaker complain EPS is not working, right? I know it's not complaining. Because I also use it every day. It functioned good. Yeah, I agree. What's your reason to not GA it? That's the question. It's only just a priority thing, so it's not important. But surely we should do it when we have time left. I think we should put some priority on it because you already see if we don't put any priority on it for the last four years. Yeah, because it was not important for any customer. So rather have HSS and Cloud Firewall instead of EPS. But if we have resources, yeah, we can. It's not that difficult, right? It's publishing APIs from all sides. It's not too much effort publishing. We will need to have some effort testing it. Question, of course, Joshua, is there any service upgrade of EPS that we want to implement before we go GA with it? I think you already checked it and you said, okay, there is no real upgrade of it available. No, not really. So that's also fine for me then. We don't need to upgrade it. Publishing APIs in UNL, testing it, okay, is it working as intended? Also the CCROS region functionality there and then let's go GA. It's okay. Yeah, what we just need to include is then testing and open bugs like service integrations. So if you cannot authorize ECS and CCE, for example, as basic services, the service is basically useless for customers. And I have to fear a lot of services will not be integrated automatically if you deploy it on Netherlands and we need to trigger other squads to do some work. But I'm open for surprises. But yeah, you are right. The priority is adjustable, but the tech is still important. Yeah. And I see the image for HSS is quite important. And hopefully next week we can get some updates like they already finished this image, that image and waiting for test or something like that. Is it also needed to update any console UI? Yes. It's already done. The console part is already done in the test bed. And we are waiting for, but it doesn't do anything because we don't have the image at the back end. So I do hope we can have some update of what they are actually doing. I'm checking maybe they are already even finished with you. I trust you, but I just don't trust them. I mean, it also comes from the bad experience because I think last year or sometime I was joined the squad. People said they are going to finish this day, that day. And when we asked them what's the progress after three months, they said, oh, we just finished our vacation. So no progress. All right. I have one other topic not related to HSS and stuff. Maybe Kibo, you can help me out there regarding the PVS or the platform VAS. Kibo, that's probably not the thing for you. Yeah. I agree with that. But in the end, OK, we repaired the manager notes. That's fine. But Kibo, we talked about in the past about upgrading it eventually, right? So and step by step. And I'd like to plan with you, maybe not in this call, but we can do it offline because I think it's also not a topic for you, I'm sure. I can just quickly say that I have created a division ticket and it's being evaluated by R&D currently. So I'm tracking the progress. I will get back to you. I have new information. I uploaded like a comment to the requirements. I spoke with Ference about it. What are the exact requirements? And I put it in the ticket. So, yeah, then I have feedback from R&D. I will get back to you. OK, good. You cannot estimate some timeline. When we get... Usually a deadline for each. By step or like... Like each... You can say step by step. It's currently in the analyze stage. So I can also ping the guy who is analyzing it. It has been one day, so it's currently on him for one day. I think that's progressing quite fast. Let's keep in touch there about this topic. The freedom to not lose focus on it. Because it's back end security, right? It's back end security, of course, but if I have some occasions, I need to take over his part with annoying people about it. But we need to get it done, right? From what I've got from my colleagues, it's fairly manageable currently to maintain it. So we need to see how we can improve the situation there. And without risking the availability of CP bus and the functionality of CP bus. Okay, that's it. Any other topics you need to talk about today? Send me the email to dedicate the priority change for the energy cloud, because I think none of us noticed that priority change. It's kind of a surprise for me though. So there was no email. There's an excel list I received from Daniel. No, not from you Sebastian, right? And you received it from Daniel. I can forward you this excel list, and there's a priority inside. I didn't notice it before. That's the excel list I already showed to you, so it's the same actually. We talked about this one already. But wasn't that because... I know we have these two servers on demand, but my question is since when the priority changed? Because I think before the CBH is median. The SACMASTER is low. That's what... I just received this file. I was absent when this file was created and prioritized. So I was absent, so I cannot answer this question. I sent you the screenshot from the list in our group. There you see the priority. And basically that is the list I received from Sebastian. And Sebastian, you received it from Daniel? Yes. I don't know when, so a few weeks ago already. It's months ago already. Months ago. So March I think. So there you see the priority. So the high things. We have delivered the cipher suits. We will deliver the RAP support for ERB mode. So these are the high things. HSS we already delivered. And then next is medium is DBS. S supports RDS for MySQL. That's what we have planned. And then next thing would be SACMASTER for medium priority. If you see the list which I just put a screenshot in the chat. That is what I received and I just identified the priority yesterday because I talked about CBH with Daniel. He said, why do you care about CBH? It's low priority. Have a look at SACMASTER. It has a higher priority for the customer. That's basically the information I have. Any comments from your side Joshua? Sorry, I was not listening. Oh. Okay. I sent you a screenshot of the priority. Yes, about the priority. And this list is a few months old. And I just received it while I returned. And there you can see the priority. So it didn't change. It was this way all the time. Okay. So SACMASTER has higher priority than CBH. That's why it would be nice to get also an overview by the new view. That we can have a look into it from our perspective. Okay. That would be really cool. Okay. Unfortunately, I have to leave. I have a private appointment. Now we talk to each other next week latest. We will stay in contact via chat. Alright. Thank you. Okay. Have a good day. Alright. Have a good day everyone. Okay. Bye. Bye. Bye. Hello. Hello. Hello. Hello. Hello. Oh, we have a meeting, right? I will pick you up. I will pick you up by phone. I am on my way out. Okay. Are you on your way back or on your way back? I just finished a meeting with a client. Okay. I am on my way to the train station. Okay. Let's talk about the background first. Why is the delay suddenly on the right? Oh. I think it's like this. Yesterday, on Monday, we had a meeting with Alker, the head of TCC. This meeting is about how OTC Force can bring Debian to the market and how GoToMarketing can do it. And in this meeting, wait a minute. Put on your headphones. Let me put them on. Hello, can you hear me? Yes, yes, yes. In this meeting, there are several parts of the meeting. One of them is that the OTC team summarized the progress of the small car and the key activities in the first half of this year. And when they summarized it, they also proposed two points to this product. The first point is the old-fashioned GTO. I think that's the pace we're going forward now. Including the July verification. After the verification, we will go through the payment process. That is the current solution. And the second thing that Alker mentioned is what is written in the film. The open source components and versions on the platform are relatively old. But it doesn't show which service specifically. Because he mentioned this before. What I understand is that it's just the first. Some of our open source versions of the PASS are relatively old. And then the second is that the open source components in ModelArt are biased. There are only two directions. Because there are a lot of sales at the meeting, we can't clarify this with him. So we sent him back. That's probably the background. I don't care what he says. We discuss our own strategy. And then we give him the answers. The strategy is good. If it doesn't work, can you optimize it in the company? If it doesn't work, then there's nothing we can do. We still have to try our best. So let's discuss the strategy again. Because last time when Mr. Yu came, he also mentioned that the open source will be specially distributed. It's specially used in Europe. The open source distribution doesn't do the reinforcement, doesn't do the verification, doesn't do the double-closing. After the community is sent, we will throw this image out. But then the plan of the leader of the Dai's If you do that, I think at least at the stage of publishing the version, TSI can't say anything, right? As for whether it can be upgraded, if it is upgraded and found to be backward again, that is also his business. You can also force him to improve. So we first put our strategy under the car, and a progress in each strategy. Let's discuss it again.
________________________________________split transcription____________________________
Meeting Minutes

**Meeting Overview**
- **Date & Time**: Not specified in transcription
- **Location**: Unspecified
- **Attendees**: Sebastian, Joshua, TiBo, Andy, Yun Dan, Lily, Tibor (arrived late)
- **Chairperson**: Unnamed Chairperson

**Agenda Items**
1. HSS Pain Points and Compatibility Issues with New Operating Systems.
2. Signing the Agent with Huawei Certificates for Better Recognition.
3. Regular Upgrade Schedule for HSS.
4. Upcoming HSS Version Upgrade to Fix Bugs, Including "Maverick" Detection Issue.

**Discussion Details**

1. **HSS Pain Points and Compatibility Issues**
   - Joshua will address compatibility issues of HSS with new operating systems at R&D level.
2. **Signing the Agent for Better Recognition**
   - TiBo proposed signing the agent with Huawei certificates to make it identifiable as coming from Huawei rather than being unknown. Andy was asked for input on this matter.
3. **Regular Upgrade Schedule for HSS**
   - There is no official promise given, but a monthly upgrade schedule is aimed at for regular updates of HSS. This is subject to change without legal liabilities or customer blame for delays.
4. **Upcoming HSS Version Upgrade**
   - The new version will fix the "Maverick" detection issue and potentially other bugs.
   - It was mentioned that the package is available but not yet installed, with the first mention being today during the meeting.

**Decisions and Action Items**

1. **Documentation Update**: TiBo to ensure documentation for third-party cloud server and on-premise (onprem) solutions is updated promptly. (Responsible: TiBo; Deadline: Not specified)
2. **Approval Process**: Sebastian will approve the creation of a ticket in Forma by Tibor for initiating the upgrade process of HSS via PPort. (Responsible: Sebastian; Action Required: Approve Ticket Creation)
3. **Release Note Preparation**: Requested documentation, including release notes and new API details, must be provided alongside the package to ensure informed customer communication regarding antivirus capabilities. (Responsible: Tibor/Team; Action Required: Provide Release Notes & Documentation)

**Other Matters**

- A discussion on HSS's antivirus and malware detection capabilities was raised, highlighting current issues with detection and the need for accurate information post-upgrade.
- The urgency of upgrading to the new version of HSS was acknowledged, but the feasibility of a one-week turnaround was questioned due to potential new functionalities requiring testing.

**Note**: Specific dates for action items and decisions were not mentioned in the transcription. Deadlines should be determined based on usual company protocols or as agreed upon by team members post-meeting.Meeting Minutes

**Meeting Overview**

* Date & Time: Not specified in transcription
* Location: Not mentioned; assumed virtual due to reference to operating systems and cloud services
* Attendees: Ryan, Andy (mentioned by name), Tao, Daniel, Homan Schiller, Johannes Zischke, Joshua, and unnamed participants from the Energy Cloud customer team
* Chairperson: Not identified

**Agenda Items**

1. Analysis of Encryption Process Issues on Linux OS (HCE2)
2. SAC Master Service Prioritization and Stability Update for Energy Cloud Customers
3. HSS Image Building and Testing Progress Update for ECS
4. EPSGA General Availability Status Inquiry

**Discussion Details**

1. **Encryption Process Issues on Linux OS (HCE2)**
   - An issue with the encryption process not completing within the expected timeframe was discussed.
   - Participants noted that the problem does not seem to be customer-driven but rather a long-standing internal matter needing resolution.

2. **SAC Master Service Prioritization and Stability Update for Energy Cloud Customers**
   - SAC Master service prioritization questioned due to its stability and lack of critical customer demand.
   - There was an agreement on completing the SAC Master service after years of it being white-listed for a single customer without further development.

3. **HSS Image Building and Testing Progress Update for ECS**
   - Homan Schiller and Johannes Zischke are responsible for the progress, which has not been reported in recent weeks.
   - Joshua expressed concern over the lack of updates and requested regular weekly check-ins to monitor progress closely.

4. **EPSGA General Availability Status Inquiry**
   - EPS (Enterprise Project Service) GA status was discussed with no clear customer demand identified.
   - The necessity for moving EPS to general availability due to its long-standing existence in a whitelisted state was debated, with the consensus being that it should be considered completed and opened up.

**Decisions and Action Items**

1. **Encryption Process**
   - Ryan is to investigate further into why the encryption process is not meeting expectations on HCE2.
   - Deadline: Not specified

2. **SAC Master Service Prioritization**
   - Tao, Daniel, and other team members will reassess SAC Master's priorities based on its stability and lack of urgent customer requests.
   - Action Item: Conduct a review to determine next steps regarding SAC Master service development.

3. **HSS Image Building for ECS**
   - Homan Schiller and Johannes Zischke are tasked with providing weekly progress updates on the creation of the HSS image for ECS.
   - Action Item: Regular weekly status reports from Homan and Johannes by end of month.

4. **EPSGA General Availability**
   - Joshua is to lead a review on moving EPS to general availability, considering its long-standing existence in a whitelisted state without customer complaints or issues.
   - Decision: Move towards GA for EPS based on current functional testing within available regions.

**Other Matters**

- There was no specific mention of other matters. However, the meeting seemed to revolve around addressing internal operational challenges and customer service improvements related to cloud services and encryption processes.**Meeting Minutes**

---

### Meeting Overview

- **Date & Time:** The meeting details were not explicitly mentioned in the transcription.
- **Location:** Not specified.
- **Attendees:** Various team members including Kibo, Sebastian, Daniel, and others discussed over a call. Attendee names were not all clearly identified throughout the conversation.
- **Chairperson:** No chairperson was named; the discussion appeared to be collaborative.

### Agenda Items

1. Update on Project Progress and Prioritization
2. Technical Issues: Open Source Component Updates
3. Strategic Plan for Distribution of Open Source Components

### Discussion Details

#### 1\. Project Progress and Prioritization

- SACMASTER has been prioritized over CBH due to its higher priority status as confirmed in the project overview.
- There was a discussion about delays and the need for an updated view to better manage priorities.

#### 2\. Technical Issues: Open Source Component Updates

- Alker, head of TCC, raised concerns during a previous meeting regarding outdated open source components on the platform. The specifics were not clarified in that setting.
- It was mentioned that some PASS (Platform as a Service) open source versions are old and ModelArt may have biases towards certain services.

#### 3\. Strategic Plan for Distribution of Open Source Components

- A strategy was discussed to distribute open source components specifically targeted at the European market without reinforcement, verification, or double-closing post-community send-off.
- The plan's leader (Dai?) suggested a course that would prevent TSI from making comments regarding version publication.

### Decisions and Action Items

#### No Explicit Decisions or Action Items Mentioned in Transcription
- There was discussion about the need for an updated overview to better understand project priorities, indicating an implied action item to revisit and possibly update project prioritization documentation.
- The team agreed on discussing their own strategy before responding to external feedback, suggesting an internal strategic review is needed.

### Other Matters

#### Communication Gaps and Future Directions
- There was a clear emphasis on the need for clearer communication regarding technical issues raised by Alker. It was decided that clarifications would be sought post-meeting.
- The team's focus shifted towards formulating their strategy independent of external comments, indicating a resolve to establish an internal direction before responding externally.

---

**Note:** Meeting minutes are typically formal documents generated following a meeting to summarize key points and decisions made. The transcription provided lacked specific dates, times, locations, full names of attendees, and clear action items with assigned responsibilities and deadlines. The minutes have been crafted based on the content shared in the discussion but may require additional input from meeting participants for complete accuracy.

**Action Item Follow-up:**
- Confirm details such as date, time, location, and full attendee list.
- Assign specific tasks to team members regarding strategy development and communication with Alker/TCC.
- Establish a deadline for revisiting project priorities and strategic planning updates.**Consolidated Meeting Minutes**

---

### Meeting Overview

- **Date & Time**: Not specified in transcription (to be determined post-meeting)
- **Location**: Unspecified; assumed virtual due to references to operating systems and cloud services
- **Attendees**: Sebastian, Joshua, TiBo, Andy, Yun Dan, Lily, Tibor, Ryan, Tao, Daniel, Homan Schiller, Johannes Zischke, Kibo, Alker (head of TCC), and unnamed participants mentioned over a call.
- **Chairperson**: No chairperson was named; the discussion appeared to be collaborative.

### Agenda Items

1. Update on Project Progress & Prioritization
2. Technical Issues: Open Source Component Updates & Strategic Distribution Plan for European Market
3. HSS Development & Deployment Challenges
4. SACMASTER vs CBH Project Priorities Clarification
5. Addressing Internal Operational Challenges and Customer Service Improvements

### Discussion Details

#### 1\. Project Progress & Prioritization

- SACMASTER prioritized over CBH due to higher priority status as confirmed in project overview.
- Delays noted; need for updated view to better manage priorities discussed.

#### 2\. Technical Issues: Open Source Component Updates & Strategic Distribution Plan

- Alker raised concerns about outdated open source components on the platform.
- Strategy discussed to distribute open source components targeted at European market without reinforcement or double-closing post-community send-off.
  
#### 3\. HSS Development Challenges

- Discussion included delays and prioritization issues for HSS development.
- SACMASTER's higher priority was noted over CBH.

#### 4\. SACMASTER vs CBH Project Priorities Clarification

- SACMASTER confirmed as a higher priority project over CBH based on current project overview.

#### 5\. Addressing Internal Operational Challenges & Customer Service Improvements

- Focus shifted towards formulating an internal strategy before responding to external feedback.
  
### Decisions and Action Items

- Need for an updated overview to better understand project priorities, indicating action item to revisit prioritization documentation.
- Strategy review needed internally before responding externally regarding version publication.

#### Specific Actions:

1. SACMASTER team to reassess priorities based on stability and lack of urgent customer requests.
2. Homan Schiller and Johannes Zischke will provide weekly updates on the creation of the HSS image for ECS by end of month.
3. Joshua will lead a review on moving EPS to general availability, considering its long-standing existence in a whitelisted state without customer complaints or issues.

### Other Matters

- Emphasis on need for clearer communication regarding technical issues raised by Alker; clarifications sought post-meeting.
- Team agreed to discuss their strategy internally before responding to external comments.

---

**Note**: Meeting minutes are typically formal documents generated following a meeting. The transcription provided lacked specific details such as full names of all attendees and clear deadlines. Additional input from meeting participants is needed for complete accuracy.

**Action Item Follow-up:**

- Confirm exact date, time, location, and full attendee list.
- Assign specific tasks to team members regarding strategy development and communication with Alker/TCC.
- Establish a deadline for revisiting project priorities and strategic planning updates.WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
